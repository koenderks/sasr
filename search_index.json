[["index.html", "Statistical Audit Sampling with R, 1st Edition Welcome", " Statistical Audit Sampling with R, 1st Edition Koen Derks 2022-12-16 Welcome Welcome to the book Statistical Audit Sampling with R (SASR), a practical guide for auditors that want to use state-of-the-art statistical methodology in their audit sampling activities. While this book focuses completely on the subject of audit sampling, it aims to discusses it from two viewpoints: the classical (frequentist) approach and the Bayesian approach. Through these two lenses, it explains the statistical theory underlying commonly applied audit sampling procedures and demonstrates how to perform these procedures in a statistically sound manner compliant with international auditing standards using the jfa (Derks 2022) R package. Please keep in mind that this is a preview release and much content is still missing. If you are missing some of the content today, then check back tomorrow: This book is actively being worked on. References "],["preface.html", "Preface", " Preface This book is for auditors who want to employ statistical audit sampling in audit practice using the statistical programming language R. It covers an array of conventional and state-of-the-art statistical instruments available to auditors, explaining what they are, the assumptions on which they are based, and when they should ideally be used. Furthermore, it offers concrete suggestions for incorporating advanced statistical methodology into audit practice and demonstrates its usefulness using real-life case studies. Hopefully, this book can be a resource for the proper, efficient and effective use of statistical methods in audit practice. This book adresses the need for a transparent and clear description of the application of statistical sampling methodology in audit practice. I have found that most guidance about audit sampling contains insufficient detail to allow for full transparentcy or a deep understanding. Furthermore, the implementation of these methods in practice is often even less transparent, as theory and calculations are hidden from the user in commercial closed-source tools or excel sheets internally used by audit firms. As such, many auditors may attempt to understand the mechanisms at play when engaging in statistical audit sampling but are often left with more questions than at the start. This book aims to give full control to the auditor when it comes to explaining the statistical methodology used in practice. This book focuses on audit sampling but approaches it from two viewpoints: a classical (frequentist) approach and a Bayesian approch. Through these two lenses, it explains the statistical theory underlying commonly applied audit sampling procedures and demonstrates how to perform these procedures in a statistically sound manner compliant with international auditing standards. It also makes the case for adopting Bayesian statistical methods in the audit practice and demonstrates why these methods can bring many practical advantages for the auditor. This book is organized as follows. Chapter 1 provides a basic introduction to the R programming language. Chapter 2 discusses the basic statistical theory underlying audit sampling. Chapter 3 discusses the standard audit sampling workflow. Chapter 4, 5, 6, and 7 go into more detail about using statistial methods to plan, select and evaluate audit samples. Finally, Chapter 8 discusses other R-related software implementations of audit sampling. "],["CHAPTER-1.html", "Chapter 1 Introduction to R", " Chapter 1 Introduction to R R is a programming language and software environment for statistical computing and graphics. It is widely used among statisticians and data scientists for data analysis and visualization. However, R can also be used in an auditing context. R has a large and active community of users, and there are many resources available for learning and using R. "],["basics.html", "1.1 Basics", " 1.1 Basics One of the basic features of R is its ability to manipulate data. In R, basic calculations work by using the standard arithmetic operators such as + for addition, - for subtraction, * for multiplication, and / for division. For example, if you want to calculate 2 + 3, you would type in 2 + 3 and R will return the result of 5. 2 + 3 # [1] 5 R also allows for more advanced calculations such as exponentiation using the ^ operator, and square roots using the sqrt() function. For example, to calculate the square root of 9, you would type in sqrt(9) and R will return the result of 3. sqrt(9) # [1] 3 You can also use parentheses to specify the order of operations in your calculations. For example, if you want to calculate (2 + 3) * 4, you would type in (2 + 3) * 4 to get the result of 20. (2 + 3) * 4 # [1] 20 Overall, basic calculations in R are similar to those in other programming languages and follow the standard order of operations. 1.1.1 Vectors In R, vectors are one-dimensional arrays of data that can hold numeric, character, or logical values. Vectors can be created using the c() function, which stands for concatenate. For example, to create a numeric vector, you can use the following code: x &lt;- c(1, 2, 3, 4, 5) To create a character vector, you can use quotes around the values: y &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;) To create a logical vector, you can use the logical values TRUE and FALSE: z &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE) Vectors can be indexed using square brackets and a numeric value. For example, to access the second element of the vector x, you can use the following code: x[2] # [1] 2 Vectors can also be subsetted using a logical vector. For example, to get all elements of the vector x that are greater than 3, you can use the following code: x[x &gt; 3] # [1] 4 5 Vectors can also be modified using indexing and assignment. For example, to change the third element of the vector x to 6, you can use the following code: x[3] # [1] 3 x[3] &lt;- 6 x[3] # [1] 6 R also has functions for performing mathematical operations on data. For example, we can use the mean() function to calculate the average of a vector of numbers, or we can use the length() function to calculate the number of elements in a vector: mean(x) # [1] 3.6 length(y) # [1] 3 Overall, vectors are a useful data structure in R for storing and manipulating data. 1.1.2 Matrices In R, a matrix is a two-dimensional collection of values that are arranged in rows and columns. You can create a matrix using the matrix() function. For example: m &lt;- matrix(1:9, nrow = 3, ncol = 3) m # [,1] [,2] [,3] # [1,] 1 4 7 # [2,] 2 5 8 # [3,] 3 6 9 This creates a 3x3 matrix with the values 1, 2, 3 in the first column, 4, 5, 6 in the second column, and 7, 8, 9 in the third column. You can also create a matrix by combining several vectors using the cbind() or rbind() functions. For example: v1 &lt;- c(1, 2, 3) v2 &lt;- c(4, 5, 6) v3 &lt;- c(7, 8, 9) m &lt;- cbind(v1, v2, v3) m # v1 v2 v3 # [1,] 1 4 7 # [2,] 2 5 8 # [3,] 3 6 9 This creates a matrix with the same values as before, but the columns are created by binding the vectors together. You can access the elements of a matrix using the square bracket notation. For example, to access the element in the second row and third column of m, you would use the following code: m[2, 3] # v3 # 8 You can also use the dim() function to get the dimensions of a matrix, and the colnames() and rownames() functions to get the names of the columns and rows, respectively. There are many other functions and operations available for working with matrices in R, including mathematical operations such as matrix multiplication and inversion. 1.1.3 Data Frames In R, a data frame is a two-dimensional table of data with rows and columns. Each row represents a single observation or record, and each column represents a particular variable or attribute. Data frames are similar to a spreadsheet in Excel or a table in a database. Each column in a data frame can have a different data type, such as numerical, character, or logical. The data in each row must match the data type of the corresponding column. To create a data frame in R, you can use the data.frame() function and pass in the data you want to include in the data frame as arguments. For example: df &lt;- data.frame(x = c(1, 2, 3), y = c(4, 5, 6)) This will create a data frame with two columns, x and y, and three rows of data. You can access the data in a data frame using indexing and subsetting. For example, to access the first row of the data frame, you can use the following command: df[1, ] # x y # 1 1 4 To access a specific column, you can use the $ operator (or the index): df$x # [1] 1 2 3 df[, 1] # [1] 1 2 3 You can also use functions like head() and tail() to view the first or last few rows of a data frame. Data frames also have several built-in functions that allow you to manipulate and analyze the data. For example, you can use the summarize() function to calculate summary statistics for each column, or the group_by() function to group the data by a specific variable and apply a function to each group. "],["packages.html", "1.2 Packages", " 1.2 Packages In addition to these basic features, R has many packages and libraries that extend its capabilities and provide additional functions and tools for data analysis and visualization. A package is a small bundle of code that an R user (or group of users) wrote and uploaded to a central server for everybody to access, download and use. Some popular packages include dplyr for data manipulation, ggplot2 for data visualization, and caret for machine learning. With its versatility and robust community, R is a valuable tool for anyone working with data. 1.2.1 Installing a Package In many cases, you will download an R package from the CRAN server. This can be done via the install.packages() function by providing the package name in quotes. For example, an important package for data visualization is ggplot2. To install this package, you can simply run: install.packages(&quot;ggplot2&quot;) To illustrate its concepts and ideas, this book heavily draws from the jfa package, an R package for statistical auditing, which can also be downloaded from CRAN. Before running the examples in this book, you should install this package by running the following command in R: install.packages(&quot;jfa&quot;) 1.2.2 Loading a Package Once you have installed a package, you must load it into every R session. To load a package into your R session, call library() and provide the name of the package (without quotes) that you want to load. For example, before running the examples in this book, you can load the jfa package with: library(jfa) If you want a deeper understanding of how the jfa package works, or want to look at the source code of the package, see the package website. 1.2.3 Updating a Package R packages are updated regularly. To update a package in your R library you should call update.packages() and provide the name of the package that you want to update in quotes. For example, each time there is a new release of the **jfa* package, you can update it by running: update.packages(&quot;jfa&quot;) "],["loading-data.html", "1.3 Loading Data", " 1.3 Loading Data 1.3.1 Loading Data from a CSV File A commonly used data type is a .csv file. You can load this type of files via the read.csv() function. For example, if the file example.csv is in the current working directory, you can load it by running: read.csv(&quot;example.csv&quot;) 1.3.2 Loading Data from an Excel File Another commonly used data type are Excel files. You can load this type of files via the read_excel() function from the readxl package. For this to work, you should first install this package using the install.packages() command and load it into the R session using a call to library(). For example, if the file example.xlsx is in the current working directory, and the data you want to load is on the first worksheet, you can load it by running: {r, eval=FALSE}\\ install.packages(\"readxl\") library(readxl) read_excel(\"example.csv\", sheet = 1) "],["CHAPTER-2.html", "Chapter 2 Important Concepts", " Chapter 2 Important Concepts Statistical audit sampling is a statistical method used by auditors to evaluate a sample of transactions or other items within a population in order to draw conclusions about the population as a whole. It is a cost-effective way to test the accuracy and reliability of financial information, as it allows auditors to test a representative sample of the population rather than the entire population. There are two main types of audit sampling: statistical sampling and non-statistical sampling. Statistical sampling uses probability theory to select a sample from the population and perform inferences about the population based on the sample. Non-statistical sampling, on the other hand, is based on the judgment of the auditor and does not involve statistical techniques. This book does not concern itself with non-statistical sampling. In statistical audit sampling, the auditor first defines the population and the sampling units, which is the unit of measurement for the population (e.g., transactions, invoices, etc.). The auditor then selects a sample from the population using a specified sampling method, such as random sampling or stratified sampling. After the sample has been selected, the auditor performs audit procedures on the sample and records the results. The auditor then uses statistical techniques to calculate estimates of population characteristics, such as the mean or the proportion of items with a certain characteristic (e.g., the proportion of items that are misstated). The auditor compares these estimates to predetermined acceptance criteria to determine (i.e., the materiality) whether the population meets the criteria. One important concept in statistical audit sampling is the confidence level. The confidence level is the probability that the sample estimate falls within a certain range of the true population value. For example, if the confidence level is 95%, there is a 95% probability that the sample estimate is within the specified range of the true population value. The confidence level is inversely related to the audit risk \\(\\alpha\\), as follows: \\[\\text{Confidence} = 1 - \\text{Audit risk}(\\alpha)\\] Hence, the desired confidence level is known to the auditor before they start with their audit sampling activities. Another important concept in statistical audit sampling is precision. Precision refers to the degree to which the auditors’ inferences are reliable. An estimate with high precision is more likely to provide accurate conclusions about the population. The precision of an estimate can be improved by increasing the sample size. To recap, the basic statistical concepts behind statistical audit sampling include: Population: The entire group of items that the auditor is interested in studying. For example, the population may be all of the transactions in a company’s accounts receivable. Sampling unit: A physical representation of the population to be audited. Sample: A subset of the population that is selected for testing. The sample should be representative of the population in order to accurately reflect the characteristics of the population. In conclusion, audit sampling is a statistical method used by auditors to evaluate a sample of transactions or other items within a population in order to draw conclusions about the population as a whole. Statistical audit sampling uses statistical techniques to select a sample from the population and make inferences about the population based on the sample, while non-statistical sampling is based on the judgment of the auditor. "],["classical-versus-bayesian-inference.html", "2.1 Classical versus Bayesian Inference", " 2.1 Classical versus Bayesian Inference The classical (frequentist) and the Bayesian approach to statistical inference are two different ways to use data to perform inferences or draw conclusions about a population. Both paradigms have their own set of assumptions and approaches to statistical estimation and hypothesis testing. Classical statistics is based on the concept of probability as a frequency. It is the traditional approach to statistical analysis and relies on the idea that probability is the long-term frequency of an event occurring in a large number of trials. This approach is based on the law of large numbers, which states that as the number of trials increases, the frequency of an event will approach the true probability of the event occurring. In frequentist estimation, the parameter that needs to be estimated is considered to be fixed, but unknown. The goal of frequentist estimation is to use the sample data to find the value of the parameter that is most likely to be true. This is typically done using point estimates, which are single values that are thought to be the best estimate of the population parameter, and interval estimates, which provide a range of values that the population parameter is likely to fall within. Bayesian estimation, on the other hand, is based on the idea that the parameter of interest is not fixed but uncertain. In this approach, the parameter is onsidered to be a random variable with a certain distribution, and the goal is to use the data and prior knowledge about the parameter to update our belief about its value. This is typically done using Bayes’ theorem, which states that the posterior probability (i.e., the updated belief about the parameter after seeing the data) is equal to the prior probability (i.e., the belief about the parameter before seeing the data) times the likelihood (i.e., the probability of the data given the parameter). One major difference between classical and Bayesian statistics is the way they handle uncertainty. In classical statistics, uncertainty is represented by the standard error of an estimate, which is a measure of the precision of an estimate. In Bayesian statistics, uncertainty is represented by the posterior distribution, which is a distribution of the possible values of the population parameter given the sample data and our prior beliefs. Bayesian inferences uses uses Bayes’ theorem to update the prior beliefs about the population parameter with the new information from the sample data. Bayes’ theorem is given by the following formula: \\[p(\\theta \\,|\\, y) = \\frac{p(y \\,|\\, \\theta)p(\\theta)}{p(y)}\\] where \\(p(\\theta \\,|\\, y)\\) is the posterior probability of the population parameter \\(\\theta\\) given the sample data \\(y\\), \\(p(y \\,|\\, \\theta)\\) is the likelihood of the sample data given \\(\\theta\\), \\(p(\\theta)\\) is the prior probability of \\(\\theta\\), and \\(p(y)\\) is the total probability of the sample data occurring. Because with a fixed sample \\(p(y)\\) is a constant, Bayes’ theorem is often given as follows: \\[p(\\theta \\,|\\, y) \\propto p(y \\,|\\, \\theta) \\times p(\\theta)\\] or, in words: \\[\\text{Posterior} \\propto \\text{Likelihood} \\times \\text{Prior}\\] There are several other differences between classical and Bayesian approaches. One major difference is that classical approaches focus on the long-run behavior of an estimator, while Bayesian approaches focus on the probability of the estimator being correct given the data. Another difference is that classical approaches rely on asymptotic results (i.e., results that hold in the limit as the sample size goes to infinity), while Bayesian approaches can be applied with any sample size. Additionally, Bayesian approaches allow for the incorporation of prior knowledge about the parameter, while classical approaches do not. Overall, classical and Bayesian statistics are two different approaches to statistical analysis that have their own unique strengths and weaknesses. Classical statistics is a well-established approach that is widely used in scientific research and audit practice, but it has some limitations, such as its reliance on assumptions and its inability to incorporate prior beliefs. Bayesian statistics is a newer approach that allows for more flexibility in statistical inferences, but it requires the specification of prior beliefs, which can be difficult to quantify. "],["the-bayes-factor.html", "2.2 The Bayes factor", " 2.2 The Bayes factor The Bayes factor is a measure used in Bayesian inference to compare the relative strength of evidence between two competing hypotheses. The Bayes factor is calculated by comparing the probability of the observed data given each of the two competing hypotheses. This probability is known as the likelihood of the data. The Bayes factor is then the ratio of the likelihood of the data under one hypothesis to the likelihood of the data under the other hypothesis. The Bayes factor can be used in the context of an audit, where the auditor is trying to determine the likelihood that a particular financial statement is represented fairly or not. For example, an auditor might be evaluating the fairness of a company’s financial statements for the year. They have two hypotheses: the first is that the statements are accurate, and the second is that the statements are not accurate. The auditor gathers data from a statistical audit sample and uses this data to calculate the Bayes factor. The Bayes factor is calculated by taking the ratio of the probability of the first hypothesis (that the statements are accurate) given the observed data, to the probability of the second hypothesis (that the statements are not accurate) given the observed data. The higher the Bayes factor, the more likely it is that the first hypothesis is true. The Bayes factor can be used to assess the strength of evidence for one hypothesis over the other and to determine which hypothesis is more likely to be true given the observed data. It is often used in scientific research to help evaluate the validity of different hypotheses and to make informed decisions based on the available evidence. For auditors, the Bayes factor can be a useful tool to determine the likelihood of different hypotheses being true based on the data they have collected, and it can help them make informed decisions about the fairness of the financial statements. For example, if the Bayes factor is 5, this means that the probability of the statements being accurate given the observed data is 5 times higher than the probability of them being not accurate. In this case, the auditor would be more likely to conclude that the financial statements are accurate. The jfa package can help us to calculate Bayes factors for and against the hypothesis that the financial statements are represented fairly. "],["CHAPTER-3.html", "Chapter 3 The Audit Sampling Workflow", " Chapter 3 The Audit Sampling Workflow This chapter discusses the standard audit sampling workflow. There are several steps involved in the audit sampling workflow, and these steps are outlined below. "],["goals.html", "3.1 Goals", " 3.1 Goals The first step in the audit sampling workflow is to define the audit objective and population. The audit objective is the specific aspect of the population that the auditor wants to test. For example, the audit objective may be to test the accuracy of the sales transactions recorded in a company’s accounting records. The population is the group of transactions or records that the auditor wants to test. In this case, the population would be all of the sales transactions recorded in the accounting records. "],["planning.html", "3.2 Planning", " 3.2 Planning The next step in the audit sampling workflow is to determine the minimum required sample size and sampling method. The sample size is the number of monetary units or records that will be selected for testing. The sampling method is the method used to select the transactions or records that will be included in the sample. There are several different sampling methods that can be used, including random sampling, systematic sampling, and stratified sampling. "],["selection.html", "3.3 Selection", " 3.3 Selection Once the sample size and sampling method have been determined, the next step is to select the sample. This involves using the sampling method to select the transactions or records that will be included in the sample. For example, if a random sampling method is used, a list of all of the transactions or records in the population will be created and a random number generator will be used to select the transactions or records that will be included in the sample. "],["execution.html", "3.4 Execution", " 3.4 Execution The next step in the audit sampling workflow is to test the sample. This involves reviewing the transactions or records that were selected for the sample and testing them to determine if they are accurate. This may involve reviewing documentation, such as invoices or receipts, to verify that the transactions or records are accurate. "],["evaluation.html", "3.5 Evaluation", " 3.5 Evaluation Once the sample has been tested, the next step is to analyze the results. This involves reviewing the results of the testing and determining if the sample is representative of the population as a whole. If the sample is representative, the auditor can draw conclusions about the population based on the results of the testing. If the sample is not representative, the auditor may need to select a new sample and test it in order to draw accurate conclusions about the population. "],["reporting.html", "3.6 Reporting", " 3.6 Reporting The final step in the audit sampling workflow is to document the audit findings. This involves preparing a report that outlines the audit objective, population, sample size, sampling method, and results of the testing. The report should also include any recommendations for improvement based on the audit findings. "],["practical-example.html", "3.7 Practical Example", " 3.7 Practical Example In this example of the audit workflow, we will consider the case of BuildIt. BuildIt is a fictional construction company in the United States that is being audited by an external auditor for a fictional audit firm. At the end of the year, BuildIt has provided a summary of its financial situation in the financial statements. The objective of the auditor is to formulate an opinion about the fairness BuildIt’s financial statements. The auditor needs to obtain sufficient and appropriate evidence for the hypothesis that the misstatement in the financial statements is lower than a certain amount: the materiality. If the financial statements contain misstatements that are considered material, this means that the errors in the financial statements are large enough that they might influence the decision of stakeholders relying on these financial statements. The performance materiality is the materiality that applies to each of the populations on which the financial statements are based. For this example, the performance materiality is set at 5% of the total value of the population. In this example, we focus on the BuildIt data set that comes with the jfa package. data(&quot;BuildIt&quot;) #head(BuildIt) The population of interest consists of 3500 items, each with a booked value. Let’s assume that, before performing audit sampling, the auditor has assessed the quality of BuildIt’s internal control systems and found that they were working properly. In order to formulate an opinion about the misstatement in the population, the auditor separates their audit workflow into four stages. First, they will need to plan the minimum size of a sample they need to inspect to perform inference about the population. Second, they will need to select the required sample from the population. Third, they will need to inspect the selected sample and determine the audit (true) value of the items it contains. Fourth, they will need to use the information from the inspected sample to perform inference about the misstatement in the population. 3.7.1 Setting Up the Audit The auditor wants to make a statement that, with 95% confidence, the misstatement in the population is lower than the performance materiality of 5%. Based on last year’s audit at BuildIt, where the upper bound of the misstatement turned out to be 2.5%, they want to tolerate at most 2.5% errors in the intended sample. The auditor can therefore re-formulate their statistical statement as that they want to conclude that, when 2.5% errors are found in the sample, they can conclude with 95% confidence that the misstatement in the population is lower than the performance materiality of 5%. Below, the auditor defines the performance materiality, confidence level, and expected misstatements in the sample. # Specify the confidence, materiality, and expected errors. confidence &lt;- 0.95 # 95% materiality &lt;- 0.05 # 5% expected &lt;- 0.025 # 2.5% Many audits are performed according to the audit risk model (ARM), which determines that the uncertainty about the auditor’s statement as a whole (1 - the confidence) is a factor of three terms: the inherent risk, the control risk, and the detection risk. Inherent risk is the risk posed by an error in BuildIt’s financial statement that could be material, before consideration of any related control systems (e.g., computer systems). Control risk is the risk that a material misstatement is not prevented or detected by BuildIt’s internal control systems. Detection risk is the risk that the auditor will fail to find material misstatements that exist in an BuildIt’s financial statements. The ARM is practically useful because for a given level of audit risk, the tolerable detection risk bears an inverse relation to the other two risks. The ARM is useful for the auditor because it enables them to incorporate existing information on BuildIt’s organization to increase the required risk that they will fail to find a material misstatement. \\[ \\text{Audit risk} = \\text{Inherent risk} \\,\\times\\, \\text{Control risk} \\,\\times\\, \\text{Detection risk}\\] Usually the auditor judges inherent risk and control risk on a three-point scale consisting of low, medium, and high. Different audit firms handle different standard percentages for these categories. The auditor’s firm defines the probabilities of low, medium, and high respectively as 50%, 60%, and 100%. Because the auditor assessed BuildIt’s internal control systems, they assess the control risk as medium (60%). # Specify the inherent risk (ir) and control risk (cr). ir &lt;- 1 # 100% cr &lt;- 0.6 # 60% 3.7.2 Planning an Audit Sample The auditor can choose to either perform a frequentist analysis, where they use the increased detection risk as their level of uncertainty, or perform a Bayesian analysis, where they incorporate the information about the control risk into a prior distribution. For this example, we will show how to perform a Bayesian analysis. A frequentist analysis can easily be done through the following functions by setting prior = FALSE. In a frequentist analysis, the auditor immediately uses the adjusted confidence to calculate the sample size via the planning() function. # Adjust the required confidence for a frequentist analysis. c.adj &lt;- 1 - ((1 - confidence) / (ir * cr)) # Step 1: Calculate the required sample size. stage1 &lt;- planning(materiality = materiality, expected = expected, conf.level = c.adj) The auditor can then inspect the result from the planning procedure by using the summary() function. The result shows that the auditor needs to select a sample of 178 items so that, when at most 4.45 misstatements are found, they can conclude with 91.66% confidence that the misstatement in BuildIt’s population is lower than the performance materiality of 5%. summary(stage1) # # Classical Audit Sample Planning Summary # # Options: # Confidence level: 0.91667 # Materiality: 0.05 # Hypotheses: H₀: Θ &gt;= 0.05 vs. H₁: Θ &lt; 0.05 # Expected: 0.025 # Likelihood: poisson # # Results: # Minimum sample size: 178 # Tolerable errors: 4.45 # Expected most likely error: 0.025 # Expected upper bound: 0.049986 # Expected precision: 0.024986 # Expected p-value: 0.083211 3.7.3 Selecting a Sample The auditor is now ready to select the required 178 items from the population. They can choose to do this according to one of two statistical methods. In record sampling (units = \"items\"), inclusion probabilities are assigned on the item level, treating item with a high value and a low value the same, an item of $5,000 is equally likely to be selected as an item of $1,000. In monetary unit sampling (units = \"values\"), inclusion probabilities are assigned on the level of individual monetary units (e.g., a dollar). When a dollar is selected to be in the sample, the item that includes that dollar is selected. This favors items with a higher value, as an item with a value of $5,000 is now five times more likely to be selected than an item with a value of $1,000. The auditor chooses to use monetary unit sampling, as they wants to include more high-valued items. The selection() function enables them to select the sample from the population. She uses the stage1 object as an input for the selection() function, since this passes the calculated sample size to the function. # Step 2: Draw a sample from the financial statements. stage2 &lt;- selection(data = BuildIt, size = stage1, units = &quot;values&quot;, values = &quot;bookValue&quot;, method = &quot;interval&quot;) Like before, the auditor can inspect the outcomes of their sampling procedure by using the summary() function. summary(stage2) # # Audit Sample Selection Summary # # Options: # Requested sample size: 178 # Sampling units: monetary units # Method: fixed interval sampling # Starting point: 1 # # Data: # Population size: 3500 # Population value: 1403221 # Selection interval: 7883.3 # # Results: # Selected sampling units: 178 # Proportion of value: 0.062843 # Selected items: 178 # Proportion of size: 0.050857 3.7.4 Performing the Audit The selected sample can be isolated by indexing the sample object from the sampling result. # Step 3: Isolate the sample for execution of the audit. sample &lt;- stage2$sample Next, the auditor can execute the audit by annotating the items in the sample with their audit values (for exampling by writing the sample to a .csv file using write.csv(). They can then load the annotated sample back into the R session for further evaluation. For this example, the audit values of the sample items are already included in the auditValue column of the data set. # To write the sample to a .csv file: write.csv(x = sample, file = &quot;auditSample.csv&quot;, row.names = FALSE) # To load annotated sample back into R: sample &lt;- read.csv(file = &quot;auditSample.csv&quot;) 3.7.5 Evaluating the Sample Using the annotated sample, the auditor can perform inference about the misstatement in the population via the evaluation() function. # Step 4: Evaluate the sample stage4 &lt;- evaluation( materiality = materiality, conf.level = c.adj, data = sample, values = &quot;bookValue&quot;, values.audit = &quot;auditValue&quot; ) The auditor can inspect the outcomes of her inference by using the summary() function. The resulting 91.66% upper bound is 1.396%, which is lower than the performance materiality of 5%. summary(stage4) # # Classical Audit Sample Evaluation Summary # # Options: # Confidence level: 0.91667 # Materiality: 0.05 # Hypotheses: H₀: Θ &gt;= 0.05 vs. H₁: Θ &lt; 0.05 # Method: poisson # # Data: # Sample size: 178 # Number of errors: 0 # Sum of taints: 0 # # Results: # Most likely error: 0 # 91.66667 percent confidence interval: [0, 0.01396] # Precision: 0.01396 # p-value: 0.00013639 3.7.6 Making a Decision Since the 91.66% upper confidence bound on the misstatement in population is lower than the performance materiality, the auditor has obtained sufficient evidence to conclude that the population does not contain material misstatements. The auditor can create a html or pdf report of the statistical results using the report() function, as shown below. report(stage4, file = &quot;report.html&quot;) "],["CHAPTER-4.html", "Chapter 4 Planning a Sample", " Chapter 4 Planning a Sample One of the key considerations in audit sampling is determining the minimum sample size required to achieve a desired level of assurance or precision. In this chapter, we will discuss how to use three standard likelihoods to plan a minimum sample size for audit sampling: the hypergeometric likelihood, the binomial likelihood and the Poisson likelihood. Before we dive into the details of computing a minimum sample size for audit sampling using any of the three likelihoods, it is important to review some key concepts and notation. Let’s start by defining the population and the sample. The population is the group of items or transactions being audited, and the sample is the subset of the population that is selected for testing. The population size is denoted by \\(N\\), and the sample size is denoted by \\(n\\). Next, we need to define the maximum tolerable error or precision level that we want to achieve in our audit. This is typically expressed as a maximum allowable misstatement rate, denoted by \\(\\theta_{max}\\). For example, if we set \\(\\theta_{max}\\) to 0.05, it means that we want to ensure that the misstatement rate in the population does not exceed 5%. "],["required-information.html", "4.1 Required Information", " 4.1 Required Information First, planning a minimum sample requires knowledge of the conditions that lead to acceptance or rejection of the population (i.e., the sampling objectives). Typically, sampling objectives can be classified into one or both of the following: Hypothesis testing: The goal of the sample is to obtain evidence for or against the claim that the misstatement in the population is lower than a given value (i.e., the performance materiality). Estimation: The goal of the sample is to obtain an accurate estimate of the misstatement in the population (with a minimum precision). Second, it is advised to specify the expected (or tolerable) misstatements in the sample. The expected misstatements are the misstatements that you allow in the sample, while still retaining the desired amount of assurance about the population. It is strongly recommended to set the value for the expected misstatements in the sample conservatively to minimize the chance of the observed misstatements in the sample exceeding the expected misstatements, which would imply that insufficient work has been done in the end. Finally, next to determining the sampling objective(s) and the expected misstatements, it is important to determine the statistical distribution linking the sample outcomes to the population misstatement. This distribution is called the likelihood (i.e., poisson, binomial, orhypergeometric). All three aforementioned likelihoods are commonly used in an audit sampling context, however, poisson is the default likelihood in jfa because it is the most conservative of the three. In the subsections below, we elaborate on the three standard likelihoods for audit sampling and demonstrate how they can be used to obtain a minimum sample size. "],["the-hypergeometric-likelihood.html", "4.2 The Hypergeometric Likelihood", " 4.2 The Hypergeometric Likelihood Let’s consider how to use the hypergeometric likelihood to calculate the minimum sample size needed to achieve a desired level of assurance. The hypergeometric distribution is a discrete probability distribution that is commonly used to model the number of events occurring in a fixed number of trials when the population size is known. For our purpose, we can use the hypergeometric distribution as a likelihood to model the number of misstatements that are expected to be found in the sample. The probability mass function (PMF) of the hypergeometric distribution is given by: \\[p(X=x)=\\frac{\\binom{K}{x}\\binom{N-K}{n-x}}{\\binom{N}{n}},\\] where \\(x\\) is the number of misstatements in the sample, \\(n\\) is the sample size, \\(N\\) is the population size and \\(K\\) is the total number of misstatements assumed in the population. The assumed misstatements \\(K\\) is a linear extrapolation of the assumed misstatement rate in the population \\(\\theta_{max}\\) to the total population: \\[K = \\theta_{max} N.\\] 4.2.1 Classical planning Given a desired misstatement tolerance \\(\\theta_{max}\\), we can solve for the minimum sample size \\(n\\) needed to achieve this assurance level. In jfa, this sample size can be calculated using the planning() function. For example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a maximum tolerable misstatement rate of 3% in a population of \\(N=1000\\), then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 94\\). planning(materiality = 0.03, expected = 0, conf.level = 0.95, likelihood = &quot;hypergeometric&quot;, N.units = 1000) # # Classical Audit Sample Planning # # minimum sample size = 94 # sample size obtained in 95 iterations via method &#39;hypergeometric&#39; As another example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a maximum tolerable misstatement rate of 3% in a population of \\(N=1000\\), then the required sample size under the assumption of one expected misstatement in the sample is \\(n = 147\\). planning(materiality = 0.03, expected = 1, conf.level = 0.95, likelihood = &quot;hypergeometric&quot;, N.units = 1000) # # Classical Audit Sample Planning # # minimum sample size = 147 # sample size obtained in 146 iterations via method &#39;hypergeometric&#39; 4.2.2 Bayesian Planning Performing Bayesian planning with the hypergeometric likelihood requires that you specify a prior distribution for the parameter \\(\\theta\\). Practically, this means that you should provide an input for the prior argument in the planning() function. Setting prior = TRUE performs Bayesian planning using a default prior conjugate to the specified likelihood (i.e., a beta prior). For example, the command below uses a default beta(1, 1) prior distribution to plan the sample, since planning() is given the binomial likelihood. If we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a maximum tolerable misstatement rate of 3% in a population of \\(N=1000\\), then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 93\\). plan &lt;- planning(materiality = 0.03, expected = 0, conf.level = 0.95, likelihood = &quot;hypergeometric&quot;, N.units = 1000, prior = TRUE) summary(plan) # # Bayesian Audit Sample Planning Summary # # Options: # Confidence level: 0.95 # Population size: 1000 # Materiality: 0.03 # Hypotheses: H₀: Θ &gt; 0.03 vs. H₁: Θ &lt; 0.03 # Expected: 0 # Likelihood: hypergeometric # Prior distribution: beta-binomial(N = 1000, α = 1, β = 1) # # Results: # Minimum sample size: 93 # Tolerable errors: 0 # Posterior distribution: beta-binomial(N = 907, α = 1, β = 94) # Expected most likely error: 0 # Expected upper bound: 0.029 # Expected precision: 0.029 # Expected BF₁₀: 620.58 You can inspect how the prior distribution compares to the expected posterior distribution by using the plot() function. The expected posterior distribution is the posterior distribution that would occur if you actually observed the planned sample containing the expected misstatements. plot(plan) "],["the-binomial-likelihood.html", "4.3 The Binomial Likelihood", " 4.3 The Binomial Likelihood Let’s consider how to use the binomial likelihood to calculate the minimum sample size needed to achieve a desired level of assurance. The binomial distribution is a discrete probability distribution that is commonly used to model the number of events occurring in a fixed number of trials. For our purpose, we can use the binomial distribution as a likelihood to model the number of misstatements that are expected to be found in the sample. In audit sampling, the binomial likelihood is often used to approximate the hypergeometric likelihood since it is easier to work with (i.e., it only has two parameters: \\(\\theta\\) and \\(n\\), while the hypergeometric has three: \\(n\\), \\(N\\), and \\(K\\)). However, the binomial likelihood is more conservative than the hypergeometric likelihood, meaning that resulting sample sizes will be higher. The probability mass function (PMF) of the binomial distribution is given by: \\[p(x; n, \\theta) = \\binom{n, x} \\theta^{x} (1-\\theta)^{n - x},\\] where \\(x\\) is the number of misstatements in the sample, \\(n\\) is the sample size and \\(\\theta\\) is the misstatement rate expected in the sample. 4.3.1 Classical Planning Concretely, the following statistical model is assumed: \\[x \\sim \\text{Binomial}(n, \\theta_{max})\\] Given a desired misstatement tolerance \\(\\theta_{max}\\), we can solve for the minimum sample size \\(n\\) needed to achieve the desired assurance level. A useful trick to utilize is that, if we do not expect any misstatements in the sample, the formula for the minimum required sample size reduces to: \\[n = \\lceil\\frac{\\ln(\\alpha)}{\\ln(1 - \\theta_{max})}\\rceil.\\] \\(\\lceil...\\rceil\\) is the ceiling function. Hence, \\(\\lceil1.2\\rceil = 2\\). For example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a maximum tolerable misstatement rate of 3%, then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 99\\). ceiling(log(1 - 0.95) / log(1 - 0.03)) # [1] 99 In jfa, this sample size can be replicated using the planning() function. planning(materiality = 0.03, expected = 0, conf.level = 0.95, likelihood = &quot;binomial&quot;) # # Classical Audit Sample Planning # # minimum sample size = 99 # sample size obtained in 100 iterations via method &#39;binomial&#39; However, if the number of expected misstatements in the sample is non-zero, it becomes more difficult to solve the formula for \\(n\\). Hence, we can iteratively try every value of \\(n\\) and return the smallest integer that satisfies the sampling objectives. In jfa, this can be done by adjusting the expected argument in the planning() function. For example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a maximum tolerable misstatement rate of 3%, then the required sample size under the assumption of one expected misstatement in the sample is \\(n = 157\\). planning(materiality = 0.03, expected = 1, conf.level = 0.95, likelihood = &quot;binomial&quot;) # # Classical Audit Sample Planning # # minimum sample size = 157 # sample size obtained in 156 iterations via method &#39;binomial&#39; 4.3.2 Bayesian Planning Performing Bayesian planning with the binomial likelihood requires that you specify a prior distribution for the parameter \\(\\theta\\). Practically, this means that you should provide an input for the prior argument in the planning() function. Setting prior = TRUE performs Bayesian planning using a default prior conjugate to the specified likelihood (i.e., a beta prior). Concretely, this means that the following statistical model is assumed: \\[x \\sim \\text{Binomial}(n, \\theta)\\] \\[\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\] For example, the command below uses a default beta(\\(\\alpha=1\\), \\(\\beta=1\\)) prior distribution to plan the sample, since planning() is given the binomial likelihood. If we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a maximum tolerable misstatement rate of 3%, then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 98\\). plan &lt;- planning(materiality = 0.03, expected = 0, conf.level = 0.95, likelihood = &quot;binomial&quot;, prior = TRUE) summary(plan) # # Bayesian Audit Sample Planning Summary # # Options: # Confidence level: 0.95 # Materiality: 0.03 # Hypotheses: H₀: Θ &gt; 0.03 vs. H₁: Θ &lt; 0.03 # Expected: 0 # Likelihood: binomial # Prior distribution: beta(α = 1, β = 1) # # Results: # Minimum sample size: 98 # Tolerable errors: 0 # Posterior distribution: beta(α = 1, β = 99) # Expected most likely error: 0 # Expected upper bound: 0.029807 # Expected precision: 0.029807 # Expected BF₁₀: 627.22 You can inspect how the prior distribution compares to the expected posterior distribution by using the plot() function. The expected posterior distribution is the posterior distribution that would occur if you actually observed the planned sample containing the expected misstatements. plot(plan) The input for the prior argument can also be an object created by the auditPrior function. If planning() receives a prior for which there is no conjugate likelihood available, it will numerically derive the posterior distribution. For example, the command below uses a Normal(0, 0.05) prior distribution to plan the sample using the binomial likelihood. Concretely, this means that the following statistical model is assumed: \\[x \\sim \\text{Binomial}(n, \\theta)\\] \\[\\theta \\sim \\text{Normal}(\\mu = 0, \\sigma = 0.05)\\] prior &lt;- auditPrior(method = &quot;param&quot;, likelihood = &quot;normal&quot;, alpha = 0, beta = 0.05) plan &lt;- planning(materiality = 0.03, expected = 0, conf.level = 0.95, likelihood = &quot;poisson&quot;, prior = prior) summary(plan) # # Bayesian Audit Sample Planning Summary # # Options: # Confidence level: 0.95 # Materiality: 0.03 # Hypotheses: H₀: Θ &gt; 0.03 vs. H₁: Θ &lt; 0.03 # Expected: 0 # Likelihood: poisson # Prior distribution: normal(μ = 0, σ = 0.05)T[0,1] # # Results: # Minimum sample size: 90 # Tolerable errors: 0 # Posterior distribution: Determined via MCMC sampling # Expected most likely error: 0.0008648 # Expected upper bound: 0.029029 # Expected precision: 0.028164 # Expected BF₁₀: 19.08 The resulting sample size under this prior is \\(n = 90\\), a reduction of 8 samples when compared to the default beta(1, 1) prior distribution. plot(plan) "],["the-poisson-likelihood.html", "4.4 The Poisson Likelihood", " 4.4 The Poisson Likelihood Let’s consider how to use the Poisson likelihood to calculate the minimum sample size needed to achieve a desired level of assurance. The Poisson distribution is a discrete probability distribution that is commonly used to model the number of events occurring in a fixed time or space. We can use the Poisson distribution as a likelihood to model the number of misstatements that are expected to be found in the sample. In audit sampling, the Poisson likelihood is often used to approximate the binomial likelihood since it is easier to work with (i.e., it only has one parameter: \\(\\lambda\\), while the binomial has two parameters: \\(\\theta\\) and \\(n\\)). However, the Poisson likelihood is more conservative than the binomial likeliood, meaning that resulting sample sizes will be higher. The probability mass function (PMF) of the Poisson distribution is given by: \\[p(x;\\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!},\\] where \\(x\\) is the number of misstatements in the sample, and \\(\\lambda\\) is the average number of misstatements expected in the sample. The average number of misstatements is related to the misstatement rate in the population, denoted by \\(\\theta\\), and the sample size, \\(n\\), by the following equation: \\[\\lambda=n\\theta.\\] 4.4.1 Classical planning Concretely, the following statistical model is assumed: \\[x \\sim \\text{Poisson}(n\\theta_{max})\\] Given a desired misstatement tolerance \\(\\theta_{max}\\) and the Poisson likelihood, we can solve for the minimum sample size \\(n\\) needed to achieve a assurance level. A useful trick to utilize is that, if we do not expect any misstatements in the sample, the formula for the required sample size reduces to: \\[n = \\lceil-\\frac{\\ln(\\alpha)}{\\theta_{max}}\\rceil.\\] \\(\\lceil...\\rceil\\) is the ceiling function. Hence, \\(\\lceil1.2\\rceil = 2\\). For example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a maximum tolerable misstatement rate of 3%, then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 100\\). ceiling(-log(1 - 0.95) / 0.03) # [1] 100 In jfa, this sample size can be replicated using the planning() function. planning(materiality = 0.03, expected = 0, conf.level = 0.95, likelihood = &quot;poisson&quot;) # # Classical Audit Sample Planning # # minimum sample size = 100 # sample size obtained in 101 iterations via method &#39;poisson&#39; However, if the number of expected misstatements in the sample is non-zero, it becomes more difficult to solve the formula for \\(n\\). Hence, we can iteratively try every value of \\(n\\) and return the smallest integer that satisfies the sampling objectives. In jfa, this can be done by adjusting the expected argument in the planning() function. For example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a maximum tolerable misstatement rate of 3%, then the required sample size under the assumption of one expected misstatement in the sample is \\(n = 159\\). planning(materiality = 0.03, expected = 1, conf.level = 0.95, likelihood = &quot;poisson&quot;) # # Classical Audit Sample Planning # # minimum sample size = 159 # sample size obtained in 158 iterations via method &#39;poisson&#39; 4.4.2 Bayesian Planning Performing Bayesian planning with the Poisson likelihood requires that you specify a prior distribution for the parameter \\(\\theta\\). Practically, this means that you should provide an input for the prior argument in the planning() function. Setting prior = TRUE performs Bayesian planning using a default prior conjugate to the specified likelihood (i.e., a gamma prior). Concretely, this means that the following statistical model is assumed: \\[x \\sim \\text{Poisson}(n\\theta)\\] \\[\\theta \\sim \\text{Gamma}(\\alpha, \\beta)\\] For example, the command below uses a default gamma(\\(\\alpha=1\\), \\(\\beta=1\\)) prior distribution to plan the sample, since planning() is given the Poisson likelihood. If we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a maximum tolerable misstatement rate of 3%, then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 99\\). plan &lt;- planning(materiality = 0.03, expected = 0, conf.level = 0.95, likelihood = &quot;poisson&quot;, prior = TRUE) summary(plan) # # Bayesian Audit Sample Planning Summary # # Options: # Confidence level: 0.95 # Materiality: 0.03 # Hypotheses: H₀: Θ &gt; 0.03 vs. H₁: Θ &lt; 0.03 # Expected: 0 # Likelihood: poisson # Prior distribution: gamma(α = 1, β = 1) # # Results: # Minimum sample size: 99 # Tolerable errors: 0 # Posterior distribution: gamma(α = 1, β = 100) # Expected most likely error: 0 # Expected upper bound: 0.029957 # Expected precision: 0.029957 # Expected BF₁₀: 626.69 You can inspect how the prior distribution compares to the expected posterior distribution by using the plot() function. The expected posterior distribution is the posterior distribution that would occur if you actually observed the planned sample containing the expected misstatements. plot(plan) The input for the prior argument can also be an object created by the auditPrior function. If planning() receives a prior for which there is no conjugate likelihood available, it will numerically derive the posterior distribution. For example, the command below uses a Normal(0, 0.05) prior distribution to plan the sample using the Poisson likelihood. Concretely, this means that the following statistical model is assumed: \\[x \\sim \\text{Poisson}(n\\theta)\\] \\[\\theta \\sim \\text{Normal}(\\mu = 0, \\sigma = 0.05)\\] prior &lt;- auditPrior(method = &quot;param&quot;, likelihood = &quot;normal&quot;, alpha = 0, beta = 0.05) plan &lt;- planning(materiality = 0.03, expected = 0, conf.level = 0.95, likelihood = &quot;poisson&quot;, prior = prior) summary(plan) # # Bayesian Audit Sample Planning Summary # # Options: # Confidence level: 0.95 # Materiality: 0.03 # Hypotheses: H₀: Θ &gt; 0.03 vs. H₁: Θ &lt; 0.03 # Expected: 0 # Likelihood: poisson # Prior distribution: normal(μ = 0, σ = 0.05)T[0,1] # # Results: # Minimum sample size: 91 # Tolerable errors: 0 # Posterior distribution: Determined via MCMC sampling # Expected most likely error: 0.0010232 # Expected upper bound: 0.029029 # Expected precision: 0.028006 # Expected BF₁₀: 19.296 The resulting sample size under this prior is \\(n = 91\\), a reduction of 8 samples when compared to the default gamma(1, 1) prior. plot(plan) "],["CHAPTER-5.html", "Chapter 5 Selecting a Sample", " Chapter 5 Selecting a Sample This chapter outlines the most commonly used sampling methodology for auditing and shows how to select a sample using these methods with the jfa package. Auditors are often required to assess balances or processes that involve a large number of items. Since they cannot inspect all of these items individually, they need to select a subset (i.e., a sample) from the total population to make a statement about a certain characteristic of the population. For this purpose, various selection methodologies are available that have become standard in an audit context. "],["sampling-units.html", "5.1 Sampling Units", " 5.1 Sampling Units Selecting a subset from the population requires knowledge of the sampling units; physical representations of the population that needs to be audited. Generally, the auditor has to choose between two types of sampling units: individual items in the population or individual monetary units in the population. In order to perform statistical selection, the population must be divided into individual sampling units that can be assigned a probability to be included in the sample. The total collection of all sampling units which have been assigned a selection probability is called the sampling frame. 5.1.1 Items A sampling unit for record (i.e., attributes) sampling is generally a characteristic of an item in the population. For example, suppose that you inspect a population of receipts. A possible sampling unit for record sampling can be the date of payment of the receipt. When a sampling unit (e.g., date of payment) is selected by the sampling method, the population item that corresponds to the sampled unit is included in the sample. 5.1.2 Monetary Units A sampling unit for monetary unit sampling is different than a sampling unit for record sampling in that it is an individual monetary unit within an item or transaction, like an individual dollar. For example, a single sampling unit can be the 10\\(^{th}\\) dollar from a specific receipt in the population. When a sampling unit (e.g., individual dollar) is selected by the sampling method, the population item that includes the sampling unit is included in the sample. "],["sampling-methods.html", "5.2 Sampling Methods", " 5.2 Sampling Methods This section discusses the four sampling methods implemented in jfa. First, for notation, let the the population \\(N\\) be defined as the total set of individual sampling units \\(x_i\\). \\[N = \\{x_1, x_2, \\dots, x_N\\}.\\] In statistical sampling, every sampling unit \\(x_i\\) in the population must receive a selection probability \\(p(x_i)\\). The purpose of the sampling method is to provide a framework to assign selection probabilities to each of the sampling units, and subsequently draw sampling units from the population until a set of size \\(n\\) has been created. The next section discusses which sampling methods are available in jfa. To illustrate the outcomes for different sampling methods, we will use the BuildIt data set that can be loaded using the code below. data(BuildIt) 5.2.1 Fixed Interval Sampling Fixed interval sampling is a method designed for yielding representative samples from monetary populations. The algorithm determines a uniform interval on the (optionally ranked) sampling units. Next, a starting point is handpicked or randomly selected in the first interval and a sampling unit is selected throughout the population at each of the uniform intervals from the starting point. For example, if the interval has a width of 10 sampling units and sampling unit number 5 is chosen as the starting point, the sampling units 5, 15, 25, etc. are selected to be included in the sample. The number of required intervals \\(I\\) can be determined by dividing the number of sampling units in the population by the required sample size: \\[I = \\frac{N}{n},\\] in which \\(n\\) is the required sample size and \\(N\\) is the total number of sampling units in the population. If the space between the selected sampling units is equal, the selection probability for each sampling unit is theoretically defined as: \\[p(x) = \\frac{1}{I},\\] with the property that the space between selected units \\(i\\) is the same as the interval \\(I\\), see Figure 1. However, in practice the selection is deterministic and completely depends on the chosen starting points (using start). Figure 5.1: Illustration of fixed interval sampling The fixed interval method yields a sample that allows every sampling unit in the population an equal chance of being selected. However, the fixed interval method has the property that all items in the population with a monetary value larger than the interval \\(I\\) have an selection probability of one because one of these items’ sampling units are always selected from the interval. Note that, if the population is arranged randomly with respect to its deviation pattern, fixed interval sampling is equivalent to random selection. Advantage(s): The advantage of the fixed interval sampling method is that it is often simple to understand and fast to perform. Another advantage is that, in monetary unit sampling, all items that are greater than the calculated interval will be included in the sample. In record sampling, since units can be ranked on the basis of value, there is also a guarantee that some large items will be in the sample. Disadvantage(s): A pattern in the population can coincide with the selected interval, rendering the sample less representative. What is sometimes seen as an added complication for this method is that the sample is hard to extend after drawing the initial sample. This is due to the chance of selecting the same sampling unit. However, by removing the already selected sampling units from the population and redrawing the intervals this problem can be efficiently solved. As an example, the code below shows how to apply the fixed interval sampling method in a record sampling and a monetary unit sampling setting. Note that, by default, the first sampling unit from each interval is selected. However, this can be changed by setting the argument start = 1 to a different value. # Record sampling sample &lt;- selection(data = BuildIt, size = 100, units = &quot;items&quot;, method = &quot;interval&quot;, start = 1) #head(sample$sample, n = 6) # Monetary unit sampling sample &lt;- selection(data = BuildIt, size = 100, units = &quot;values&quot;, method = &quot;interval&quot;, values = &quot;bookValue&quot;, start = 1) #head(sample$sample, n = 6) 5.2.2 Cell Sampling The cell sampling method divides the (optionally ranked) population into a set of intervals \\(I\\) that are computed through the previously given equations. Within each interval, a sampling unit is selected by randomly drawing a number between 1 and the interval range \\(I\\). This causes the space \\(i\\) between the sampling units to vary. Like in the fixed interval sampling method, the selection probability for each sampling unit is defined as: \\[p(x) = \\frac{1}{I}.\\] Figure 5.2: Illustration of cell sampling The cell sampling method has the property that all items in the population with a monetary value larger than twice the interval \\(I\\) have a selection probability of one. Advantage(s): More sets of samples are possible than in fixed interval sampling, as there is no systematic interval \\(i\\) to determine the selections. It is argued that the cell sampling algorithm offers a solution to the pattern problem in fixed interval sampling. Disadvantage(s): A disadvantage of this sampling method is that not all items in the population with a monetary value larger than the interval have a selection probability of one. Besides, population items can be in two adjacent cells, thereby creating the possibility that an items is included in the sample twice. As an example, the code below shows how to apply the cell sampling method in a record sampling and a monetary unit sampling setting. It is important to set a seed to make the results reproducible. # Record sampling set.seed(1) sample &lt;- selection(data = BuildIt, size = 100, units = &quot;items&quot;, method = &quot;cell&quot;) #head(sample$sample, n = 6) # Monetary unit sampling set.seed(1) sample &lt;- selection(data = BuildIt, size = 100, units = &quot;values&quot;, method = &quot;cell&quot;, values = &quot;bookValue&quot;) #head(sample$sample, n = 6) 5.2.3 Random Sampling Random sampling is the most simple and straight-forward selection method The random sampling method provides a method that allows every sampling unit in the population an equal chance of being selected, meaning that every combination of sampling units has the same probability of being selected as every other combination of the same number of sampling units. Simply put, the algorithm draws a random selection of size \\(n\\) of the sampling units. Therefore, the selection probability for each sampling unit is defined as: \\[p(x) = \\frac{1}{N},\\] where \\(N\\) is the number of units in the population. To clarify this procedure, Figure 3 provides an illustration of the random sampling method. Figure 5.3: Illustration of random sampling Advantage(s): The random sampling method yields an optimal random selection, with the additional advantage that the sample can be easily extended by applying the same method again. Disadvantages: Because the selection probabilities are equal for all sampling units there is no guarantee that items with a large monetary value in the population will be included in the sample. As an example, the code below shows how to apply the random sampling (with our without replacement using replace) method in a record sampling and a monetary unit sampling setting. It is important to set a seed to make results reproducible. # Record sampling set.seed(1) sample &lt;- selection(data = BuildIt, size = 100, units = &quot;items&quot;, method = &quot;random&quot;) #head(sample$sample, n = 6) # Monetary unit sampling set.seed(1) sample &lt;- selection(data = BuildIt, size = 100, units = &quot;values&quot;, method = &quot;random&quot;, values = &quot;bookValue&quot;) #head(sample$sample, n = 6) 5.2.4 Modified Sieve Sampling The fourth option for the sampling method is modified sieve sampling (Hoogduin, Hall, &amp; Tsay, 2010). The algorithm starts by selecting a standard uniform random number \\(R_i\\) between 0 and 1 for each item in the population. Next, the sieve ratio: \\[S_i = \\frac{Y_i}{R_i}\\] is computed for each item by dividing the book value of that item by the random number. Lastly, the items in the population are sorted by their sieve ratio \\(S\\) (in decreasing order) and the top \\(n\\) items are selected for inspection. In contrast to the classical sieve sampling method (Rietveld, 1978), the modified sieve sampling method provides precise control over sample sizes. As an example, the code below shows how to apply the modified sieve sampling method in a monetary unit sampling setting. It is important to set a seed to make results reproducible. # Monetary unit sampling set.seed(1) sample &lt;- selection(data = BuildIt, size = 100, units = &quot;values&quot;, method = &quot;sieve&quot;, values = &quot;bookValue&quot;) #head(sample$sample, n = 6) "],["ordering-or-randomizing-the-population.html", "5.3 Ordering or Randomizing the Population", " 5.3 Ordering or Randomizing the Population The selection() function has additional arguments (order, decreasing, and randomize) to preprocess your population before selection. The order argument takes as input a column name in data which determines the order of the population. For example, you can order the population from lowest book value to highest book value before engaging in selection. In this case, you should use the decreasing = FALSE argument. # Ordering population from lowest &#39;bookValue&#39; to highest &#39;bookValue&#39; before MUS set.seed(1) sample &lt;- selection( data = BuildIt, size = 100, units = &quot;values&quot;, values = &quot;bookValue&quot;, order = &quot;bookValue&quot;, decreasing = FALSE ) #head(sample$sample, n = 6) The randomize argument can be used to randomly shuffle the items in the population before selection. # Randomly shuffle population items before MUS set.seed(1) sample &lt;- selection( data = BuildIt, size = 100, units = &quot;values&quot;, values = &quot;bookValue&quot;, randomize = TRUE ) #head(sample$sample, n = 6) "],["CHAPTER-6.html", "Chapter 6 Evaluating an Unstratified Sample", " Chapter 6 Evaluating an Unstratified Sample A non-stratified audit sample does not involve dividing the population into subgroups. Here, the auditor selects a random sample from the entire population without considering any specific characteristics of the population. For example, in an audit of a company’s inventory, the auditor may simply select a random sample of items from the entire inventory without dividing it into subgroups based on characteristics such as location or type of item. Another example of such a situation would be where the auditor is auditing the general ledger of a small business. Naturally, non-stratified sampling is simpler than stratified sampling and can be used when the population is considered homogenous or the auditor does not need to consider differences between subgroups (e.g., strata). "],["classical-evaluation.html", "6.1 Classical Evaluation", " 6.1 Classical Evaluation Classical hypothesis testing uses the p-value to make a decision about whether to reject the hypothesis \\(H_0\\) or not. As an example, consider that an auditor wants to verify whether the population contains less than 5 percent misstatement, implying the hypotheses \\(H_1:\\theta&lt;0.05\\) and \\(H_0:\\theta\\geq0.05\\). They have taken a sample of 100 items, of which 1 contained an error. They set the significance level for the p-value to 0.05, implying that \\(p &lt; 0.05\\) will be enough to reject the hypothesis \\(H_0\\). The call below evaluates the sample using a classical non-stratified evaluation procedure. evaluation(materiality = 0.05, x = 1, n = 100) # # Classical Audit Sample Evaluation # # data: 1 and 100 # number of errors = 1, number of samples = 100, taint = 1, p-value = # 0.040428 # alternative hypothesis: true misstatement rate is less than 0.05 # 95 percent confidence interval: # 0.00000000 0.04743865 # most likely estimate: # 0.01 # results obtained via method &#39;poisson&#39; The output shows that the most likely error in the population is estimated to be 1 / 100 = 1% and that the 95% (one-sided) confidence interval ranges from 0% to 4.74%. The output also shows that the p-value is lower than 0.05 implying that the hypothesis \\(H_0\\) can be rejected. Hence, the auditor is able to conclude that the sample provides sufficient evidence to state with reasonable assurance that the population does not contain material misstatement. "],["bayesian-evaluation.html", "6.2 Bayesian Evaluation", " 6.2 Bayesian Evaluation Bayesian hypothesis testing uses the Bayes factor, \\(BF_{10}\\) or \\(BF_{01}\\), to make a statement about the evidence provided by the sample in support for one of the two hypotheses \\(H_1\\) or \\(H_0\\). As an example of how to interpret the Bayes factor, the value of \\(BF_{10} = 10\\) (provided by the evaluation() function) can be interpreted as: the data are 10 times more likely to have occurred underthe hypothesis \\(H_1\\) than under the hypothesis \\(H_0\\). \\(BF_{10} &gt; 1\\) indicates evidence in favor of \\(H_1\\) and against \\(H_0\\), while \\(BF_{10} &lt; 1\\) indicates evidence in favor of \\(H_0\\) and against \\(H_1\\). The evaluation() function returns the value for \\(BF_{10}\\), but \\(BF_{01}\\) can be computed as \\(\\frac{1}{BF_{10}}\\). Consider the previous example of an auditor who wants to verify whether the population contains less than 5 percent misstatement, implying the hypotheses \\(H_1:\\theta&lt;0.05\\) and \\(H_0:\\theta\\geq0.05\\). They have taken a sample of 100 items, of which 1 was found to contain a misstatement. The prior distribution is assumed to be a default beta(1,1) prior. The call below evaluates the sample using a Bayesian non-stratified evaluation procedure. prior &lt;- auditPrior(materiality = 0.05, method = &quot;default&quot;, likelihood = &quot;binomial&quot;) evaluation(materiality = 0.05, x = 1, n = 100, prior = prior) # # Bayesian Audit Sample Evaluation # # data: 1 and 100 # number of errors = 1, number of samples = 100, taint = 1, BF₁₀ = # 515.86 # alternative hypothesis: true misstatement rate is less than 0.05 # 95 percent credible interval: # 0.00000000 0.04610735 # most likely estimate: # 0.01 # results obtained via method &#39;binomial&#39; + &#39;prior&#39; The output shows that the most likely error in the population is estimated to be 1 / 100 = 1% and that the 95% (one-sided) credible interval ranges from 0% to 4.61%. The small difference between the classical and default Bayesian results is due to the prior distribution, which must be proper in order to calculate a Bayes factor (classical results can be emulated by constructing a prior with method = \"strict\" in the auditPrior() function). The Bayes factor in this case is shown to be \\(BF_{10}=515\\), meaning that the data from the sample are about 515 times more likely to occur under the hypothesis of tolerable misstatement than under the hypothesis of material misstatement. Note that this is a very high Bayes factor for the little data that is observed. That is because the Bayes factor is dependent on the prior distribution for \\(\\theta\\). As a rule of thumb, when the prior distribution is highly conservative (as with method = 'default') with respect to the hypothesis of tolerable misstatement, the Bayes factor tends to over quantify the evidence in favor of this hypothesis. You can mitigate this dependency by using a prior distribution that is impartial with respect to the hypotheses via method = \"impartial\" in the auditPrior() function (Derks et al., 2022). prior &lt;- auditPrior(materiality = 0.05, method = &quot;impartial&quot;, likelihood = &quot;binomial&quot;) evaluation(materiality = 0.05, x = 1, n = 100, prior = prior) # # Bayesian Audit Sample Evaluation # # data: 1 and 100 # number of errors = 1, number of samples = 100, taint = 1, BF₁₀ = # 47.435 # alternative hypothesis: true misstatement rate is less than 0.05 # 95 percent credible interval: # 0.00000000 0.04110834 # most likely estimate: # 0.0088878 # results obtained via method &#39;binomial&#39; + &#39;prior&#39; The output shows that \\(BF_{10}=47\\), implying that under the assumption of impartiality there is strong evidence for \\(H_1\\), the hypothesis that the population contains misstatements lower than 5 percent of the population (tolerable misstatement). Since the two prior distributions both resulted in convincing Bayes factors, the results can be considered robust to the choice of prior distribution. Hence, the auditor is able to conclude that the sample provides convincing evidence to state that the population does not contain material misstatement. "],["evaluation-using-data.html", "6.3 Evaluation using Data", " 6.3 Evaluation using Data For this example, we take the allowances that set that comes with the package. This data set contains 3500 financial statement line items, each with a booked value bookValue and, for illustrative purposes, and audited (true) value auditValue. Since the focus of this vignette is the evaluation stage in the audit, the sample is already indicated in the data set. The performance materiality in this example is set to 5%. data(allowances) #head(allowances) Evaluating a non-stratified sample using data requires specification of the data, values and values.audit arguments. The input for these arguments is the name of the specific column in data. 6.3.1 Classical Evaluation The call below evaluates the allowances sample using a classical non-stratified evaluation procedure. x &lt;- evaluation( materiality = 0.05, data = allowances, values = &quot;bookValue&quot;, values.audit = &quot;auditValue&quot;, times = &quot;times&quot; ) summary(x) # # Classical Audit Sample Evaluation Summary # # Options: # Confidence level: 0.95 # Materiality: 0.05 # Hypotheses: H₀: Θ &gt;= 0.05 vs. H₁: Θ &lt; 0.05 # Method: poisson # # Data: # Sample size: 1604 # Number of errors: 401 # Sum of taints: 252.9281046 # # Results: # Most likely error: 0.15769 # 95 percent confidence interval: [0, 0.175] # Precision: 0.017311 # p-value: 1 In this case, the output shows that the estimate of the misstatement in the population is 15.77%, with the 95% (one-sided) confidence interval ranging from 0% to 17.5%. 6.3.2 Bayesian evaluation The call below evaluates the allowances sample using a Bayesian non-stratified evaluation procedure. x &lt;- evaluation( materiality = 0.05, data = allowances, prior = TRUE, values = &quot;bookValue&quot;, values.audit = &quot;auditValue&quot;, times = &quot;times&quot; ) summary(x) # # Bayesian Audit Sample Evaluation Summary # # Options: # Confidence level: 0.95 # Materiality: 0.05 # Hypotheses: H₀: Θ &gt; 0.05 vs. H₁: Θ &lt; 0.05 # Method: poisson # Prior distribution: gamma(α = 1, β = 1) # # Data: # Sample size: 1604 # Number of errors: 401 # Sum of taints: 252.9281046 # # Results: # Posterior distribution: gamma(α = 253.928, β = 1605) # Most likely error: 0.15759 # 95 percent credible interval: [0, 0.17489] # Precision: 0.0173 # BF₁₀: 0 The output shows that the estimate of the misstatement in the population is 15.76%, with the 95% (one-sided) credible interval ranging from 0% to 17.49%. "],["CHAPTER-7.html", "Chapter 7 Evaluating a Stratified Sample", " Chapter 7 Evaluating a Stratified Sample In an audit context, stratified sampling can be used to select a sample of transactions from different departments, locations, or business units to ensure that the sample is representative of the population. For example, if you want to audit the expense claims of a large organization, you can stratify the population based on the department, location, or business unit to ensure that all departments are represented accordingly in the sample. Another example of such a situation would be a group audit where the audited organization consists of different components or branches. Stratification is relevant for the group auditor if they must form an opinion on the group as a whole because they must aggregate the samples taken by the component auditors. As a data example, consider the retailer data set that comes with the package. The organization in question consists of 20 branches across the country. In each of the 20 strata, a component auditor has taken a statistical sample and reported the outcomes to the group auditor. data(retailer) stratum items samples errors 1 5000 300 21 2 5000 300 16 3 5000 300 15 4 5000 300 14 5 5000 300 16 6 5000 150 5 7 5000 150 4 8 5000 150 3 9 5000 150 4 10 5000 150 5 11 10000 50 2 12 10000 50 3 13 10000 50 2 14 10000 50 1 15 10000 50 0 16 10000 15 0 17 10000 15 0 18 10000 15 0 19 10000 15 1 20 4000 15 3 In general, there are three approaches to evaluating a stratified sample: no pooling, complete pooling, and partial pooling (see Derks et al., 2022). When using evaluation(), you must to indicate which type of pooling to use via the pooling argument. No pooling assumes no similarities between strata, which means that all strata are analyzed independently. Complete pooling assumes no difference between strata, which means that all data is aggregated and analyzed as a whole. Finally, partial pooling assumes differences and similarities between strata, which means that information can be shared between strata. Partial pooling (i.e., multilevel/hierarchical modeling) is a powerful technique that can result in more efficient population and stratum estimates but is currently only feasible when performing a Bayesian analysis. For this reason, this vignette only describes the Bayesian approach to stratified evaluation but going from this approach to a classical approach only requires setting prior = FALSE. The number of units per stratum in the population can be provided with N.units to weigh the stratum estimates to determine population estimate. This is called poststratification. If N.units is not specified, each stratum is assumed to be equally represented in the population. "],["no-pooling.html", "7.1 No pooling", " 7.1 No pooling No pooling (pooling = \"none\", default) assumes no similarities between strata. This means that the prior distribution specified through prior is applied independently for each stratum. This allows for independent estimates for the misstatement in each stratum but also results in a relatively high uncertainty in the population estimate. The call below evaluates the sample using a Bayesian stratified evaluation procedure, in which the stratum estimates are poststratified to arrive at the population estimate. set.seed(1) # Important because the posterior distribution is determined via sampling result_np &lt;- evaluation( materiality = 0.05, method = &quot;binomial&quot;, prior = TRUE, n = retailer$samples, x = retailer$errors, N.units = retailer$items, alternative = &quot;two.sided&quot;, pooling = &quot;none&quot; ) summary(result_np) # # Bayesian Audit Sample Evaluation Summary # # Options: # Confidence level: 0.95 # Population size: 144000 # Materiality: 0.05 # Hypotheses: H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 # Method: binomial # Prior distribution: Determined via MCMC sampling # # Data: # Sample size: 2575 # Number of errors: 115 # Sum of taints: 115 # # Results: # Posterior distribution: Determined via MCMC sampling # Most likely error: 0.058487 # 95 percent credible interval: [0.042763, 0.082201] # Precision: 0.023714 # BF₁₀: 0 # # Strata (20): # N n x t mle lb ub precision # 1 5000 300 21 21 0.07000 0.04637 0.10467 0.03467 # 2 5000 300 16 16 0.05333 0.03324 0.08489 0.03156 # 3 5000 300 15 15 0.05000 0.03069 0.08086 0.03086 # 4 5000 300 14 14 0.04667 0.02816 0.07681 0.03014 # 5 5000 300 16 16 0.05333 0.03324 0.08489 0.03156 # 6 5000 150 5 5 0.03333 0.01472 0.07558 0.04225 # 7 5000 150 4 4 0.02667 0.01084 0.06643 0.03977 # 8 5000 150 3 3 0.02000 0.00726 0.05696 0.03696 # 9 5000 150 4 4 0.02667 0.01084 0.06643 0.03977 # 10 5000 150 5 5 0.03333 0.01472 0.07558 0.04225 # 11 10000 50 2 2 0.04000 0.01230 0.13459 0.09459 # 12 10000 50 3 3 0.06000 0.02178 0.16242 0.10242 # 13 10000 50 2 2 0.04000 0.01230 0.13459 0.09459 # 14 10000 50 1 1 0.02000 0.00478 0.10447 0.08447 # 15 10000 50 0 0 0.00000 0.00050 0.06978 0.06978 # 16 10000 15 0 0 0.00000 0.00158 0.20591 0.20591 # 17 10000 15 0 0 0.00000 0.00158 0.20591 0.20591 # 18 10000 15 0 0 0.00000 0.00158 0.20591 0.20591 # 19 10000 15 1 1 0.06667 0.01551 0.30232 0.23565 # 20 4000 15 3 3 0.20000 0.07266 0.45646 0.25646 In this case, the output of the summary() function shows that the estimate of the misstatement in the population is 5.85%, with the 95% credible interval ranging from 4.28% to 8.22%. The stratum estimates differ substantially from each other but are relatively uncertain. plot(result_np, type = &quot;estimates&quot;) The prior and posterior distribution for the population misstatement can be requested via the plot() function. plot(result_np, type = &quot;posterior&quot;) "],["complete-pooling.html", "7.2 Complete pooling", " 7.2 Complete pooling Complete pooling (pooling = \"complete\") assumes no differences between strata. This has the advantages that data from all strata can be aggregated, which decreases the uncertainty in the population estimate compared to the no pooling approach. However, the disadvantage of this approach is that it does not facilitate the distinction between between strata, as every stratum receives the same estimate equal to that of the population. The call below evaluates the sample using a Bayesian stratified evaluation procedure, in which the strata are assumed to be the same. result_cp &lt;- evaluation( materiality = 0.05, method = &quot;binomial&quot;, prior = TRUE, n = retailer$samples, x = retailer$errors, N.units = retailer$items, alternative = &quot;two.sided&quot;, pooling = &quot;complete&quot; ) summary(result_cp) # # Bayesian Audit Sample Evaluation Summary # # Options: # Confidence level: 0.95 # Population size: 144000 # Materiality: 0.05 # Hypotheses: H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 # Method: binomial # Prior distribution: beta(α = 1, β = 1) # # Data: # Sample size: 2575 # Number of errors: 115 # Sum of taints: 115 # # Results: # Posterior distribution: beta(α = 116, β = 2461) # Most likely error: 0.04466 # 95 percent credible interval: [0.03735, 0.053345] # Precision: 0.0086852 # BF₁₀: 0.022725 # # Strata (20): # N n x t mle lb ub precision bf10 # 1 5000 300 21 21 0.04466 0.03735 0.05335 0.00869 0.02273 # 2 5000 300 16 16 0.04466 0.03735 0.05335 0.00869 0.02273 # 3 5000 300 15 15 0.04466 0.03735 0.05335 0.00869 0.02273 # 4 5000 300 14 14 0.04466 0.03735 0.05335 0.00869 0.02273 # 5 5000 300 16 16 0.04466 0.03735 0.05335 0.00869 0.02273 # 6 5000 150 5 5 0.04466 0.03735 0.05335 0.00869 0.02273 # 7 5000 150 4 4 0.04466 0.03735 0.05335 0.00869 0.02273 # 8 5000 150 3 3 0.04466 0.03735 0.05335 0.00869 0.02273 # 9 5000 150 4 4 0.04466 0.03735 0.05335 0.00869 0.02273 # 10 5000 150 5 5 0.04466 0.03735 0.05335 0.00869 0.02273 # 11 10000 50 2 2 0.04466 0.03735 0.05335 0.00869 0.02273 # 12 10000 50 3 3 0.04466 0.03735 0.05335 0.00869 0.02273 # 13 10000 50 2 2 0.04466 0.03735 0.05335 0.00869 0.02273 # 14 10000 50 1 1 0.04466 0.03735 0.05335 0.00869 0.02273 # 15 10000 50 0 0 0.04466 0.03735 0.05335 0.00869 0.02273 # 16 10000 15 0 0 0.04466 0.03735 0.05335 0.00869 0.02273 # 17 10000 15 0 0 0.04466 0.03735 0.05335 0.00869 0.02273 # 18 10000 15 0 0 0.04466 0.03735 0.05335 0.00869 0.02273 # 19 10000 15 1 1 0.04466 0.03735 0.05335 0.00869 0.02273 # 20 4000 15 3 3 0.04466 0.03735 0.05335 0.00869 0.02273 For example, the output of the summary() function shows that the estimate of the misstatement in the population is 4.47%, with the 95% credible interval ranging from 3.74% to 5.33%. Since the data is aggregated, the stratum estimates contain relatively little uncertainty. However, the probability of misstatement in stratum 20 (many misstatements) under this assumption is the same as that of stratum 15 (few misstatements). plot(result_cp, type = &quot;estimates&quot;) The prior and posterior distribution for the population misstatement can be requested via the plot() function. plot(result_cp, type = &quot;posterior&quot;) "],["partial-pooling.html", "7.3 Partial pooling", " 7.3 Partial pooling Finally, partial pooling (pooling = \"partial\") assumes differences and similarities between strata. This allows the auditor to differentiate between strata, while also sharing information between the strata to reduce uncertainty in the population estimate. The call below evaluates the sample using a Bayesian stratified evaluation procedure, in which the stratum estimates are poststratified to arrive at the population estimate. set.seed(1) # Important because the posterior distribution is determined via sampling result_pp &lt;- evaluation( materiality = 0.05, method = &quot;binomial&quot;, prior = TRUE, n = retailer$samples, x = retailer$errors, N.units = retailer$items, alternative = &quot;two.sided&quot;, pooling = &quot;partial&quot; ) summary(result_pp) # # Bayesian Audit Sample Evaluation Summary # # Options: # Confidence level: 0.95 # Population size: 144000 # Materiality: 0.05 # Hypotheses: H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 # Method: binomial # Prior distribution: Determined via MCMC sampling # # Data: # Sample size: 2575 # Number of errors: 115 # Sum of taints: 115 # # Results: # Posterior distribution: Determined via MCMC sampling # Most likely error: 0.043714 # 95 percent credible interval: [0.034206, 0.053522] # Precision: 0.0098086 # BF₁₀: 0.019031 # # Strata (20): # N n x t mle lb ub precision # 1 5000 300 21 21 0.04809 0.03814 0.08017 0.03207 # 2 5000 300 16 16 0.04569 0.03328 0.06816 0.02247 # 3 5000 300 15 15 0.04497 0.03207 0.06407 0.01909 # 4 5000 300 14 14 0.04433 0.03043 0.06220 0.01787 # 5 5000 300 16 16 0.04620 0.03281 0.06708 0.02088 # 6 5000 150 5 5 0.04348 0.02367 0.05968 0.01620 # 7 5000 150 4 4 0.04126 0.02088 0.05677 0.01551 # 8 5000 150 3 3 0.04164 0.01846 0.05501 0.01337 # 9 5000 150 4 4 0.04229 0.02137 0.05677 0.01448 # 10 5000 150 5 5 0.04181 0.02328 0.05844 0.01663 # 11 10000 50 2 2 0.04410 0.02417 0.06688 0.02278 # 12 10000 50 3 3 0.04418 0.02616 0.07366 0.02948 # 13 10000 50 2 2 0.04318 0.02261 0.06669 0.02351 # 14 10000 50 1 1 0.04280 0.01993 0.06367 0.02087 # 15 10000 50 0 0 0.04234 0.01641 0.05928 0.01694 # 16 10000 15 0 0 0.04331 0.02039 0.06699 0.02369 # 17 10000 15 0 0 0.04424 0.02027 0.06700 0.02276 # 18 10000 15 0 0 0.04330 0.01984 0.06587 0.02257 # 19 10000 15 1 1 0.04293 0.02313 0.07342 0.03049 # 20 4000 15 3 3 0.04527 0.03047 0.10417 0.05889 In this case, the output shows that the estimate of the misstatement in the population is 4.34%, with the 95% credible interval ranging from 3.45% to 5.33%. Note that this population estimate is substantially less uncertain than that of the no pooling approach. Note that, like in the no pooling approach, the stratum estimates are different from each other but lie closer together and are less uncertain. plot(result_pp, type = &quot;estimates&quot;) The prior and posterior distribution for the population misstatement can be requested via the plot() function. plot(result_pp, type = &quot;posterior&quot;) "],["evaluation-using-data-1.html", "7.4 Evaluation using data", " 7.4 Evaluation using data For this example, we take the allowances that set that comes with the package. This data set contains 3500 financial statement line items, each with a booked value bookValue and, for illustrative purposes, and audited (true) value auditValue. Since the focus of this vignette is the evaluation stage in the audit, the sample is already indicated in the data set. The performance materiality in this example is set to 5%. data(allowances) #head(allowances) Evaluating a stratified sample using data requires specification of the data, values, values.audit and strata arguments in the evaluation() function. In this case, the units are monetary and calculated by aggregating the book values of the items in each stratum. N.units &lt;- aggregate(allowances$bookValue, list(allowances$branch), sum)$x 7.4.1 Classical Evaluation The call below evaluates the allowances sample using a classical stratified evaluation procedure, in which the stratum estimates are poststratified to arrive at the population estimate. x &lt;- evaluation( materiality = 0.05, data = allowances, values = &quot;bookValue&quot;, values.audit = &quot;auditValue&quot;, strata = &quot;branch&quot;, times = &quot;times&quot;, alternative = &quot;two.sided&quot;, N.units = N.units ) summary(x) # # Classical Audit Sample Evaluation Summary # # Options: # Confidence level: 0.95 # Population size: 16772249 # Materiality: 0.05 # Hypotheses: H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 # Method: poisson # # Data: # Sample size: 1604 # Number of errors: 401 # Sum of taints: 252.9281046 # # Results: # Most likely error: 0.14723 # 95 percent confidence interval: [0.12549, 0.18239] # Precision: 0.03516 # p-value: NA # # Strata (16): # N n x t mle lb ub precision p.value # 1 317200.09 87 6 1.27814 0.01469 0.00073 0.06950 0.05481 0.46285 # 2 2792814.33 305 233 193.23313 0.63355 0.54558 0.72945 0.09590 0.00000 # 3 1144231.69 55 3 3.00000 0.05455 0.01105 0.15940 0.10486 0.75827 # 4 414202.89 70 45 15.05094 0.21501 0.11878 0.35434 0.13933 0.00000 # 5 96660.53 18 1 0.64537 0.03585 0.00015 0.27456 0.23871 0.59343 # 6 348006.13 34 1 0.17866 0.00525 0.00000 0.11926 0.11401 1.00000 # 7 2384079.33 55 14 9.44448 0.17172 0.07885 0.32122 0.14950 0.00058 # 8 1840399.33 96 1 0.00813 0.00008 0.00000 0.03860 0.03852 0.10355 # 9 563957.70 92 0 0.00000 0.00000 0.00000 0.04010 0.04010 0.01783 # 10 3198877.73 201 7 0.92023 0.00458 0.00009 0.02703 0.02245 0.00122 # 11 1983299.06 128 7 1.50034 0.01172 0.00084 0.05013 0.03841 0.10773 # 12 319144.13 86 5 1.68141 0.01955 0.00174 0.07806 0.05851 0.46069 # 13 148905.79 25 0 0.00000 0.00000 0.00000 0.14756 0.14756 0.64187 # 14 513058.76 150 0 0.00000 0.00000 0.00000 0.02459 0.02459 0.00134 # 15 432007.61 150 39 21.80000 0.14533 0.09026 0.22045 0.07511 0.00001 # 16 275403.70 52 39 4.18726 0.08052 0.02237 0.20215 0.12163 0.12258 In this case, the output shows that the estimate of the misstatement in the population is 14.72%, with the 95% confidence interval ranging from 12.55% to 18.26%. The precision of the population estimate is 3.54%. The stratum estimates can be seen in the output of the summary() function and are visualized below. plot(x, type = &quot;estimates&quot;) 7.4.2 Bayesian Evaluation Bayesian inference can improve upon the estimates of the classical approach by pooling information between strata where possible. The call below evaluates the allowances sample using a Bayesian multilevel stratified evaluation procedure, in which the stratum estimates are poststratified to arrive at the population estimate. x &lt;- evaluation( materiality = 0.05, data = allowances, prior = TRUE, values = &quot;bookValue&quot;, values.audit = &quot;auditValue&quot;, strata = &quot;branch&quot;, times = &quot;times&quot;, alternative = &quot;two.sided&quot;, N.units = N.units, pooling = &quot;partial&quot; ) summary(x) # # Bayesian Audit Sample Evaluation Summary # # Options: # Confidence level: 0.95 # Population size: 16772249 # Materiality: 0.05 # Hypotheses: H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 # Method: poisson # Prior distribution: Determined via MCMC sampling # # Data: # Sample size: 1350 # Number of errors: 401 # Sum of taints: 224.657517 # # Results: # Posterior distribution: Determined via MCMC sampling # Most likely error: 0.1555 # 95 percent credible interval: [0.1458, 0.17009] # Precision: 0.014595 # BF₁₀: 3.1386e+15 # # Strata (16): # N n x t mle lb ub precision # 1 317200.09 62 6 1.07814 0.02037 0.01356 0.03659 0.01622 # 2 2792814.33 283 233 176.87807 0.60930 0.57298 0.65128 0.04198 # 3 1144231.69 55 3 3.00000 0.16735 0.11682 0.24582 0.07847 # 4 414202.89 48 45 11.65094 0.27653 0.22254 0.34868 0.07214 # 5 96660.53 9 1 0.21512 0.02207 0.01055 0.08932 0.06725 # 6 348006.13 14 1 0.04467 0.01233 0.00723 0.04022 0.02790 # 7 2384079.33 44 14 6.65401 0.13637 0.09156 0.21540 0.07903 # 8 1840399.33 78 1 0.00813 0.00640 0.00458 0.00961 0.00320 # 9 563957.70 74 0 0.00000 0.00608 0.00461 0.00957 0.00349 # 10 3198877.73 184 7 0.89982 0.00804 0.00615 0.01074 0.00270 # 11 1983299.06 111 7 1.35066 0.01525 0.01077 0.02243 0.00718 # 12 319144.13 56 5 1.19069 0.08428 0.05625 0.14502 0.06074 # 13 148905.79 10 0 0.00000 0.01216 0.00636 0.04545 0.03329 # 14 513058.76 150 0 0.00000 0.00472 0.00377 0.00633 0.00161 # 15 432007.61 128 39 18.30000 0.27398 0.23217 0.33730 0.06332 # 16 275403.70 44 39 3.38726 0.07640 0.05784 0.10161 0.02521 The output shows that the estimate of the misstatement in the population is 15.66%, with the 95% credible interval ranging from 14.59% to 17%. The precision of the population estimate is 1.34%, which is substantially lower than that of the classical approach. The stratum estimates can be seen in the output of the summary() function and are visualized below. plot(x, type = &quot;estimates&quot;) The prior and posterior distribution for the population misstatement can be requested via the plot() function. plot(x, type = &quot;posterior&quot;) "],["CHAPTER-8.html", "Chapter 8 Other Software", " Chapter 8 Other Software This chapter discusses other R-related open-source software implementing statistical techniques for audit sampling. "],["jasp-for-audit-gui.html", "8.1 JASP for Audit (GUI)", " 8.1 JASP for Audit (GUI) JASP for Audit (Derks et al. 2021) is an add-on module for JASP (JASP Team 2022), based on the jfa package, that facilitates statistical audit sampling. Concretely, it contains graphical user interfaces (GUI’s) for calculating sample sizes, selecting items according to standard audit sampling techniques, and performing inference about the population misstatement on the basis of a data sample or summary statistics of a sample. The module also features Bayesian equivalents of these analyses that enable the user to easily incorporate prior information into the statistical procedure. In all analyses, the Audit module offers explanatory text that helps the auditor in interpreting, explaining, and reporting the analysis. Since JASP for Audit is an R-based GUI around jfa, its functionality can be mapped almost one-on-one to that of the package. Figure 8.1: The JASP welcome screen. 8.1.1 Planning Planning a sample in JASP for Audit works similar to how you would do it in jfa. For example, the screenshot below shows how to plan a minimum sample size for a performance materiality of 5% using a beta(1, 1) prior distribution, while expecting zero misstatements in the sample. Figure 8.2: The JASP interface for planning a sample. In jfa, these results can be reproduced via the following command: planning(materiality = 0.05, likelihood = &quot;binomial&quot;, prior = TRUE) # # Bayesian Audit Sample Planning # # minimum sample size = 58 # sample size obtained in 59 iterations via method &#39;binomial&#39; + &#39;prior&#39; 8.1.2 Selection Selecting a sample in JASP for Audit works similar to how you would do it in jfa. For example, the screenshot below shows how to select a sample of 60 monetary units from the BuildIt data set that is included in the package using a fixed interval sampling method with a starting point of 1. set.seed(1) data(BuildIt) result &lt;- selection(data = BuildIt, size = 60, method = &quot;interval&quot;, start = 1, units = &quot;values&quot;, values = &quot;bookValue&quot;) head(result$sample) # row times ID bookValue auditValue # 1 1 1 82884 242.61 242.61 # 2 63 1 51272 248.40 248.40 # 3 123 1 37985 562.09 562.09 # 4 183 1 96080 449.07 449.07 # 5 240 1 92819 690.08 690.08 # 6 302 1 94296 198.59 198.59 Figure 8.3: The JASP interface for selecting a sample. 8.1.3 Evaluation Evaluating a sample in JASP for Audit works similar to how you would do it in jfa. For example, the screenshot below shows how to evaluating a sample of \\(n = 60\\) containing \\(x = 0\\) misstatements against a performance materiality of 5% using a beta(1, 1) prior distribution. Figure 8.4: The JASP interface for evaluating a sample. In jfa, these results can be reproduced via the following command: evaluation(materiality = 0.05, method = &quot;binomial&quot;, x = 2, n = 93, prior = TRUE) # # Bayesian Audit Sample Evaluation # # data: 2 and 93 # number of errors = 2, number of samples = 93, taint = 2, BF₁₀ = # 111.66 # alternative hypothesis: true misstatement rate is less than 0.05 # 95 percent credible interval: # 0.0000000 0.0654624 # most likely estimate: # 0.021505 # results obtained via method &#39;binomial&#39; + &#39;prior&#39; References "],["mus-r.html", "8.2 MUS (R)", " 8.2 MUS (R) MUS (Prömpers and Guimarães 2019) is an R package proving sampling and evaluation methods to apply Monetary Unit Sampling during an audit of financial statements. The package is available via CRAN and can be downloaded with: install.packages(&quot;MUS&quot;) References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
