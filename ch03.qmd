```{r echo = FALSE, cache = FALSE}
source("utils.R", local = TRUE)
```

::: {.callout-note appearance="simple"}
You are reading the work-in-progress first edition of Statistical Auditing with
R. This chapter is largely complete and just needs final proof reading.
:::

# Planning a Sample {#CHAPTER-3}

One of the key considerations in audit sampling is determining the appropriate
sample size to achieve a desired level of assurance or precision. This chapter
will focus on three standard likelihoods commonly used in audit sampling: the
hypergeometric likelihood, the binomial likelihood, and the Poisson likelihood.

![Figure 3.1: The standard audit sampling workflow consists of four stages: planning, selection, execution, and evaluation. The planning stage is the first of these stages.](img/planning.png){fig-align="center"}

In **jfa**, determining an appropriate sample size is achieved via the
`planning()` function.

::: {.callout-tip}
## Bayesian planning?
When you are using the Bayesian approach to audit sampling, it is not required
to plan a certain sample size in advance [@Derks2022]. That is because in
Bayesian inference, the posterior distribution after seeing each item is used as
the prior distribution for the next item. That means that you can simply start
sampling and monitor the evidence in the data over time. However, to get an idea
of how many samples are required to achieve a certain amount of assurance,
planning a sample using a Bayesian approach can still be good practice.
:::

## Required Information

First, planning a minimum sample requires knowledge of the conditions that lead 
to acceptance or rejection of the population (i.e., the sampling objectives).
Typically, sampling objectives can be classified into one or both of the
following:

- **Hypothesis testing**: The goal of the sample is to obtain evidence for or
  against the claim that the misstatement in the population is lower than a
  given value (i.e., the performance materiality).
- **Estimation**: The goal of the sample is to obtain an accurate estimate of
  the misstatement in the population (with a minimum precision).

Second, it is advised to specify the expected (or tolerable) misstatements in
the sample. The expected misstatements are the misstatements that you allow in
the sample, while still retaining the desired amount of assurance about the 
population. It is strongly recommended to set the value for the expected
misstatements in the sample conservatively to minimize the chance of the
observed misstatements in the sample exceeding the expected misstatements, which
would imply that insufficient work has been done in the end.

Finally, next to determining the sampling objective(s) and the expected
misstatements, it is important to determine the statistical distribution linking
the sample outcomes to the population misstatement. This distribution is called
the likelihood (i.e., `poisson`, `binomial`, or `hypergeometric`). All three
aforementioned likelihoods are commonly used in an audit sampling context,
however, `poisson` is the default likelihood in **jfa** because it is the most
conservative of the three. In the subsections below, we elaborate on the three
standard likelihoods for audit sampling and demonstrate how they can be used
to obtain a minimum sample size.

## The Hypergeometric Likelihood

Let's consider how to use the hypergeometric likelihood to calculate the
minimum sample size needed to achieve the desired level of assurance. The
hypergeometric distribution is a discrete probability distribution that is
commonly used to model the number of events occurring in a fixed number of
trials when the population size is known. It assumes that samples are drawn
from the population without replacement, and is therefore the likelihood that
most closely resembles the audit practice. For our purpose, we can use the
hypergeometric distribution as a likelihood to model the number of misstatements
that are expected to be found in the sample.

The probability mass function (PMF) of the hypergeometric distribution is given
by:

\begin{equation}
  p(X=k)=\frac{\binom{K}{k}\binom{N-K}{n-k}}{\binom{N}{n}},
\end{equation}

where $k$ is the number of misstatements in the sample, $n$ is the sample size,
$N$ is the population size and $K$ is the total number of misstatements assumed
in the population. The assumed misstatements $K$ is a linear extrapolation of
the assumed misstatement rate in the population $\theta_{max}$ to the total
population:

\begin{equation}
  K = \theta_{max} N.
\end{equation}

### Classical planning

Concretely, the following statistical model is assumed:

\begin{equation}
  k \sim \text{Hypergeometric}(n, N, K)
\end{equation}

Given the performance materiality $\theta_{max}$, we can solve for the minimum
sample size $n$ needed to achieve this assurance level. This sample size is
dependent on the number of misstatements that the auditor expects, or tolerates,
in the sample. 

#### No Expected Misstatement

If the auditor does not expect any misstatements in the sample, they can set
$k = 0$, which consequently determines how the sample size can be calculated.
For example, if we want to achieve an assurance level of 95% ($\alpha = 0.05$)
for a performance materiality of $\theta_{max} = 0.03$ in a population of
$N = 1000$ items, then the required sample size under the assumption of no
expected misstatements in the sample is $n = 94$.

```{r}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "hypergeometric", N.units = 1000)
```

::: {.callout-tip}
## Additional arguments
The `planning()` function has two additional arguments that are not shown in
the call above: `by` and `max`. The argument `by` sets the increment between
possible sample sizes for consideration. For example, `by = 5` considers only
samples of size 10, 20, 30, etc:

```{r}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "hypergeometric", N.units = 1000, by = 10)
```

The argument `max` sets the sample size at which the algorithm terminates. This
can be used to avoid too many iterations of the algorithm at very low values of
the performance materiality. For instance, `max = 50` throws an error if more
than 100 samples are required.

```{r error=TRUE}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "hypergeometric", N.units = 1000, max = 50)
```
:::

The sample size of 94 can be confirmed by checking that 94 is the minimum
integer that results in less than 5% probability of finding 0 misstatements,
given the assumption that the population misstatement is truly 3%. The
`dhyper()` function calculates the probability of observing $k$ missatements in
a sample of $n$ items given the assumed hypergeometric distribution with $N$
items and $K$ assumed misstatements in the population. By calculating this
probability for $n = 93$, we can show that this sample size is insufficient as
the relevant probability is higher than the sampling risk $\alpha$.

```{r}
K <- ceiling(0.03 * 1000)
dhyper(x = 0, m = K, n = 1000 - K, k = 93) < 0.05
```

However, for $n = 94$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
dhyper(x = 0, m = K, n = 1000 - K, k = 94) < 0.05
```

We can make this sample size visually intuitive by showing thehypergeometric($k$
| 94, 1000, 30) distribution and highlighting the probability for $k = 0$. This
probability is lower than the required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dhyper(x = 0:10, m = K, n = 1000 - K, k = 94))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c("firebrick", rep("darkgray", 10)), colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5, size = 3) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

#### Expected Misstatements

If the auditor expects misstatements in the sample, they can set $k$ to any
integer value, which consequently determines how the sample size can be
calculated. As another example, if we want to achieve an assurance level of 95%
($\alpha = 0.05$) for a performance materiality of $\theta_{max} = 0.03$ in a
population of $N = 1000$ items, then the required sample size under the
assumption of one expected misstatement in the sample is $n = 147$.

```{r}
planning(materiality = 0.03, expected = 1, conf.level = 0.95,
         likelihood = "hypergeometric", N.units = 1000)
```

Once again, the sample size of 147 can be confirmed by checking that 147 is the
minimum integer that results in less than 5% probability of finding 0 or 1
misstatements, given the assumption that that the population misstatement is
truly 3%. By calculating this probability for $n = 146$, we can show that this
sample size is insufficient as the relevant probability is higher than the
sampling risk $\alpha$.

```{r}
sum(dhyper(x = 0:1, m = K, n = 1000 - K, k = 146)) < 0.05
```

However, for $n = 147$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
sum(dhyper(x = 0:1, m = K, n = 1000 - K, k = 147)) < 0.05
```

Like before, we can make this sample size visually intuitive by showing the
hypergeometric($k$ | 147, 1000, 30) distribution and highlighting the
probabilities for $k = 0$ and $k = 1$. The sum of these probabilities is lower
than the required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dhyper(x = 0:10, m = K, n = 1000 - K, k = 147))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c(rep("firebrick", 2), rep("darkgray", 9)),
           colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5, size = 3) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

### Bayesian Planning

Performing Bayesian planning with the hypergeometric likelihood [@Dyer1993]
requires that you specify a prior distribution for the parameter $\theta$.
Practically, this means that you should provide an input for the `prior`
argument in the `planning()` function.

Setting `prior = TRUE` performs Bayesian planning using a [default prior](https://koenderks.github.io/jfa/articles/creating-prior.html#default-priors-method-default)
conjugate to the specified `likelihood` (i.e., a beta-binomial prior).
Concretely, this means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Hypergeometric}(n, N, K) \\
  K &\sim \text{Beta-binomial}(N, \alpha, \beta)
\end{align}

::: {.callout-note}
The beta-binomial prior distribution is the conjugate prior for to the
hypergeometric likelihood (see this [list](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)
of conjugate priors), which means that the posterior distribution of $K$ can be
determined analytically. For example, if the prior distribution for $K$ is
beta-binomial($N$, $\alpha$, $\beta$) and the auditor has observed a sample of
$n$ items containing $k$ misstatements, the posterior distribution for $K$ is
beta-binomial($N - n$, $\alpha + k$, $\beta + n - k$).
:::

For example, the command below uses a default beta-binomial($N$, 1, 1) prior
distribution to plan the sample, since `planning()` is given the hypergeometric
likelihood. If we want to achieve an assurance level of 95% ($\alpha = 0.05$)
for a performance materiality of $\theta_{max} = 0.03$ in a population of
$N = 1000$ items, then the required sample size under the assumption of zero
expected misstatements in the sample is $n = 93$.

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "hypergeometric", N.units = 1000,
                 prior = TRUE)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

You can inspect how the prior distribution compares to the expected posterior
distribution by using the `plot()` function. The expected posterior distribution
is the posterior distribution that would occur if you actually observed the
planned sample containing the expected misstatements.

```{r}
plot(plan)
```

Note that the hypergeometric likelihood does not allow for non-conjugate prior
distributions to be used as a prior.

## The Binomial Likelihood

Let's consider how to use the binomial likelihood to calculate the minimum
sample size needed to achieve a desired level of assurance. The binomial
distribution is a discrete probability distribution that is commonly used to
model the number of events occurring in a fixed number of trials. It is similar
to the hypergeometric distribution, however, it assumes that samples are drawn
from the population with replacement. For our purpose, we can use the binomial
distribution as a likelihood to model the number of misstatements that are
expected to be found in the sample. 

::: {.callout-note}
In audit sampling, the binomial likelihood is often used to approximate the
hypergeometric likelihood since it is easier to work with (i.e., it only has two
parameters: $\theta$ and $n$, while the hypergeometric has three: $n$, $N$, and
$K$). However, the binomial likelihood is more conservative than the
hypergeometric likelihood, meaning that resulting sample sizes will be higher.
:::

The probability mass function (PMF) of the binomial distribution is given by:

\begin{equation}
  p(k; n, \theta) = \binom{n}{k} \theta^{k} (1-\theta)^{n - k},
\end{equation}

where $k$ is the number of misstatements in the sample, $n$ is the sample size
and $\theta$ is the probability of misstatement in the population.

### Classical Planning

Concretely, the following statistical model is assumed:

\begin{equation}
  k \sim \text{Binomial}(n, \theta_{max})
\end{equation}

#### No Expected Misstatement

If the auditor does not expect any misstatements in the sample, they can set
$k = 0$, which consequently determines how the sample size can be calculated.
Given a performance materiality $\theta_{max}$, we can solve for the minimum
sample size $n$ needed to achieve a certain assurance level. A useful trick to
utilize is that, if we do not expect any misstatements in the sample, the
formula for the minimum required sample size reduces to:

\begin{equation}
  n = \lceil\frac{\ln(\alpha)}{\ln(1 - \theta_{max})}\rceil.
\end{equation}

::: {.callout-note}
$\lceil...\rceil$ is the ceiling function, which means that $\lceil1.2\rceil = 2$.
:::

For example, if we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 99$.

```{r}
ceiling(log(1 - 0.95) / log(1 - 0.03))
```

In **jfa**, this sample size can be replicated using the following code:

```{r}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "binomial")
```

The sample size of 99 can be confirmed by checking that 99 is the minimum
integer that results in less than 5% probability of finding 0 misstatements,
given the assumption that the population misstatement is truly 3%. The
`dbinom()` function calculates the probability of observing $k$ missatements in
a sample of $n$ items given an assumed misstatement probability $\theta_{max}$.
By calculating this probability for $n = 98$, we can show that this
sample size is insufficient as the relevant probability is higher than the
sampling risk $\alpha$.

```{r}
dbinom(x = 0, size = 98, prob = 0.03) < 0.05
```

However, for $n = 99$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
dbinom(x = 0, size = 99, prob = 0.03) < 0.05
```

We can make this sample size visually intuitive by showing the binomial($k$ |
99, 0.03) distribution and highlighting the probability for $k = 0$. This
probability is lower than the required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dbinom(x = 0:10, size = 99, prob = 0.03))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c("firebrick", rep("darkgray", 10)), colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5, size = 3) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

#### Expected Misstatements

However, if the number of expected misstatements in the sample is non-zero,
it becomes more difficult to solve the formula for $n$. Hence, they will need to
set $k$ to a different integer value, which consequently determines how the
sample size is calculated. Here, we can iteratively try every value of $n$ and
return the smallest integer that satisfies the sampling objectives.

In **jfa**, this can be done by adjusting the `expected` argument in the
`planning()` function. For example, if we want to achieve an assurance level of
95% ($\alpha = 0.05$) for a performance materiality of $\theta_{max} = 0.03$,
then the required sample size under the assumption of one expected misstatement
in the sample is $n = 157$.

```{r}
planning(materiality = 0.03, expected = 1, conf.level = 0.95,
         likelihood = "binomial")
```

Once again, the sample size of 157 can be confirmed by checking that 157 is the
minimum integer that results in less than 5% probability of finding 0 or 1
misstatements, given the assumption that the population misstatement is truly
3%. By calculating this probability for $n = 156$, we can show that this
sample size is insufficient as the relevant probability is higher than the
sampling risk $\alpha$.

```{r}
sum(dbinom(x = 0:1, size = 156, prob = 0.03)) < 0.05
```

However, for $n = 157$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
sum(dbinom(x = 0:1, size = 157, prob = 0.03)) < 0.05
```

Like before, we can make this sample size visually intuitive by showing the
binomial($k$ | 157, 0.03) distribution and highlighting the probabilities for
$k = 0$ and $k = 1$. The sum of these probabilities is lower than the
required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dbinom(x = 0:10, size = 157, prob = 0.03))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c(rep("firebrick", 2), rep("darkgray", 9)),
           colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5, size = 3) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

#### Partial Expected Misstatements

When the expected misstatements in the sample $\theta_{exp}$ is assessed, the
value for $k$ can be determined as $k = n\theta_{exp}$, which consequently
determines how the sample size can be calculated.

To account for the fact that $k$ can have non-integer values in this case, we
can use a well-known similarity between the binomial distribution and the beta
distribution to plan the sample size. The upper bound for any binomial($k$; $n$,
$\theta$) distributed variable can also be obtained via percentiles of the
beta($1 + k$, $n - k$) distribution. 

For example, the upper bound for a sample of $n = 10$ items containing $k = 2$
misstatements, when calculated via the traditional `binom.test()` is:

```{r}
ub_binom <- binom.test(x = 2, n = 10, p = 0.03, conf.level = 0.95,
                       alternative = "less")$conf.int[2]
ub_binom
```

When calculated via the beta relationship, the upper bound is:

```{r}
ub_beta <- qbeta(p = 0.95, shape1 = 1 + k, shape2 = n - k)
ub_beta
```

It can be validated that the two approaches result in the same upper bound via:

```{r}
ub_binom == ub_beta
```

This relationship between the binomial likelihood and the beta distribution is
deliberately **not** used in **jfa**. That is because, in the case of the
binomial distribution, the auditing standards round the tolerable misstatements
upwards to a whole number [@AICPA-A]. For example, if we try to call the
`planning()` function with the argument `expected = 1.5`, **jfa** will
internally convert this to `expected = 2` and base the sample size on this to
comply with @AICPA-A Appendix A. The resulting sample size is $n = 208$ in this
case.

```{r}
planning(materiality = 0.03, expected = 1.5, conf.level = 0.95,
         likelihood = "binomial")
```

### Bayesian Planning

Performing Bayesian planning with the binomial likelihood requires that you
specify a prior distribution for the parameter $\theta$. Practically, this means
that you should provide an input for the `prior` argument in the `planning()`
function.

Setting `prior = TRUE` performs Bayesian planning using a [default prior](https://koenderks.github.io/jfa/articles/creating-prior.html#default-priors-method-default)
conjugate to the specified `likelihood` (i.e., a beta prior). Concretely, this
means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Binomial}(n, \theta) \\
  \theta &\sim \text{Beta}(\alpha, \beta)
\end{align}

::: {.callout-note}
The beta prior distribution is the conjugate prior for the binomial likelihood
(see this [list](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)
of conjugate priors), which means that the posterior distribution of $\theta$
can be determined analytically. For example, if the prior distribution is
beta($\alpha$, $\beta$) and the auditor has observed a sample of $n$ items
containing $k$ misstatements, the posterior distribution for $\theta$ is
beta($\alpha + k$, $\beta + n - k$).
:::

For example, the command below uses a default beta($\alpha=1$, $\beta=1$) prior
distribution to plan the sample, since `planning()` is given the binomial
likelihood. If we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 98$.

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "binomial", prior = TRUE)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

You can inspect how the prior distribution compares to the expected
posterior distribution by using the `plot()` function. The expected posterior
distribution is the posterior distribution that would occur if you actually
observed the planned sample containing the expected misstatements.

```{r}
plot(plan)
```

The input for the `prior` argument can also be an object created by the
`auditPrior` function. If `planning()` receives a prior for which there is no
conjugate likelihood available, it will numerically derive the posterior
distribution. For example, the command below uses a Normal(0, 0.05) prior
distribution to plan the sample using the binomial likelihood. Concretely, this
means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Binomial}(n, \theta) \\
  \theta &\sim \text{Normal}(\mu = 0, \sigma = 0.05)
\end{align}

```{r}
prior <- auditPrior(method = "param", likelihood = "normal",
                    alpha = 0, beta = 0.05)

plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson", prior = prior)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

The resulting sample size under this prior is $n = 90$, a reduction of 8 samples
when compared to the default beta(1, 1) prior distribution.

```{r}
plot(plan)
```

## The Poisson Likelihood

Let's consider how to use the Poisson likelihood to calculate the minimum
sample size needed to achieve the desired level of assurance. The Poisson
distribution is a discrete probability distribution that is commonly used to
model the number of events occurring in a fixed time or space. We can use the
Poisson distribution as a likelihood to model the number of misstatements that
are expected to be found in the sample.

::: {.callout-note}
In audit sampling, the Poisson likelihood is often used to approximate the
binomial likelihood since it is easier to work with (i.e., it only has one
parameter: $\lambda$, while the binomial has two parameters: $\theta$ and $n$).
However, the Poisson likelihood is more conservative than the binomial
likelihood, meaning that resulting sample sizes will be higher.
:::

The probability mass function (PMF) of the Poisson distribution is given by:

\begin{equation}
  p(k; \lambda) = \frac{\lambda^k e^{-\lambda}}{k!},
\end{equation}

where $k$ is the number of misstatements in the sample, and $\lambda$ is the
average number of misstatements expected in the sample. The average number of
misstatements is related to the misstatement rate in the population, denoted by
$\theta$, and the sample size, $n$, by the following equation:

\begin{equation}
  \lambda = n \theta.
\end{equation}

### Classical planning

Concretely, the following statistical model is assumed:

\begin{equation}
  k \sim \text{Poisson}(n \theta_{max})
\end{equation}

#### No Expected Misstatement

Given the performance materiality $\theta_{max}$ and the Poisson likelihood, we
can solve for the minimum sample size $n$ needed to achieve a certain assurance
level. A useful trick to utilize is that, if we do not expect any misstatements
in the sample, the formula for the required sample size reduces to:

\begin{equation}
  n = \lceil-\frac{\ln(\alpha)}{\theta_{max}}\rceil.
\end{equation}

For example, if we want to achieve an assurance level of 95% ($\alpha = 0.05$)
for a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 100$.

```{r}
ceiling(-log(1 - 0.95) / 0.03)
```

In **jfa**, this sample size can be replicated using the following code:

```{r}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "poisson")
```

The sample size of 100 can be confirmed by checking that 100 is the minimum
integer that results in less than 5% probability of finding 0 misstatements,
given the assumption that the population misstatement is truly 3%. The `dpois()`
function calculates the probability of observing $k$ missatements in a sample of
$n$ items given an assumed misstatement probability $\theta_{max}$. By
calculating this probability for $n = 99$, we can show that this sample size is
insufficient as the relevant probability is higher than the sampling risk
$\alpha$.

```{r}
dpois(x = 0, lambda = 99 * 0.03) < 0.05
```

However, for $n = 100$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
dpois(x = 0, lambda = 100 * 0.03) < 0.05
```

We can make this visually intuitive by showing the Poisson($k$ | 100 * 0.03)
distribution and highlighting the probability for $k = 0$. This probability is
lower than the required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dpois(x = 0:10, lambda = 100 * 0.03))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c("firebrick", rep("darkgray", 10)),
           colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5, size = 3) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

#### Expected Misstatements

However, if the number of expected misstatements in the sample is non-zero,
it becomes more difficult to solve the formula for $n$ algebraically. Hence,
they will need to set $k$ to a different integer value. Next, we can iteratively
try every value of $n$ and return the smallest integer that satisfies the
sampling objectives.

For example, if we want to achieve an assurance level of 95% ($\alpha = 0.05$)
for a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of one expected misstatement in the sample is
$n = 159$.

```{r}
planning(materiality = 0.03, expected = 1, conf.level = 0.95,
         likelihood = "poisson")
```

Once again, the sample size of 159 can be confirmed by checking that 159 is the
minimum integer that results in less than 5% probability of finding 0 or 1
misstatements, given the assumption that the population misstatement is truly
3%. By calculating this probability for $n = 158$, we can show that this sample
size is insufficient as the relevant probability is higher than the sampling
risk $\alpha$.

```{r}
sum(dpois(x = 0:1, lambda = 158 * 0.03)) < 0.05
```

However, for $n = 159$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
sum(dpois(x = 0:1, lambda = 159 * 0.03)) < 0.05
```

Like before, we can make this visually intuitive by showing the Poisson($k$ |
159 * 0.03) distribution and highlighting the probabilities for $k = 0$ and
$k = 1$. The sum of these probabilities is lower than the required sampling risk
$\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dpois(x = 0:10, lambda = 159 * 0.03))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c(rep("firebrick", 2), rep("darkgray", 9)),
           colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5, size = 3) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

#### Partial Expected Misstatements

When the expected misstatements in the sample $\theta_{exp}$ is assessed, the
value for $k$ can be determined as $k = n\theta_{exp}$, which consequently
determines how the sample size can be calculated.

To account for the fact that $k$ can have non-integer values in this case, we
use a well-known similarity between the Poisson distribution and the gamma
distribution to plan the sample size. The upper bound for any Poisson($k$;
$n \theta$) distributed variable can also be obtained via percentiles of the
gamma($1 + k$, $n$) distribution. 

For example, the upper bound for a sample of $n = 10$ items containing $k = 2$
misstatements, when calculated via the traditional `poisson.test()` is:

```{r}
ub_pois <- poisson.test(x = 2, T = 10, r = 0.03, conf.level = 0.95,
                        alternative = "less")$conf.int[2]
ub_pois
```

When calculated via the relationship with the gamma distribution, the upper
bound is:

```{r}
ub_gamma <- qgamma(p = 0.95, shape = 1 + k, rate = n)
ub_gamma
```

It can be validated that the two approaches result in the same upper bound via:

```{r}
ub_pois == ub_gamma
```

This relationship between the Poisson likelihood and the gamma distribution is
used under the hood in **jfa**. For example, if we want to achieve an assurance
level of 95% ($\alpha = 0.05$) for a performance materiality of
$\theta_{max} = 0.03$, then the required sample size under the assumption of 1.5
expected misstatements in the sample is $n = 185$.

```{r}
planning(materiality = 0.03, expected = 1.5, conf.level = 0.95,
         likelihood = "poisson")
```

The sample size of 185 can be confirmed by checking that 185 is the minimum
integer that results in less than 5% probability of finding a misstatement rate
in the population equal to, or higher than, 3%. By calculating this probability
for $n = 184$, we can show that this sample size is insufficient as the relevant
upper bound is higher than the performance materiality $\theta_{max}$.

```{r}
qgamma(p = 0.95, shape = 1 + 1.5, rate = 184) < 0.03
```

However, for $n = 185$ the relevant upper bound is lower than the performance
materiality $\theta_{max}$ and thus the sample size is sufficient.

```{r}
qgamma(p = 0.95, shape = 1 + 1.5, rate = 185) < 0.03
```

### Bayesian Planning

Performing Bayesian planning with the Poisson likelihood requires that you
specify a prior distribution for the parameter $\theta$. Practically, this means
that you should provide an input for the `prior` argument in the `planning()`
function.

Setting `prior = TRUE` performs Bayesian planning using a [default prior](https://koenderks.github.io/jfa/articles/creating-prior.html#default-priors-method-default)
conjugate to the specified `likelihood` (i.e., a gamma prior). Concretely, this
means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Poisson}(n\theta) \\
  \theta &\sim \text{Gamma}(\alpha, \beta)
\end{align}

::: {.callout-note}
The gamma prior distribution is the conjugate prior for the Poisson likelihood
(see this [list](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)
of conjugate priors), which means that the posterior distribution of $\theta$
can be determined analytically. For example, if the prior distribution is
gamma($\alpha$, $\beta$) and the auditor has observed a sample of $n$ items
containing $k$ misstatements, the posterior distribution for $\theta$ is
gamma($\alpha + k$, $\beta + n$).
:::

For example, the command below uses a default gamma($\alpha=1$, $\beta=1$) prior
distribution to plan the sample, since `planning()` is given the Poisson
likelihood. If we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 99$.

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson", prior = TRUE)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

You can inspect how the prior distribution compares to the expected
posterior distribution by using the `plot()` function. The expected posterior
distribution is the posterior distribution that would occur if you actually
observed the planned sample containing the expected misstatements.

```{r}
plot(plan)
```

The input for the `prior` argument can also be an object created by the
`auditPrior` function. If `planning()` receives a prior for which there is no
conjugate likelihood available, it will numerically derive the posterior
distribution. For example, the command below uses a Normal(0, 0.05) prior
distribution to plan the sample using the Poisson likelihood. Concretely, this
means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Poisson}(n\theta) \\
  \theta &\sim \text{Normal}(\mu = 0, \sigma = 0.05)
\end{align}

```{r}
prior <- auditPrior(method = "param", likelihood = "normal",
                    alpha = 0, beta = 0.05)

plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson", prior = prior)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

The resulting sample size under this prior is $n = 91$, a reduction of 8 samples
when compared to the default gamma(1, 1) prior.

```{r}
plot(plan)
```

## Practical Examples

This section contains practical examples of how to conduct the planning of
statistical audit samples and demonstrates how to set up a prior distribution
based on various types of relevant audit information.

### Audit Risk Model

In our first example, an auditor is performing tests of details on a population
of the auditee. For instance, let's say an auditor is performing an audit on a
company's accounts payable transactions. The company has a total of $N$ = 1000
accounts payable transactions for the year. Rather than testing all 1000
transactions, the auditor can choose to test a sample of the transactions. The
performance materiality for the payable transactions account is set to
$\theta_{max}$ = 3%, and the audit risk is set to $\alpha = 0.05$, or 5%. Based
on the results of last years audit, where the most likely estimate of the
misstatement was 1%, the auditor wants to tolerate 1% misstatements in the
sample before giving an unqualified opinion on the population.

```{r}
ar          <- 0.05 # Audit risk
materiality <- 0.03 # Performance materiality
expected    <- 0.01 # Tolerable deviation rate
```

Before tests of details, the auditor has assessed risk of material
misstatement via the audit risk model. In this example, the auditor has assessed
the effectiveness of the company's internal controls, such as its segregation of
duties and its risk management processes, and has determined that they are
sufficient to prevent or detect material misstatements. Because the internal
control systems were effective, the auditor assesses the control risk as medium.
The auditor's firm defines the risk categories low, medium, and high
respectively as 50%, 60%, and 100%. According to the Audit Risk Model, the
detection risk can be calculated as a function of the audit risk, the inherent
risk and the control risk.

```{r}
ir <- 1              # Inherent risk
cr <- 0.6            # Control risk
dr <- ar / (ir * cr) # Detection risk
dr
```

By using the detection risk of 8.33% as the sampling risk for this population,
the auditor can plan for a sample while taking into account the risk-reducing
information. The required minimum sample size is 174 in this case.

```{r}
planning(materiality = 0.03, expected = expected, conf.level = 1 - dr)
```

The example above is a frequentist one. However, the auditor is free to apply a
Bayesian philosophy in planning the sample. For example, the risk assessments
from the ARM can be incorporated into a prior distribution. This can be done
using `method = "arm"` in the `auditPrior()` function, which takes the values of
the inherent risk probability `ir` and the control risk probability `cr`. Hence,
the prior distribution in this example can be constructed using the following
command:

```{r}
prior <- auditPrior(method = "arm", materiality = 0.03, expected = expected,
                    ir = ir, cr = cr)
```

The `summary()` function can be used to obtain relevant information about the
prior distribution.

```{r}
summary(prior)
```

Furthermore, the prior distribution can be visualized with a call to the
`plot()` function.

```{r}
plot(prior)
```

By using the prior distribution to incorporate the assessments of the inherent
risk and the control risk, the auditor can plan a sample while taking into
account the risk-reducing information. The required minimum sample size
is also 174 in this case.

```{r}
planning(materiality = 0.03, expected = expected, conf.level = 1 - ar,
         prior = prior)
```

### Benchmark Analysis

The auditor may incorporate information obtained through analytical procedures
[@Derks2021], such as a benchmark analysis, into the prior distribution for
$\theta$. While we have previously discussed methods for constructing a prior
distribution based on existing knowledge, there is no set procedure for
incorporating information obtained through analytical procedures, as these
procedures can vary significantly depending on the type of information being
incorporated into the prior distribution. Therefore, it is important to
thoroughly substantiate the data and assumptions used in this approach and to
carefully consider how these assumptions are incorporated into the prior
distribution.

One way to construct a prior distribution on the basis of data is through the
use of regression models, such as benchmarking the relationship between sales
and costs of sales within the auditee's specific industry sector. The **jfa**
package includes a data set `benchmark` that can be used for this example.

```{r}
data(benchmark)
head(benchmark)
```

The auditee's the sum of the sales is $298,112,312 and the sum of the booked
costs of sales is $223,994,405, respectively. This is indicated by a blue dot in
the figure below, which visualizes the industry sales versus the cost of sales.

```{r}
C_real <- 223994405
```

```{r echo = FALSE, fig.width = 7, fig.height = 6, fig.align = "center"}
breaks <- pretty(c(benchmark$sales, benchmark$costofsales))
labels <- paste0("$", format(breaks / 1000000, scientific = FALSE), "M")
p <- ggplot(data = benchmark, mapping = aes(x = sales, y = costofsales)) +
  geom_point(shape = 21, fill = "darkgray", size = 2) +
  geom_point(data = data.frame(x = 298112312, y = C_real), shape = 21,
             mapping = aes(x = x, y = y), fill = "dodgerblue", size = 2.5,
             inherit.aes = FALSE, show.legend = FALSE) +
  scale_x_continuous(name = "Sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  scale_y_continuous(name = "Cost of sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  geom_segment(x = -Inf, xend = -Inf, y = min(breaks), yend = max(breaks)) +
  geom_segment(x = min(breaks), xend = max(breaks), y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

The relationship between the sales $S$ and the cost of sales $C$ can be modelled
by a linear equation:

\begin{equation}
  C = \beta_0 + \beta_1 \cdot S + \epsilon.
\end{equation}

In practice, this relationship is often more complex than is presented above,
and the auditor must carefully construct and evaluate the applied regression
model. However, for ease of understanding we will continue our example with this
simplified model. The auditor can estimate the regression model using the
following command:

```{r}
fit <- lm(costofsales ~ 1 + sales, data = benchmark)
summary(fit)
```

The predicted cost of sales for the auditee, based on the industry benchmark,
can be computed as follows:

```{r}
C_pred <- predict(fit, newdata = data.frame(sales = 298112312),
                  interval = "prediction", level = 0.90)[1]
C_pred
```

The fitted regression line and the predicted cost of sales (red dot) are
visualized in the figure below:

```{r echo = FALSE, fig.width = 7, fig.height = 6, fig.align = "center"}
breaks <- pretty(c(benchmark$sales, benchmark$costofsales))
labels <- paste0("$", format(breaks / 1000000, scientific = FALSE), "M")
p <- ggplot(data = benchmark, mapping = aes(x = sales, y = costofsales)) +
  geom_smooth(stat = "smooth", formula = y ~ x, method = "lm",
              colour = "black", linewidth = 0.5) +
  geom_point(shape = 21, fill = "darkgray", size = 2) +
  geom_point(data = data.frame(x = 298112312, y = C_real), shape = 21,
             mapping = aes(x = x, y = y), fill = "dodgerblue", size = 2.5,
             inherit.aes = FALSE, show.legend = FALSE) +
  geom_point(data = data.frame(x = 298112312, y = C_pred), shape = 21,
             mapping = aes(x = x, y = y), fill = "firebrick", size = 2.5,
             inherit.aes = FALSE, show.legend = FALSE) +
  scale_x_continuous(name = "Sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  scale_y_continuous(name = "Cost of sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  geom_segment(x = -Inf, xend = -Inf, y = min(breaks), yend = max(breaks)) +
  geom_segment(x = min(breaks), xend = max(breaks), y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

The prior distribution can be justified by the data and the auditee's numerical
prediction of the cost of sales. In this analytical procedure, the prior
distribution on $\theta$ can utilize the relative error distribution from the
linear regression. This relative error distribution, which is a Normal($\mu$,
$\sigma$) distribution, captures the uncertainty of the prediction of the cost
of sales through the use of linear regression, scaled to be a percentage of the
total cost of sales. The mean $\mu$ of the prior distribution is determined by
the relative deviation of the auditee's booked cost of sales when compared to
the predicted cost of sales according to the benchmark data
$\frac{C - \hat{C}}{C}$.

```{r}
mu <- (C_real - C_pred) / C_real
mu
```

The standard deviation of the prior distribution is expressed through the
standard deviation of the distribution of $\epsilon$:

```{r}
stdev <- sd(fit$residuals) / C_real
stdev
```

The Normal(0.019, 0.05) prior distribution can be constructed through a call to
`auditPrior()`, where the likelihood of the prior is specified as `normal`. We
call the function with `method = "param"` to manually specify the parameters of
the prior distribution.

```{r}
prior <- auditPrior(method = "param", likelihood = "normal",
                    alpha = mu, beta = stdev)
summary(prior)
```

The specified prior distribution can be visualized using the `plot()` function.

```{r}
plot(prior)
```

By using this prior distribution, the required minimum sample size is 50.

```{r}
plan <- planning(materiality = 0.05, conf.level = 0.95,
                 likelihood = "binomial", prior = prior)
plan
```

You can inspect how the prior distribution compares to the expected posterior
distribution by using the `plot()` function.

```{r}
plot(plan)
```
