```{r echo = FALSE, cache = FALSE}
source("utils.R", local = TRUE)
```

# Planning a Sample {#CHAPTER-3}

This chapter discusses the most commonly used approaches to plan a statistical
audit sample.

![](img/planning.png)

One of the key considerations in audit sampling is determining the minimum
sample size required to achieve a desired level of assurance or precision. In
this chapter, we will discuss how to use three standard likelihoods to plan a
minimum sample size for audit sampling: the hypergeometric likelihood, the
binomial likelihood and the Poisson likelihood.

## Required Information

First, planning a minimum sample requires knowledge of the conditions that lead 
to acceptance or rejection of the population (i.e., the sampling objectives).
Typically, sampling objectives can be classified into one or both of the
following:

- **Hypothesis testing**: The goal of the sample is to obtain evidence for or
  against the claim that the misstatement in the population is lower than a
  given value (i.e., the performance materiality).
- **Estimation**: The goal of the sample is to obtain an accurate estimate of
  the misstatement in the population (with a minimum precision).

Second, it is advised to specify the expected (or tolerable) misstatements in
the sample. The expected misstatements are the misstatements that you allow in
the sample, while still retaining the desired amount of assurance about the 
population. It is strongly recommended to set the value for the expected
misstatements in the sample conservatively to minimize the chance of the
observed misstatements in the sample exceeding the expected misstatements, which
would imply that insufficient work has been done in the end.

Finally, next to determining the sampling objective(s) and the expected
misstatements, it is important to determine the statistical distribution linking
the sample outcomes to the population misstatement. This distribution is called
the likelihood (i.e., `poisson`, `binomial`, or `hypergeometric`). All three
aforementioned likelihoods are commonly used in an audit sampling context,
however, `poisson` is the default likelihood in **jfa** because it is the most
conservative of the three. In the subsections below, we elaborate on the three
standard likelihoods for audit sampling and demonstrate how they can be used
to obtain a minimum sample size.

## The Hypergeometric Likelihood

Let's consider how to use the hypergeometric likelihood to calculate the
minimum sample size needed to achieve a desired level of assurance. The
hypergeometric distribution is a discrete probability distribution that is
commonly used to model the number of events occurring in a fixed number of
trials when the population size is known. For our purpose, we can use the
hypergeometric distribution as a likelihood to model the number of misstatements
that are expected to be found in the sample.

The probability mass function (PMF) of the hypergeometric distribution is given
by:

\begin{equation}
  p(X=k)=\frac{\binom{K}{k}\binom{N-K}{n-k}}{\binom{N}{n}},
\end{equation}

where $k$ is the number of misstatements in the sample, $n$ is the sample size,
$N$ is the population size and $K$ is the total number of misstatements assumed
in the population. The assumed misstatements $K$ is a linear extrapolation of
the assumed misstatement rate in the population $\theta_{max}$ to the total
population:

\begin{equation}
  K = \theta_{max} N.
\end{equation}

### Classical planning

Concretely, the following statistical model is assumed:

\begin{equation}
  k \sim \text{Hypergeometric}(n, N, K)
\end{equation}

Given a desired misstatement tolerance $\theta_{max}$, we can solve for the
minimum sample size $n$ needed to achieve this assurance level. In **jfa**,
this sample size can be calculated using the `planning()` function. For example,
if we want to achieve an assurance level of 95% ($\alpha=0.05$) for a
performance materiality of $\theta_{max} = 0.03$ in a population of $N=1000$
items, then the required sample size under the assumption of zero expected
misstatements in the sample is $n = 94$.

```{r}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "hypergeometric", N.units = 1000)
```

The `dhyper()` function calculates the probability of observing $k$ missatements
in a sample of $n$ items given an assumed misstatement probability. The sample
size of 94 can be confirmed by checking that 94 is the minimum integer that
results in less than 5% probability of finding 0 misstatements if the population
misstatement is truly 3%.

```{r}
K <- ceiling(0.03 * 1000)
dhyper(x = 0, m = K, n = 1000 - K, k = 93) < 0.05 # 93: Not sufficient
dhyper(x = 0, m = K, n = 1000 - K, k = 94) < 0.05 # 94: Sufficient
```

We can make this visually intuitive by showing the hypergeometric($k$ | 94,
1000, 30) distribution and highlighting the probability for $k = 0$. This
probability should be lower than the required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dhyper(x = 0:10, m = K, n = 1000 - K, k = 94))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c("firebrick", rep("darkgray", 10)), colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

As another example, if we want to achieve an assurance level of 95%
($\alpha=0.05$) for a performance materiality of $\theta_{max} = 0.03$ in a
population of $N=1000$ items, then the required sample size under the assumption
of one expected misstatement in the sample is $n = 147$.

```{r}
planning(materiality = 0.03, expected = 1, conf.level = 0.95,
         likelihood = "hypergeometric", N.units = 1000)
```

Once again, the sample size of 147 can be confirmed by checking that 147 is the
minimum integer that results in less than 5% probability of finding 0 or 1
misstatements if the population misstatement is truly 3%.

```{r}
sum(dhyper(x = 0:1, m = K, n = 1000 - K, k = 146)) < 0.05 # 146: Not sufficient
sum(dhyper(x = 0:1, m = K, n = 1000 - K, k = 147)) < 0.05 # 147: Sufficient
```

Like before, we can make this visually intuitive by showing the
hypergeometric($k$ | 147, 1000, 30) distribution and highlighting the
probabilities for $k = 0$ and $k = 1$. The sum of these probabilities should be
lower than the required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dhyper(x = 0:10, m = K, n = 1000 - K, k = 147))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c(rep("firebrick", 2), rep("darkgray", 9)),
           colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

### Bayesian Planning

Performing Bayesian planning with the hypergeometric likelihood [@Dyer1993]
requires that you specify a prior distribution for the parameter $\theta$.
Practically, this means that you should provide an input for the `prior`
argument in the `planning()` function.

Setting `prior = TRUE` performs Bayesian planning using a [default prior](https://koenderks.github.io/jfa/articles/creating-prior.html#default-priors-method-default)
conjugate to the specified `likelihood` (i.e., a beta-binomial prior).
Concretely, this means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Hypergeometric}(n, N, K) \\
  K &\sim \text{Beta-binomial}(N, \alpha, \beta)
\end{align}

> The beta-binomial prior distribution is conjugate to the hypergeometric
likelihood (see this [list](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)
of conjugate priors), which means that the posterior distribution of $K$ can be
determined analytically. For example, if the prior distribution for $K$ is
beta-binomial($N$, $\alpha$, $\beta$) and the auditor has observed a sample of
$n$ items containing $k$ misstatements, the posterior distribution for $K$ is
beta-binomial($N - n$, $\alpha + k$, $\beta + n - k$).

For example, the command below uses a default beta-binomial($N$, 1, 1) prior
distribution to plan the sample, since `planning()` is given the hypergeometric
likelihood. If we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$ in a population of $N=1000$
items, then the required sample size under the assumption of zero expected
misstatements in the sample is $n = 93$.

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "hypergeometric", N.units = 1000, prior = TRUE)
summary(plan)
```

You can inspect how the prior distribution compares to the expected
posterior distribution by using the `plot()` function. The expected posterior
distribution is the posterior distribution that would occur if you actually
observed the planned sample containing the expected misstatements.

```{r}
plot(plan)
```

The hypergeometric likelihood does not allow for non-conjugate prior
distributions to be used as a prior.

## The Binomial Likelihood

Let's consider how to use the binomial likelihood to calculate the minimum
sample size needed to achieve a desired level of assurance. The binomial
distribution is a discrete probability distribution that is commonly used to
model the number of events occurring in a fixed number of trials. For our
purpose, we can use the binomial distribution as a likelihood to model the
number of misstatements that are expected to be found in the sample. 

> In audit sampling, the binomial likelihood is often used to approximate the
hypergeometric likelihood since it is easier to work with (i.e., it only has two
parameters: $\theta$ and $n$, while the hypergeometric has three: $n$, $N$, and
$K$). However, the binomial likelihood is more conservative than the
hypergeometric likelihood, meaning that resulting sample sizes will be higher.

The probability mass function (PMF) of the binomial distribution is given by:

\begin{equation}
  p(k; n, \theta) = \binom{n}{k} \theta^{k} (1-\theta)^{n - k},
\end{equation}

where $k$ is the number of misstatements in the sample, $n$ is the sample size
and $\theta$ is the misstatement rate expected in the sample.

### Classical Planning

Concretely, the following statistical model is assumed:

\begin{equation}
  k \sim \text{Binomial}(n, \theta_{max})
\end{equation}

Given a desired misstatement tolerance $\theta_{max}$, we can solve for
the minimum sample size $n$ needed to achieve the desired assurance level. A
useful trick to utilize is that, if we do not expect any misstatements in the
sample, the formula for the minimum required sample size reduces to:

\begin{equation}
  n = \lceil\frac{\ln(\alpha)}{\ln(1 - \theta_{max})}\rceil.
\end{equation}

> $\lceil...\rceil$ is the ceiling function. Hence, $\lceil1.2\rceil = 2$.

For example, if we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 99$.

```{r}
ceiling(log(1 - 0.95) / log(1 - 0.03))
```

In **jfa**, this sample size can be replicated using the `planning()` function.

```{r}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "binomial")
```

The `dbinom()` function calculates the probability of observing $k$ missatements
in a sample of $n$ items given an assumed misstatement probability. The sample
size of 99 can be confirmed by checking that 99 is the minimum integer that
results in less than 5% probability of finding 0 misstatements if the population
misstatement is truly 3%.

```{r}
dbinom(x = 0, size = 98, prob = 0.03) < 0.05 # 98: Not sufficient
dbinom(x = 0, size = 99, prob = 0.03) < 0.05 # 99: Sufficient
```

We can make this visually intuitive by showing the binomial($k$ | 99, 0.03)
distribution and highlighting the probability for $k = 0$. This probability
should be lower than the required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dbinom(x = 0:10, size = 99, prob = 0.03))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c("firebrick", rep("darkgray", 10)), colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

However, if the number of expected misstatements in the sample is non-zero,
it becomes more difficult to solve the formula for $n$. Hence, we can
iteratively try every value of $n$ and return the smallest integer that
satisfies the sampling objectives. In **jfa**, this can be done by adjusting the
`expected` argument in the `planning()` function. For example, if we want to
achieve an assurance level of 95% ($\alpha=0.05$) for a performance materiality
of $\theta_{max} = 0.03$, then the required sample size under the assumption of
one expected misstatement in the sample is $n = 157$.

```{r}
planning(materiality = 0.03, expected = 1, conf.level = 0.95,
         likelihood = "binomial")
```

Once again, the sample size of 157 can be confirmed by checking that 157 is the
minimum integer that results in less than 5% probability of finding 0 or 1
misstatements if the population misstatement is truly 3%.

```{r}
sum(dbinom(x = 0:1, size = 156, prob = 0.03)) < 0.05 # 156: Not sufficient
sum(dbinom(x = 0:1, size = 157, prob = 0.03)) < 0.05 # 157: Sufficient
```

Like before, we can make this visually intuitive by showing the
binomial($k$ | 157, 0.03) distribution and highlighting the probabilities for
$k = 0$ and $k = 1$. The sum of these probabilities should be lower than the
required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dbinom(x = 0:10, size = 157, prob = 0.03))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c(rep("firebrick", 2), rep("darkgray", 9)),
           colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

### Bayesian Planning

Performing Bayesian planning with the binomial likelihood requires that you
specify a prior distribution for the parameter $\theta$. Practically, this means
that you should provide an input for the `prior` argument in the `planning()`
function.

Setting `prior = TRUE` performs Bayesian planning using a [default prior](https://koenderks.github.io/jfa/articles/creating-prior.html#default-priors-method-default)
conjugate to the specified `likelihood` (i.e., a beta prior). Concretely, this
means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Binomial}(n, \theta) \\
  \theta &\sim \text{Beta}(\alpha, \beta)
\end{align}

> The beta prior distribution is conjugate to the binomial likelihood (see
this [list](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)
of conjugate priors), which means that the posterior distribution of $\theta$
can be determined analytically. For example, if the prior distribution is
beta($\alpha$, $\beta$) and the auditor has observed a sample of $n$ items
containing $k$ misstatements, the posterior distribution for $\theta$ is
beta($\alpha + k$, $\beta + n - k$).

For example, the command below uses a default beta($\alpha=1$, $\beta=1$) prior
distribution to plan the sample, since `planning()` is given the binomial
likelihood. If we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 98$.

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "binomial", prior = TRUE)
summary(plan)
```

You can inspect how the prior distribution compares to the expected
posterior distribution by using the `plot()` function. The expected posterior
distribution is the posterior distribution that would occur if you actually
observed the planned sample containing the expected misstatements.

```{r}
plot(plan)
```

The input for the `prior` argument can also be an object created by the
`auditPrior` function. If `planning()` receives a prior for which there is no
conjugate likelihood available, it will numerically derive the posterior
distribution. For example, the command below uses a Normal(0, 0.05) prior
distribution to plan the sample using the binomial likelihood. Concretely, this
means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Binomial}(n, \theta) \\
  \theta &\sim \text{Normal}(\mu = 0, \sigma = 0.05)
\end{align}

```{r}
prior <- auditPrior(method = "param", likelihood = "normal",
                    alpha = 0, beta = 0.05)

plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson", prior = prior)

summary(plan)
```

The resulting sample size under this prior is $n = 90$, a reduction of 8 samples
when compared to the default beta(1, 1) prior distribution.

```{r}
plot(plan)
```

## The Poisson Likelihood

Let's consider how to use the Poisson likelihood to calculate the minimum
sample size needed to achieve a desired level of assurance. The Poisson
distribution is a discrete probability distribution that is commonly used to
model the number of events occurring in a fixed time or space. We can use the
Poisson distribution as a likelihood to model the number of misstatements that
are expected to be found in the sample.

> In audit sampling, the Poisson likelihood is often used to approximate the
binomial likelihood since it is easier to work with (i.e., it only has one
parameter: $\lambda$, while the binomial has two parameters: $\theta$ and $n$).
However, the Poisson likelihood is more conservative than the binomial
likeliood, meaning that resulting sample sizes will be higher.

The probability mass function (PMF) of the Poisson distribution is given by:

\begin{equation}
  p(k; \lambda) = \frac{\lambda^k e^{-\lambda}}{k!},
\end{equation}

where $k$ is the number of misstatements in the sample, and $\lambda$ is the
average number of misstatements expected in the sample. The average number of
misstatements is related to the misstatement rate in the population, denoted by
$\theta$, and the sample size, $n$, by the following equation:

\begin{equation}
  \lambda=n\theta.
\end{equation}

### Classical planning

Concretely, the following statistical model is assumed:

\begin{equation}
  k \sim \text{Poisson}(n\theta_{max})
\end{equation}

Given a desired misstatement tolerance $\theta_{max}$ and the Poisson
likelihood, we can solve for the minimum sample size $n$ needed to achieve a
assurance level. A useful trick to utilize is that, if we do not expect any
misstatements in the sample, the formula for the required sample size reduces
to:

\begin{equation}
  n = \lceil-\frac{\ln(\alpha)}{\theta_{max}}\rceil.
\end{equation}

> $\lceil...\rceil$ is the ceiling function. Hence, $\lceil1.2\rceil = 2$.

For example, if we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 100$.

```{r}
ceiling(-log(1 - 0.95) / 0.03)
```

In **jfa**, this sample size can be replicated using the `planning()` function.

```{r}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "poisson")
```

The `dpois()` function calculates the probability of observing $k$ missatements
in a sample of $n$ items given an assumed misstatement probability. The sample
size of 100 can be confirmed by checking that 100 is the minimum integer that
results in less than 5% probability of finding 0 misstatements if the population
misstatement is truly 3%.

```{r}
dpois(x = 0, lambda = 99 * 0.03) < 0.05  # 99:  Not sufficient
dpois(x = 0, lambda = 100 * 0.03) < 0.05 # 100: Sufficient
```

We can make this visually intuitive by showing the Poisson($k$ | 100 * 0.03)
distribution and highlighting the probability for $k = 0$. This probability
should be lower than the required sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dpois(x = 0:10, lambda = 100 * 0.03))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c("firebrick", rep("darkgray", 10)),
           colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

However, if the number of expected misstatements in the sample is non-zero,
it becomes more difficult to solve the formula for $n$. Hence, we can
iteratively try every value of $n$ and return the smallest integer that
satisfies the sampling objectives. In **jfa**, this can be done by adjusting the
`expected` argument in the `planning()` function. For example, if we want to
achieve an assurance level of 95% ($\alpha=0.05$) for a performance materiality
of $\theta_{max} = 0.03$, then the required sample size under the assumption of
one expected misstatement in the sample is $n = 159$.

```{r}
planning(materiality = 0.03, expected = 1, conf.level = 0.95,
         likelihood = "poisson")
```

Once again, the sample size of 159 can be confirmed by checking that 159 is the
minimum integer that results in less than 5% probability of finding 0 or 1
misstatements if the population misstatement is truly 3%.

```{r}
sum(dpois(x = 0:1, lambda = 158 * 0.03)) < 0.05 # 158: Not sufficient
sum(dpois(x = 0:1, lambda = 159 * 0.03)) < 0.05 # 159: Sufficient
```

Like before, we can make this visually intuitive by showing the Poisson($k$ |
159 * 0.03) distribution and highlighting the probabilities for $k = 0$ and
$k = 1$. The sum of these probabilities should be lower than the required
sampling risk $\alpha = 0.05$.

```{r echo = FALSE}
df <- data.frame(x = 0:10, y = dpois(x = 0:10, lambda = 159 * 0.03))
y_breaks <- pretty(df$y, min.n = 4)
p <- ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_col(position = "identity",
           fill = c(rep("firebrick", 2), rep("darkgray", 9)),
           colour = "black") +
  annotate(geom = "text", x = df$x, y = df$y, label = round(df$y, 3),
           vjust = -0.5) +
  scale_x_continuous(name = "Misstatements", breaks = 0:10) +
  scale_y_continuous(name = "Probability", breaks = y_breaks,
                     limits = range(y_breaks)) +
  geom_segment(x = -Inf, xend = -Inf, y = min(y_breaks), yend = max(y_breaks)) +
  geom_segment(x = 0, xend = 10, y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

### Bayesian Planning

Performing Bayesian planning with the Poisson likelihood requires that you
specify a prior distribution for the parameter $\theta$. Practically, this means
that you should provide an input for the `prior` argument in the `planning()`
function.

Setting `prior = TRUE` performs Bayesian planning using a [default prior](https://koenderks.github.io/jfa/articles/creating-prior.html#default-priors-method-default)
conjugate to the specified `likelihood` (i.e., a gamma prior). Concretely, this
means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Poisson}(n\theta) \\
  \theta &\sim \text{Gamma}(\alpha, \beta)
\end{align}

> The gamma prior distribution is conjugate to the Poisson likelihood (see
this [list](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)
of conjugate priors), which means that the posterior distribution of $\theta$
can be determined analytically. For example, if the prior distribution is
gamma($\alpha$, $\beta$) and the auditor has observed a sample of $n$ items
containing $k$ misstatements, the posterior distribution for $\theta$ is
gamma($\alpha + k$, $\beta + n$).

For example, the command below uses a default gamma($\alpha=1$, $\beta=1$) prior
distribution to plan the sample, since `planning()` is given the Poisson
likelihood. If we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 99$.

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson", prior = TRUE)
summary(plan)
```

You can inspect how the prior distribution compares to the expected
posterior distribution by using the `plot()` function. The expected posterior
distribution is the posterior distribution that would occur if you actually
observed the planned sample containing the expected misstatements.

```{r}
plot(plan)
```

The input for the `prior` argument can also be an object created by the
`auditPrior` function. If `planning()` receives a prior for which there is no
conjugate likelihood available, it will numerically derive the posterior
distribution. For example, the command below uses a Normal(0, 0.05) prior
distribution to plan the sample using the Poisson likelihood. Concretely, this
means that the following statistical model is assumed:

\begin{align}
  k &\sim \text{Poisson}(n\theta) \\
  \theta &\sim \text{Normal}(\mu = 0, \sigma = 0.05)
\end{align}

```{r}
prior <- auditPrior(method = "param", likelihood = "normal",
                    alpha = 0, beta = 0.05)

plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson", prior = prior)

summary(plan)
```

The resulting sample size under this prior is $n = 91$, a reduction of 8 samples
when compared to the default gamma(1, 1) prior.

```{r}
plot(plan)
```

## Practical Examples

This section contains practical examples of how to construct a prior
distribution based on audit information.

### Audit Risk Model

In this example, an auditor is performing tests of details on a population of
the auditee. For instance, let's say an auditor is performing an audit on a
company's accounts payable transactions. The company has a total of $N$ = 1000
accounts payable transactions for the year. Rather than testing all 1000
transactions, the auditor can choose to test a sample of the transactions. The
performance materiality for the payable transactions account is set to 3%. Based
on the results of last years audit, where the estimate of the maximum
misstatement was 1%, the auditor wants to tolerate 1% misstatements in the
sample before giving an unqualified opinion on the population.

```{r}
ar          <- 0.05 # Audit risk
materiality <- 0.03 # Performance materiality
expected    <- 0.01 # Tolerable deviation rate
```

Before tests of details, the auditor has assessed risk of material
misstatement via the audit risk model. In this example, the auditor has assessed
the effectiveness of the company's internal controls, such as its segregation of
duties and its risk management processes, and has determined that they are
sufficient to prevent or detect material misstatements. Because the internal
control systems were effective, the auditor assesses the control risk as medium.
The auditor's firm defines the risk categories low, medium, and high
respectively as 50%, 60%, and 100%.

```{r}
ir <- 1              # Inherent risk
cr <- 0.6            # Control risk
dr <- ar / (ir * cr) # Detection risk
```

By using the detection risk as the adjusted audit risk, the auditor can plan
for a sample while taking into account the risk-reducing information from the
assessments of inherent risk and control risk. The required minimum sample size
is 174 in this case.

```{r}
planning(materiality = 0.03, expected = expected, conf.level = 1 - dr)
```

The auditor is free to apply a Bayesian philosophy in planning the sample. For
example, the risk assessments from the ARM can be incorporated into a prior
distribution. This can be done using `method = "arm"` in the `auditPrior()`
function, which takes the values of the inherent risk probability `ir` and the
control risk probability `cr`. Hence, the prior distribution in this example
can be constructed using the following command:

```{r}
prior <- auditPrior(method = "arm", materiality = 0.03, expected = expected,
                    ir = ir, cr = cr)
summary(prior)
```

The prior distribution can be visualized using the `plot()` function.

```{r}
plot(prior)
```

By using the prior distribution to incorporate the assessments of the inherent
risk and the control risk, the auditor can plan a sample while taking into
account the risk-reducing information. The required minimum sample size
is also 174 in this case.

```{r}
planning(materiality = 0.03, expected = expected, conf.level = 1 - ar,
         prior = prior)
```

### Benchmark Analysis

The auditor may incorporate information obtained through analytical procedures
[@Derks2021], such as a benchmark analysis, into the prior distribution for
$\theta$. While we have previously discussed methods for constructing a prior
distribution based on existing knowledge, there is no set procedure for
incorporating information obtained through analytical procedures, as these
procedures can vary significantly depending on the type of information being
incorporated into the prior distribution. Therefore, it is important to
thoroughly substantiate the data and assumptions used in this approach and to
carefully consider how these assumptions are incorporated into the prior
distribution.

One way to construct a prior distribution on the basis of data is through the
use of regression models, such as benchmarking the relationship between sales
and costs of sales within the auditee's specific industry sector. The **jfa**
package includes a data set `benchmark` that can be used for this example.

```{r}
data(benchmark)
head(benchmark)
```

The auditee's the sum of the sales is $298,112,312 and the sum of the booked
costs of sales is $223,994,405, respectively. This is indicated by a blue dot in
the figure below, which visualizes the industry sales versus the cost of sales.

```{r echo = FALSE, fig.width = 7, fig.height = 6, fig.align = "center"}
breaks <- pretty(c(benchmark$sales, benchmark$costofsales))
labels <- paste0("$", format(breaks / 1000000, scientific = FALSE), "M")
p <- ggplot(data = benchmark, mapping = aes(x = sales, y = costofsales)) +
  geom_point(shape = 21, fill = "darkgray", size = 2) +
  geom_point(data = data.frame(x = 298112312, y = 223994405), shape = 21,
             mapping = aes(x = x, y = y), fill = "dodgerblue", size = 2.5,
             inherit.aes = FALSE, show.legend = FALSE) +
  scale_x_continuous(name = "Sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  scale_y_continuous(name = "Cost of sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  geom_segment(x = -Inf, xend = -Inf, y = min(breaks), yend = max(breaks)) +
  geom_segment(x = min(breaks), xend = max(breaks), y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

The relationship between the sales $S$ and the cost of sales $C$ can be modelled
by a linear equation:

\begin{equation}
  C = \beta_0 + \beta_1 \cdot S + \epsilon.
\end{equation}

In practice, this relationship is often more complex than is presented above,
and the auditor must carefully construct and evaluate the applied regression
model. However, for ease of understanding we will continue our example with this
simplified model. The auditor can estimate the regression model using the
following command:

```{r}
fit <- lm(costofsales ~ 1 + sales, data = benchmark)
summary(fit)
```

The predicted cost of sales for the auditee, based on the industry benchmark,
can be computed as follows:

```{r}
C_hat <- predict(fit, newdata = data.frame(sales = 298112312),
                 interval = "prediction", level = 0.90)[1]
C_hat
```

The fitted regression line and the predicted cost of sales (red dot) are
visualized in the figure below:

```{r echo = FALSE, fig.width = 7, fig.height = 6, fig.align = "center"}
breaks <- pretty(c(benchmark$sales, benchmark$costofsales))
labels <- paste0("$", format(breaks / 1000000, scientific = FALSE), "M")
p <- ggplot(data = benchmark, mapping = aes(x = sales, y = costofsales)) +
  geom_smooth(stat = "smooth", formula = y ~ x, method = "lm",
              colour = "black", linewidth = 0.5) +
  geom_point(shape = 21, fill = "darkgray", size = 2) +
  geom_point(data = data.frame(x = 298112312, y = 223994405), shape = 21,
             mapping = aes(x = x, y = y), fill = "dodgerblue", size = 2.5,
             inherit.aes = FALSE, show.legend = FALSE) +
  geom_point(data = data.frame(x = 298112312, y = C_hat), shape = 21,
             mapping = aes(x = x, y = y), fill = "firebrick", size = 2.5,
             inherit.aes = FALSE, show.legend = FALSE) +
  scale_x_continuous(name = "Sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  scale_y_continuous(name = "Cost of sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  geom_segment(x = -Inf, xend = -Inf, y = min(breaks), yend = max(breaks)) +
  geom_segment(x = min(breaks), xend = max(breaks), y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

The prior distribution can be justified by the data and the auditee's numerical
prediction of the cost of sales. In this analytical procedure, the prior
distribution on $\theta$ can utilize the relative error distribution from the
linear regression. This relative error distribution, which is a Normal($\mu$,
$\sigma$) distribution, captures the uncertainty of the prediction of the cost
of sales through the use of linear regression, scaled to be a percentage of the
total cost of sales. The mean $\mu$ of the prior distribution is determined by
the relative deviation of the auditee's booked cost of sales when compared to
the predicted cost of sales according to the benchmark data
$\frac{C - \hat{C}}{C}$.

```{r}
mu <- (223994405 - C_hat) / 223994405
mu
```

The standard deviation of the prior distribution is expressed through the
standard deviation of the distribution of $\epsilon$:

```{r}
stdev <- sd(fit$residuals) / 223994405
stdev
```

The Normal(0.019, 0.05) prior distribution can be constructed through a call to
`auditPrior()`, where the likelihood of the prior is specified as `normal`. We
call the function with `method = "param"` to manually specify the parameters of
the prior distribution.

```{r}
prior <- auditPrior(method = "param", likelihood = "normal",
                    alpha = mu, beta = stdev)
summary(prior)
```

The specified prior distribution can be visualized using the `plot()` function.

```{r}
plot(prior)
```

By using this prior distribution, the required minimum sample size is 50.

```{r}
plan <- planning(materiality = 0.05, conf.level = 0.95,
                 likelihood = "binomial", prior = prior)
plan
```

You can inspect how the prior distribution compares to the expected posterior
distribution by using the `plot()` function.

```{r}
plot(plan)
```

## References
