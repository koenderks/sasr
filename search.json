[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Audit Sampling with R",
    "section": "",
    "text": "Welcome\nThis book, Statistical Audit Sampling with R, is intended as a practical guide for auditors who wish to utilize state-of-the-art statistical methodology in their audit sampling activities. While the focus of this book is exclusively on audit sampling, it aims to examine the topic from both the classical (frequentist) perspective and the Bayesian perspective. By examining the subject through these two lenses, the book explains the statistical theory behind commonly used audit sampling procedures and demonstrates how to perform these procedures in accordance with international auditing standards, using the jfa R package, in a statistically sound manner."
  },
  {
    "objectID": "ch00.html",
    "href": "ch00.html",
    "title": "Preface",
    "section": "",
    "text": "This book is intended for auditors that want to obtain the knowledge and skill to utilize statistical audit sampling in their practice using the R programming language. It covers an array of traditional and innovative statistical tools that are available to auditors, explaining their function, the underlying assumptions, and when they are best utilized. In addition, it offers practical guidance on integrating advanced statistical sampling methodology into audit practice and demonstrates its value through real-world case studies. It is our hope that this book will serve as a valuable resource for auditors looking to effectively and efficiently utilize statistical methods in their practice.\nThe aim of this book is to address the need for a clear and transparent explanation of the use of statistical sampling methodology in audit practice. In my opinion, most guidance about audit sampling (e.g., American Institute of Certified Public Accountants (AICPA) (2016a); American Institute of Certified Public Accountants (AICPA) (2016b)) lacks sufficient detail to allow for full transparency or a deep understanding (one notable exception is Stewart (2012)). Additionally, the implementation of statistical sampling methodology in practice is often even less transparent, as theory and calculations are hidden from auditors in commercial closed-source tools or in Excel sheets from audit guides used internally by audit firms. Thus, while attempting to comprehend the theoretical aspects of statistical audit sampling, auditors may encounter numerous relevant questions that are left unanswered by these tools. This book aims to clarify the statistical methodology utilized in practice, thereby empowering auditors through a comprehensive explanation.\nThis book discusses the topic of audit sampling from both a classical (frequentist) and a Bayesian perspective. By utilizing these two approaches, the book elucidates the statistical theory that underlies commonly used audit sampling techniques and illustrates how to utilize these techniques in accordance with international auditing standards. Additionally, the book demonstrates the use of Bayesian statistical methods in auditing practice and highlights the practical advantages that these methods can offer for auditors.\nThe organization of this book is as follows: Chapter 1 provides a foundational introduction to the R programming language. Chapter 2 addresses the fundamental statistical theory relevant to audit sampling. Chapters 3, 4, 5, and 5 delve more deeply into the use of statistical methods for the planning, selection, and evaluation of audit samples. Finally, Chapter 7 considers other software implementations of audit sampling utilizing R.\n\n\n\n\nAmerican Institute of Certified Public Accountants (AICPA). (2016a). Appendix A: Attributes statistical sampling tables. In Audit guide: Audit sampling. https://doi.org/10.1002/9781119448617.app1\n\n\nAmerican Institute of Certified Public Accountants (AICPA). (2016b). Appendix C: Monetary unit sampling tables. In Audit guide: Audit sampling. https://doi.org/10.1002/9781119448617.app3\n\n\nStewart, T. (2012). Technical notes on the AICPA audit guide audit sampling. 5–8."
  },
  {
    "objectID": "ch01.html#basics",
    "href": "ch01.html#basics",
    "title": "1  Introduction to R",
    "section": "1.1 Basics",
    "text": "1.1 Basics\nOne of the basic features of R is its ability to manipulate data. In R, basic calculations work by using the standard arithmetic operators such as + for addition, - for subtraction, * for multiplication, and / for division. For example, if you want to calculate 2 + 3, you would type in 2 + 3 and R will return the result of 5.\n\n2 + 3\n#> [1] 5\n\nR also allows for more advanced calculations such as exponentiation using the ^ operator, and square roots using the sqrt() function. For example, to calculate the square root of 9, you would type in sqrt(9) and R will return the result of 3.\n\nsqrt(9)\n#> [1] 3\n\nYou can also use parentheses to specify the order of operations in your calculations. For example, if you want to calculate (2 + 3) * 4, you would type in (2 + 3) * 4 to get the result of 20.\n\n(2 + 3) * 4\n#> [1] 20\n\nOverall, basic calculations in R are similar to those in other programming languages and follow the standard order of operations.\n\n1.1.1 Vectors\nIn R, vectors are one-dimensional arrays of data that can hold numeric, character, or logical values. Vectors can be created using the c() function, which stands for concatenate. For example, to create a numeric vector, you can use the following code:\n\nx <- c(1, 2, 3, 4, 5)\n\nTo create a character vector, you can use quotes around the values:\n\ny <- c(\"apple\", \"banana\", \"orange\")\n\nTo create a logical vector, you can use the logical values TRUE and FALSE:\n\nz <- c(TRUE, FALSE, TRUE, TRUE, FALSE)\n\nVectors can be indexed using square brackets and a numeric value. For example, to access the second element of the vector x, you can use the following code:\n\nx[2]\n#> [1] 2\n\nVectors can also be subsetted using a logical vector. For example, to get all elements of the vector x that are greater than 3, you can use the following code:\n\nx[x > 3]\n#> [1] 4 5\n\nVectors can also be modified using indexing and assignment. For example, to change the third element of the vector x to 6, you can use the following code:\n\nx[3]\n#> [1] 3\nx[3] <- 6\nx[3]\n#> [1] 6\n\nR also has functions for performing mathematical operations on data. For example, we can use the mean() function to calculate the average of a vector of numbers, or we can use the length() function to calculate the number of elements in a vector:\n\nmean(x)\n#> [1] 3.6\nlength(y)\n#> [1] 3\n\nOverall, vectors are a useful data structure in R for storing and manipulating data.\n\n\n1.1.2 Matrices\nIn R, a matrix is a two-dimensional collection of values that are arranged in rows and columns. You can create a matrix using the matrix() function. For example:\n\nm <- matrix(1:9, nrow = 3, ncol = 3)\nm\n#>      [,1] [,2] [,3]\n#> [1,]    1    4    7\n#> [2,]    2    5    8\n#> [3,]    3    6    9\n\nThis creates a 3x3 matrix with the values 1, 2, 3 in the first column, 4, 5, 6 in the second column, and 7, 8, 9 in the third column.\nYou can also create a matrix by combining several vectors using the cbind() or rbind() functions. For example:\n\nv1 <- c(1, 2, 3)\nv2 <- c(4, 5, 6)\nv3 <- c(7, 8, 9)\nm <- cbind(v1, v2, v3)\nm\n#>      v1 v2 v3\n#> [1,]  1  4  7\n#> [2,]  2  5  8\n#> [3,]  3  6  9\n\nThis creates a matrix with the same values as before, but the columns are created by binding the vectors together.\nYou can access the elements of a matrix using the square bracket notation. For example, to access the element in the second row and third column of m, you would use the following code:\n\nm[2, 3]\n#> v3 \n#>  8\n\nYou can also use the dim() function to get the dimensions of a matrix, and the colnames() and rownames() functions to get the names of the columns and rows, respectively.\nThere are many other functions and operations available for working with matrices in R, including mathematical operations such as matrix multiplication and inversion.\n\n\n1.1.3 Data Frames\nIn R, a data frame is a two-dimensional table of data with rows and columns. Each row represents a single observation or record, and each column represents a particular variable or attribute. Data frames are similar to a spreadsheet in Excel or a table in a database. Each column in a data frame can have a different data type, such as numerical, character, or logical. The data in each row must match the data type of the corresponding column.\nTo create a data frame in R, you can use the data.frame() function and pass in the data you want to include in the data frame as arguments. For example:\n\ndf <- data.frame(x = c(1, 2, 3), y = c(4, 5, 6))\n\nThis will create a data frame with two columns, x and y, and three rows of data. You can access the data in a data frame using indexing and subsetting. For example, to access the first row of the data frame, you can use the following command:\n\ndf[1, ]\n#>   x y\n#> 1 1 4\n\nTo access a specific column, you can use the $ operator (or the index):\n\ndf$x\n#> [1] 1 2 3\ndf[, 1]\n#> [1] 1 2 3\n\nYou can also use functions like head() and tail() to view the first or last few rows of a data frame. Data frames also have several built-in functions that allow you to manipulate and analyze the data. For example, you can use the summarize() function to calculate summary statistics for each column, or the group_by() function to group the data by a specific variable and apply a function to each group."
  },
  {
    "objectID": "ch01.html#packages",
    "href": "ch01.html#packages",
    "title": "1  Introduction to R",
    "section": "1.2 Packages",
    "text": "1.2 Packages\nIn addition to these basic features, R has many packages and libraries that extend its capabilities and provide additional functions and tools for data analysis and visualization. A package is a small bundle of code that an R user (or group of users) wrote and uploaded to a central server for everybody to access, download and use. Some popular packages include dplyr for data manipulation, ggplot2 for data visualization, and caret for machine learning. With its versatility and robust community, R is a valuable tool for anyone working with data.\n\nIf you want to know more about making your own package, read Wickam & Brian (2022).\n\n\n1.2.1 Installing a Package\nIn many cases, you will download an R package from the CRAN server. This can be done via the install.packages() function by providing the package name in quotes. For example, an important package for data visualization is ggplot2. To install this package, you can simply run:\n\ninstall.packages(\"ggplot2\")\n\nTo illustrate its concepts and ideas, this book heavily draws from the jfa package, an R package for statistical auditing, which can also be downloaded from CRAN. Before running the examples in this book, you should install this package by running the following command in R:\n\ninstall.packages(\"jfa\")\n\n\n\n1.2.2 Loading a Package\nOnce you have installed a package, you must load it into every R session. To load a package into your R session, call library() and provide the name of the package (without quotes) that you want to load. For example, before running the examples in this book, you can load the jfa package with:\n\nlibrary(jfa)\n\n\nIf you want a deeper understanding of how the jfa package works, or want to look at the source code of the package, see the package website.\n\n\n\n1.2.3 Updating a Package\nR packages are updated regularly. To update a package in your R library you should call update.packages() and provide the name of the package that you want to update in quotes. For example, each time there is a new release of the **jfa* package, you can update it by running:\n\nupdate.packages(\"jfa\")"
  },
  {
    "objectID": "ch01.html#loading-data",
    "href": "ch01.html#loading-data",
    "title": "1  Introduction to R",
    "section": "1.3 Loading Data",
    "text": "1.3 Loading Data\n\n1.3.1 Loading Data from a CSV File\nA commonly used data type is a .csv file. You can load this type of files via the read.csv() function. For example, if the file example.csv is in the current working directory, you can load it by running:\n\nread.csv(\"example.csv\")\n\n\n\n1.3.2 Loading Data from an Excel File\nAnother commonly used data type are Excel files. You can load this type of files via the read_excel() function from the readxl package. For this to work, you should first install this package using the install.packages() command and load it into the R session using a call to library(). For example, if the file example.xlsx is in the current working directory, and the data you want to load is on the first worksheet, you can load it by running:\n\ninstall.packages(\"readxl\")\nlibrary(readxl)\nread_excel(\"example.csv\", sheet = 1)\n\n\n\n\n\nChang, W. (2022). R Graphics Cookbook. O’Reilly. https://r-graphics.org/\n\n\nGrolemund, G. (2014). Hands-On Programming with R. https://rstudio-education.github.io/hopr/\n\n\nLin, J. (2021). Audit Analytics with R. https://auditanalytics.jonlin.ca/\n\n\nWickam, H., & Brian, J. (2022). R Packages. https://r-pkgs.org/\n\n\nWickam, H., & Grolemund, G. (2017). R for Data Science. https://r4ds.had.co.nz/\n\n\nWilke, C. O. (2022). Fundamentals of Data Visualization. https://clauswilke.com/dataviz/"
  },
  {
    "objectID": "ch02.html#auditing-standards",
    "href": "ch02.html#auditing-standards",
    "title": "2  Background Information",
    "section": "2.1 Auditing Standards",
    "text": "2.1 Auditing Standards\nThere are three auditing standards related to staistical sampling in the audit:\n\nISA 530: Auditing standard for international firms published by the International Auditing and Assurance Standards Board (IAASB).\nAU-C 530: Auditing standard for private firms published by the American Institute of Certified Public Accountants (AICPA).\nAS 2315: Auditing standard for public firms published by the Public Company Accounting Oversign Board (PCAOB).\n\nAll three standards present a similar explanation of statistical sampling. For instance, ISA 530 (International Auditing and Assurance Standards Board (IAASB), 2018) defines statistical audit sampling as a method that at minimum exhibits the following two characteristics:\n\nRandom selection of sample items,\nThe use of an appropriate statistical technique to evaluate sample results, including measurement of sampling risk\n\nAccording to auditing standards, any sampling approach that lacks these two characteristics is considered nonstatistical sampling.\nIn order to effectively utilize statistical sampling during an audit, it is necessary to tailor the approach to the specific circumstances of the audit. This may involve considering factors such as the size and complexity of the population, the materiality of the items being tested, and the level of inherent risk in the audit area. It is also essential for the auditor to document the sampling process in order to demonstrate compliance with auditing standards. The following sections will delve further into these crucial concepts in the context of statistical audit sampling."
  },
  {
    "objectID": "ch02.html#important-concepts",
    "href": "ch02.html#important-concepts",
    "title": "2  Background Information",
    "section": "2.2 Important Concepts",
    "text": "2.2 Important Concepts\nThis section aims to delve into several theoretical concepts that are integral to statistical audit sampling.\n\n2.2.1 Materiality\nIn an audit, materiality is the maximum amount of misstatement that can be present in the financial statements of the auditee before the auditor concludes that the financical statements are materially misstated, meaning that they contains misstatements that would influence the decisions of stakeholders relying on those statements.\nThe term performance materiality refers to the maximum amount of misstatement that can be present in a given population that is part of the financial statements before the auditor concludes that the population is materially misstated. Performance materiality is used by auditors to determine the appropriate level of testing to be performed on a population.\n\nThe performance materiality is usually defined to be lower than the materiality because an individual population that is subject to audit sampling is often only a (small) part of the financial statements.\n\nFor example, consider an audit of a company’s financial statements for the year ended December 31, 2021. The auditor determines that the company’s accounts receivable balance is a large part of to the financial statements and decides to test a sample of the accounts receivable transactions to assess the accuracy of the balance. The auditor calculates the performance materiality for the accounts receivable balance by considering the materiality for the financial statements as a whole. If the auditor finds misstatements in the sample such that their estimate of the misstatement exceeds the performance materiality, the auditor would need to express an unqualified opinion on the population or would need to perform additional testing on the population. If the auditor finds misstatements in the sample such that their estimate of the misstatement does not exceed the performance materiality, the auditor would express a positive opinion on the financial statements.\n\n\n2.2.2 Audit risk\nAfter completing an audit and making any necessary corrections, an auditor will issue a written report stating whether the financial statements are accurate and free of material misstatement. The potential for this opinion to be incorrect is known as audit risk, and it is the auditor’s job to minimize this risk as much as possible.\nFor example, during an audit of a company’s financial statements, the auditor may carefully review documentation, perform tests of details via audit sampling, and speak with management in order to reduce the audit risk and provide a reliable opinion on the accuracy of the financial statements as a whole.\n\n\n2.2.3 Population\nIn statistical inference, the term population refers to the entire group of individuals or items that have some common characteristic or interest, and about which we want to gather data or make inferences. A population can be as large as all the people in a country or, as is more sensible in auditing, as small as a group of employees in a specific department of a company.\nFor example, consider an audit of a company’s payroll records. The population in this case would be all the employees of the company, and the goal of the audit would be to gather data on their salaries, benefits, and other payroll-related information. The audit team would collect this data from a a representative group of employees (i.e., a sample) of the population and use statistical methods to draw conclusions about the entire population.\n\n\n2.2.4 Sampling risk\nThere is a possibility that the results of an audit based on a sample may differ from the results if the entire population were examined using the same procedures. This is known as sampling risk. Sampling risk can result in two types of incorrect conclusions:\n\nThe first type is when, in a test of controls, the controls are perceived to be more effective than they actually are, or in a test of details, a material misstatement is believed to not exist when it actually does. This type of erroneous conclusion is particularly concerning for auditors because it can compromise the effectiveness of the audit and may lead to an inappropriate audit opinion.\nThe second type of incorrect conclusion is when, in a test of controls, the controls are perceived to be less effective than they actually are, or in a test of details, a material misstatement is believed to exist when it actually does not. This type of erroneous conclusion impacts the efficiency of the audit as it may require additional work to determine that the initial conclusions were incorrect.\n\nMany audits are performed according to the audit risk model (ARM), which determines that the uncertainty about the auditor’s statement as a whole is a factor of three terms: the inherent risk, the control risk, and the detection risk (i.e., the sampling risk). Inherent risk is the risk posed by a misstatement in the auditees financial statements that could be material, before consideration of any related control systems (e.g., computer systems). Control risk is the risk that a material misstatement is not prevented or detected by the auditee’s internal control systems. Detection risk is the risk that the auditor will fail to find material misstatements that exist in the auditee’s financial statements. The ARM is practically useful because, for a given level of audit risk, the tolerable detection risk bears an inverse relation to the other two risks.\n\\[\\begin{equation}\n  \\text{Audit risk} = \\text{Inherent risk} \\times \\text{Control risk} \\times \\text{Detection risk}\n\\end{equation}\\]\nUsually the auditor judges inherent risk and control risk on a three-point scale consisting of low, medium, and high. Different audit firms handle different standard percentages for these categories. Given an assessment of the inherent risk and the control risk, the detection risk can be calculated as:\n\\[\\begin{equation}\n  \\text{Detection risk} = \\frac{\\text{Audit risk}}{\\text{Inherent risk} \\times \\text{Control risk}}\n\\end{equation}\\]\n\nThe ARM is commonly used in practice, but is not a proper model of audit risk. For example, it is not possible to set one of the risks to 0, since that would result in an infinite detection risk (\\(\\frac{0.05}{0 \\times 1} = \\infty\\)).\n\nLet’s consider an example. Suppose that, in their audit guide, an audit firm associates the following percentages with the categories high, medium and low:\n\nHigh: 100%\nMedium: 60%\nLow: 50%\n\nIf an auditor is working with an audit risk of 5%, and judges inherent and control risk to both be medium, the sampling risk can be calculated as:\n\\[\\begin{equation}\n  \\frac{0.05}{0.6 \\times 0.6} = 0.139\n\\end{equation}\\]\n\n\n2.2.5 Sample Size\nThe sample size is an important consideration in the context of audit sampling, as it determines the number of items that will be selected for testing during the audit process. This factor has an impact on both effectiveness and efficiency. In general, a larger sample size can provide a higher level of assurance, but it requires more audit effort to obtain and inspect. On the other hand, a smaller sample size offers a lower level of assurance, but it is less costly.\n\n\n2.2.6 Notation\nThe table below summarizes the notation used in this book (middle column) and in the jfa R package (right column).\n\n\n\nMeaning\nSymbol\njfa\n\n\n\n\nProbability of misstatement\n\\(\\theta\\)\n\n\n\nPerformance materiality\n\\(\\theta_{max}\\)\nmateriality\n\n\nExpected deviation rate\n\\(\\theta_{exp}\\)\nexpected\n\n\nType-I error probability\n\\(\\alpha\\)\n1 - conf.level\n\n\nType-II error probability\n\\(\\beta\\)\n\n\n\nPopulation size\n\\(N\\)\nN.units\n\n\nPopulation misstatements\n\\(K\\)\n\n\n\nSample size\n\\(n\\)\nn\n\n\nObserved misstatements\n\\(k\\)\nx"
  },
  {
    "objectID": "ch02.html#classical-inference",
    "href": "ch02.html#classical-inference",
    "title": "2  Background Information",
    "section": "2.3 Classical Inference",
    "text": "2.3 Classical Inference\nFrequentist statistics, also known as classical statistics, is a statistical framework that is based on the concept of probability as a long-term frequency of events. This approach assumes that statistical models are purely objective and that data is generated by a well-defined process, which can be described by a set of probabilistic assumptions. The philosophy behind frequentist statistics is that statistical estimates should be based on the frequency of events in a population, rather than on subjective or personal beliefs. This approach is particularly useful for making predictions or making decisions based on data, as it allows for the calculation of confidence intervals and statistical tests, which provide a measure of the reliability of the estimates. Overall, frequentist statistics is a rigorous and reliable approach that is widely used in the scientific community for making informed decisions based on data.\n\n2.3.1 Parameter Estimation\nThe philosophy behind frequentist parameter estimation is based on the idea that statistical parameters are fixed, but unknown, quantities that can be estimated through the process of repeated sampling. This approach assumes that the sample data represent a random sample from a larger population, and that the sample statistics (i.e., the sample proportion of misstatements) can be used to estimate the corresponding population parameters (i.e., the population misstatement). The key principle of frequentist estimation is that the estimated parameter values should be unbiased and have a certain level of precision, which can be quantified through statistical measures such as confidence bounds or intervals.\n\n\n2.3.2 Hypothesis Testing\nFrequentist hypothesis testing is a statistical method that involves evaluating the probability of obtaining a certain sample outcome or more extreme, given a certain assumption or hypothesis. This probability, known as the p value, is used to determine the likelihood of the hypothesis being true.\nFor example, in a typical audit sampling hypothesis test using the binomial distribution, we may be interested in testing the hypothesis that the misstatement is higher or lower than the performance materiality. We would inspect a sample and calculate the p value based on the observed frequency of misstatements versus the expected frequency under the assumption of material misstatement. If the p value is below the sampling risk \\(\\alpha\\), we reject the hypothesis that the population is materially misstated and conclude that it is not materially misstated.\n\n\n2.3.3 Example\nAs an example, the binom.test() function in R can be used to test if a population contains less than 3 percent misstatements. Suppose an auditor obtained a sample of \\(n = 100\\) items containing \\(k = 0\\) misstatements. To use the binom.test() function, the auditor must input the number of items in the sample n = 100, the number of misstatements in the sample x = 0, and the hypothesized proportion of misstatement in the population (i.e., the performance materiality) p = 0.03. The sampling risk is set to 5%, which the auditor can provide to the function with conf.level = 1 - 0.05. Finally, the auditor can specify the alternative hypothesis as alternative = \"less\" to test if the proportion of misstatements in the sample is less than the hypothesized proportion.\n\nbinom.test(x = 0, n = 100, p = 0.03, alternative = \"less\", conf.level = 0.95)\n#> \n#>  Exact binomial test\n#> \n#> data:  0 and 100\n#> number of successes = 0, number of trials = 100, p-value = 0.04755\n#> alternative hypothesis: true probability of success is less than 0.03\n#> 95 percent confidence interval:\n#>  0.00000000 0.02951305\n#> sample estimates:\n#> probability of success \n#>                      0\n\nThe most likely misstatement in the population is displayed under sample estimates and is 0%. The 95% upper confidence bound for the estimate of the population misstatement is displayed under 95 percent confidence interval and is 2.95%. The p value is shown to be 0.04755. Since the p value is lower than the specified sampling risk \\(\\alpha\\), the auditor can reject the hypothesis of material misstatement."
  },
  {
    "objectID": "ch02.html#bayesian-inference",
    "href": "ch02.html#bayesian-inference",
    "title": "2  Background Information",
    "section": "2.4 Bayesian Inference",
    "text": "2.4 Bayesian Inference\nBayesian inference is based on the idea that the parameters in a statistical model are not fixed but uncertain. In this approach, the parameter is onsidered to be a random variable with a certain distribution, and the goal is to use the data and any prior knowledge about the parameter to update our belief about its value. This is typically done using Bayes’ theorem, which states that the posterior probability (i.e., the updated belief about the parameter after seeing the data) is equal to the prior probability (i.e., the belief about the parameter before seeing the data) times the likelihood (i.e., the probability of the data given the parameter).\n\\[\\begin{equation}\n  \\text{Posterior} \\propto \\text{Likelihood} \\times \\text{Prior}\n\\end{equation}\\]\nBayesian statistics is a more nuanced approach that allows for more efficiency in statistical audit sampling, but it requires the specification of prior distributions that can be difficult to quantify. That is because, especially in an audit, all information that is incorporated into the statistical analysis should be based on audit evidence and should be properly justified.\n\n2.4.1 Parameter Estimation\nOne major difference between classical and Bayesian statistics is the way they handle uncertainty. In classical statistics, uncertainty is represented by the standard error of an estimate, which is a measure of the precision of an estimate. In Bayesian statistics, uncertainty is represented by the posterior distribution, which is a distribution of the possible values of the population parameter given the sample data and our prior beliefs. Bayesian inferences uses uses Bayes’ theorem to update the prior beliefs about the population parameter with the new information from the sample data. Bayes’ theorem is given by the following formula:\n\\[\\begin{equation}\n  p(\\theta | y) = \\frac{p(y | \\theta)p(\\theta)}{p(y)}\n\\end{equation}\\]\nwhere \\(p(\\theta | y)\\) is the posterior probability of the population parameter \\(\\theta\\) given the sample data \\(y\\), \\(p(y | \\theta)\\) is the likelihood of the sample data given \\(\\theta\\), \\(p(\\theta)\\) is the prior probability of \\(\\theta\\), and \\(p(y)\\) is the total probability of the sample data occurring. Because with a fixed sample \\(p(y)\\) is a constant, Bayes’ theorem is often given as follows:\n\\[\\begin{equation}\n  p(\\theta | y) \\propto p(y | \\theta) \\times p(\\theta)\n\\end{equation}\\]\n\n\n2.4.2 Hypothesis Testing\nThe Bayes factor is a measure used in Bayesian inference to compare the relative strength of evidence between two competing hypotheses. The Bayes factor is calculated by comparing the probability of the observed data given each of the two competing hypotheses. This probability is known as the likelihood of the data. The Bayes factor is then the ratio of the likelihood of the data under one hypothesis to the likelihood of the data under the other hypothesis. The Bayes factor can be used in the context of an audit, where the auditor is trying to determine the likelihood that a particular financial statement is represented fairly or not.\nFor example, an auditor might be evaluating the fairness of a company’s financial statements for the year. They have two hypotheses: the first is that the statements are accurate, and the second is that the statements are not accurate. The auditor gathers data from a statistical audit sample and uses this data to calculate the Bayes factor.\nThe Bayes factor is calculated by taking the ratio of the probability of the first hypothesis (that the statements are accurate) given the observed data, to the probability of the second hypothesis (that the statements are not accurate) given the observed data. The higher the Bayes factor, the more likely it is that the first hypothesis is true.\nThe Bayes factor can be used to assess the strength of evidence for one hypothesis over the other and to determine which hypothesis is more likely to be true given the observed data. It is often used in scientific research to help evaluate the validity of different hypotheses and to make informed decisions based on the available evidence. For auditors, the Bayes factor can be a useful tool to determine the likelihood of different hypotheses being true based on the data they have collected, and it can help them make informed decisions about the fairness of the financial statements.\nFor example, if the Bayes factor is 5, this means that the probability of the statements being accurate given the observed data is 5 times higher than the probability of them being not accurate. In this case, the auditor would be more likely to conclude that the financial statements are accurate.\nThe jfa package can help us to calculate Bayes factors for and against the hypothesis that the financial statements are represented fairly.\n\n\n\n\nInternational Auditing and Assurance Standards Board (IAASB). (2018). ISA 530: Audit sampling. In International standards on auditing (ISA)."
  },
  {
    "objectID": "ch03.html#required-information",
    "href": "ch03.html#required-information",
    "title": "3  Planning a Sample",
    "section": "3.1 Required Information",
    "text": "3.1 Required Information\nFirst, planning a minimum sample requires knowledge of the conditions that lead to acceptance or rejection of the population (i.e., the sampling objectives). Typically, sampling objectives can be classified into one or both of the following:\n\nHypothesis testing: The goal of the sample is to obtain evidence for or against the claim that the misstatement in the population is lower than a given value (i.e., the performance materiality).\nEstimation: The goal of the sample is to obtain an accurate estimate of the misstatement in the population (with a minimum precision).\n\nSecond, it is advised to specify the expected (or tolerable) misstatements in the sample. The expected misstatements are the misstatements that you allow in the sample, while still retaining the desired amount of assurance about the population. It is strongly recommended to set the value for the expected misstatements in the sample conservatively to minimize the chance of the observed misstatements in the sample exceeding the expected misstatements, which would imply that insufficient work has been done in the end.\nFinally, next to determining the sampling objective(s) and the expected misstatements, it is important to determine the statistical distribution linking the sample outcomes to the population misstatement. This distribution is called the likelihood (i.e., poisson, binomial, or hypergeometric). All three aforementioned likelihoods are commonly used in an audit sampling context, however, poisson is the default likelihood in jfa because it is the most conservative of the three. In the subsections below, we elaborate on the three standard likelihoods for audit sampling and demonstrate how they can be used to obtain a minimum sample size."
  },
  {
    "objectID": "ch03.html#the-hypergeometric-likelihood",
    "href": "ch03.html#the-hypergeometric-likelihood",
    "title": "3  Planning a Sample",
    "section": "3.2 The Hypergeometric Likelihood",
    "text": "3.2 The Hypergeometric Likelihood\nLet’s consider how to use the hypergeometric likelihood to calculate the minimum sample size needed to achieve a desired level of assurance. The hypergeometric distribution is a discrete probability distribution that is commonly used to model the number of events occurring in a fixed number of trials when the population size is known. For our purpose, we can use the hypergeometric distribution as a likelihood to model the number of misstatements that are expected to be found in the sample.\nThe probability mass function (PMF) of the hypergeometric distribution is given by:\n\\[\\begin{equation}\n  p(X=k)=\\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}},\n\\end{equation}\\]\nwhere \\(k\\) is the number of misstatements in the sample, \\(n\\) is the sample size, \\(N\\) is the population size and \\(K\\) is the total number of misstatements assumed in the population. The assumed misstatements \\(K\\) is a linear extrapolation of the assumed misstatement rate in the population \\(\\theta_{max}\\) to the total population:\n\\[\\begin{equation}\n  K = \\theta_{max} N.\n\\end{equation}\\]\n\n3.2.1 Classical planning\nConcretely, the following statistical model is assumed:\n\\[\\begin{equation}\n  k \\sim \\text{Hypergeometric}(n, N, K)\n\\end{equation}\\]\nGiven a desired misstatement tolerance \\(\\theta_{max}\\), we can solve for the minimum sample size \\(n\\) needed to achieve this assurance level. In jfa, this sample size can be calculated using the planning() function. For example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a performance materiality of \\(\\theta_{max} = 0.03\\) in a population of \\(N=1000\\) items, then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 94\\).\n\nplanning(materiality = 0.03, expected = 0, conf.level = 0.95,\n         likelihood = \"hypergeometric\", N.units = 1000)\n#> \n#>  Classical Audit Sample Planning\n#> \n#> minimum sample size = 94 \n#> sample size obtained in 95 iterations via method 'hypergeometric'\n\nThe dhyper() function calculates the probability of observing \\(k\\) missatements in a sample of \\(n\\) items given an assumed misstatement probability. The sample size of 94 can be confirmed by checking that 94 is the minimum integer that results in less than 5% probability of finding 0 misstatements if the population misstatement is truly 3%.\n\nK <- ceiling(0.03 * 1000)\ndhyper(x = 0, m = K, n = 1000 - K, k = 93) < 0.05 # 93: Not sufficient\n#> [1] FALSE\ndhyper(x = 0, m = K, n = 1000 - K, k = 94) < 0.05 # 94: Sufficient\n#> [1] TRUE\n\nWe can make this visually intuitive by showing the hypergeometric(\\(k\\) | 94, 1000, 30) distribution and highlighting the probability for \\(k = 0\\). This probability should be lower than the required sampling risk \\(\\alpha = 0.05\\).\n\n\n\n\n\n\n\n\n\nAs another example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a performance materiality of \\(\\theta_{max} = 0.03\\) in a population of \\(N=1000\\) items, then the required sample size under the assumption of one expected misstatement in the sample is \\(n = 147\\).\n\nplanning(materiality = 0.03, expected = 1, conf.level = 0.95,\n         likelihood = \"hypergeometric\", N.units = 1000)\n#> \n#>  Classical Audit Sample Planning\n#> \n#> minimum sample size = 147 \n#> sample size obtained in 146 iterations via method 'hypergeometric'\n\nOnce again, the sample size of 147 can be confirmed by checking that 147 is the minimum integer that results in less than 5% probability of finding 0 or 1 misstatements if the population misstatement is truly 3%.\n\nsum(dhyper(x = 0:1, m = K, n = 1000 - K, k = 146)) < 0.05 # 146: Not sufficient\n#> [1] FALSE\nsum(dhyper(x = 0:1, m = K, n = 1000 - K, k = 147)) < 0.05 # 147: Sufficient\n#> [1] TRUE\n\nLike before, we can make this visually intuitive by showing the hypergeometric(\\(k\\) | 147, 1000, 30) distribution and highlighting the probabilities for \\(k = 0\\) and \\(k = 1\\). The sum of these probabilities should be lower than the required sampling risk \\(\\alpha = 0.05\\).\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Bayesian Planning\nPerforming Bayesian planning with the hypergeometric likelihood (Dyer & Pierce, 1993) requires that you specify a prior distribution for the parameter \\(\\theta\\). Practically, this means that you should provide an input for the prior argument in the planning() function.\nSetting prior = TRUE performs Bayesian planning using a default prior conjugate to the specified likelihood (i.e., a beta-binomial prior). Concretely, this means that the following statistical model is assumed:\n\\[\\begin{align}\n  k &\\sim \\text{Hypergeometric}(n, N, K) \\\\\n  K &\\sim \\text{Beta-binomial}(N, \\alpha, \\beta)\n\\end{align}\\]\n\nThe beta-binomial prior distribution is conjugate to the hypergeometric likelihood (see this list of conjugate priors), which means that the posterior distribution of \\(K\\) can be determined analytically. For example, if the prior distribution for \\(K\\) is beta-binomial(\\(N\\), \\(\\alpha\\), \\(\\beta\\)) and the auditor has observed a sample of \\(n\\) items containing \\(k\\) misstatements, the posterior distribution for \\(K\\) is beta-binomial(\\(N - n\\), \\(\\alpha + k\\), \\(\\beta + n - k\\)).\n\nFor example, the command below uses a default beta-binomial(\\(N\\), 1, 1) prior distribution to plan the sample, since planning() is given the hypergeometric likelihood. If we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a performance materiality of \\(\\theta_{max} = 0.03\\) in a population of \\(N=1000\\) items, then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 93\\).\n\nplan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,\n                 likelihood = \"hypergeometric\", N.units = 1000, prior = TRUE)\nsummary(plan)\n#> \n#>  Bayesian Audit Sample Planning Summary\n#> \n#> Options:\n#>   Confidence level:              0.95 \n#>   Population size:               1000 \n#>   Materiality:                   0.03 \n#>   Hypotheses:                    H₀: Θ > 0.03 vs. H₁: Θ < 0.03 \n#>   Expected:                      0 \n#>   Likelihood:                    hypergeometric \n#>   Prior distribution:            beta-binomial(N = 1000, α = 1, β = 1) \n#> \n#> Results:\n#>   Minimum sample size:           93 \n#>   Tolerable errors:              0 \n#>   Posterior distribution:        beta-binomial(N = 907, α = 1, β = 94) \n#>   Expected most likely error:    0 \n#>   Expected upper bound:          0.029 \n#>   Expected precision:            0.029 \n#>   Expected BF₁₀:                 620.58\n\nYou can inspect how the prior distribution compares to the expected posterior distribution by using the plot() function. The expected posterior distribution is the posterior distribution that would occur if you actually observed the planned sample containing the expected misstatements.\n\nplot(plan)\n\n\n\n\n\n\n\n\nThe hypergeometric likelihood does not allow for non-conjugate prior distributions to be used as a prior."
  },
  {
    "objectID": "ch03.html#the-binomial-likelihood",
    "href": "ch03.html#the-binomial-likelihood",
    "title": "3  Planning a Sample",
    "section": "3.3 The Binomial Likelihood",
    "text": "3.3 The Binomial Likelihood\nLet’s consider how to use the binomial likelihood to calculate the minimum sample size needed to achieve a desired level of assurance. The binomial distribution is a discrete probability distribution that is commonly used to model the number of events occurring in a fixed number of trials. For our purpose, we can use the binomial distribution as a likelihood to model the number of misstatements that are expected to be found in the sample.\n\nIn audit sampling, the binomial likelihood is often used to approximate the hypergeometric likelihood since it is easier to work with (i.e., it only has two parameters: \\(\\theta\\) and \\(n\\), while the hypergeometric has three: \\(n\\), \\(N\\), and \\(K\\)). However, the binomial likelihood is more conservative than the hypergeometric likelihood, meaning that resulting sample sizes will be higher.\n\nThe probability mass function (PMF) of the binomial distribution is given by:\n\\[\\begin{equation}\n  p(k; n, \\theta) = \\binom{n}{k} \\theta^{k} (1-\\theta)^{n - k},\n\\end{equation}\\]\nwhere \\(k\\) is the number of misstatements in the sample, \\(n\\) is the sample size and \\(\\theta\\) is the misstatement rate expected in the sample.\n\n3.3.1 Classical Planning\nConcretely, the following statistical model is assumed:\n\\[\\begin{equation}\n  k \\sim \\text{Binomial}(n, \\theta_{max})\n\\end{equation}\\]\nGiven a desired misstatement tolerance \\(\\theta_{max}\\), we can solve for the minimum sample size \\(n\\) needed to achieve the desired assurance level. A useful trick to utilize is that, if we do not expect any misstatements in the sample, the formula for the minimum required sample size reduces to:\n\\[\\begin{equation}\n  n = \\lceil\\frac{\\ln(\\alpha)}{\\ln(1 - \\theta_{max})}\\rceil.\n\\end{equation}\\]\n\n\\(\\lceil...\\rceil\\) is the ceiling function. Hence, \\(\\lceil1.2\\rceil = 2\\).\n\nFor example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a performance materiality of \\(\\theta_{max} = 0.03\\), then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 99\\).\n\nceiling(log(1 - 0.95) / log(1 - 0.03))\n#> [1] 99\n\nIn jfa, this sample size can be replicated using the planning() function.\n\nplanning(materiality = 0.03, expected = 0, conf.level = 0.95,\n         likelihood = \"binomial\")\n#> \n#>  Classical Audit Sample Planning\n#> \n#> minimum sample size = 99 \n#> sample size obtained in 100 iterations via method 'binomial'\n\nThe dbinom() function calculates the probability of observing \\(k\\) missatements in a sample of \\(n\\) items given an assumed misstatement probability. The sample size of 99 can be confirmed by checking that 99 is the minimum integer that results in less than 5% probability of finding 0 misstatements if the population misstatement is truly 3%.\n\ndbinom(x = 0, size = 98, prob = 0.03) < 0.05 # 98: Not sufficient\n#> [1] FALSE\ndbinom(x = 0, size = 99, prob = 0.03) < 0.05 # 99: Sufficient\n#> [1] TRUE\n\nWe can make this visually intuitive by showing the binomial(\\(k\\) | 99, 0.03) distribution and highlighting the probability for \\(k = 0\\). This probability should be lower than the required sampling risk \\(\\alpha = 0.05\\).\n\n\n\n\n\n\n\n\n\nHowever, if the number of expected misstatements in the sample is non-zero, it becomes more difficult to solve the formula for \\(n\\). Hence, we can iteratively try every value of \\(n\\) and return the smallest integer that satisfies the sampling objectives. In jfa, this can be done by adjusting the expected argument in the planning() function. For example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a performance materiality of \\(\\theta_{max} = 0.03\\), then the required sample size under the assumption of one expected misstatement in the sample is \\(n = 157\\).\n\nplanning(materiality = 0.03, expected = 1, conf.level = 0.95,\n         likelihood = \"binomial\")\n#> \n#>  Classical Audit Sample Planning\n#> \n#> minimum sample size = 157 \n#> sample size obtained in 156 iterations via method 'binomial'\n\nOnce again, the sample size of 157 can be confirmed by checking that 157 is the minimum integer that results in less than 5% probability of finding 0 or 1 misstatements if the population misstatement is truly 3%.\n\nsum(dbinom(x = 0:1, size = 156, prob = 0.03)) < 0.05 # 156: Not sufficient\n#> [1] FALSE\nsum(dbinom(x = 0:1, size = 157, prob = 0.03)) < 0.05 # 157: Sufficient\n#> [1] TRUE\n\nLike before, we can make this visually intuitive by showing the binomial(\\(k\\) | 157, 0.03) distribution and highlighting the probabilities for \\(k = 0\\) and \\(k = 1\\). The sum of these probabilities should be lower than the required sampling risk \\(\\alpha = 0.05\\).\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Bayesian Planning\nPerforming Bayesian planning with the binomial likelihood requires that you specify a prior distribution for the parameter \\(\\theta\\). Practically, this means that you should provide an input for the prior argument in the planning() function.\nSetting prior = TRUE performs Bayesian planning using a default prior conjugate to the specified likelihood (i.e., a beta prior). Concretely, this means that the following statistical model is assumed:\n\\[\\begin{align}\n  k &\\sim \\text{Binomial}(n, \\theta) \\\\\n  \\theta &\\sim \\text{Beta}(\\alpha, \\beta)\n\\end{align}\\]\n\nThe beta prior distribution is conjugate to the binomial likelihood (see this list of conjugate priors), which means that the posterior distribution of \\(\\theta\\) can be determined analytically. For example, if the prior distribution is beta(\\(\\alpha\\), \\(\\beta\\)) and the auditor has observed a sample of \\(n\\) items containing \\(k\\) misstatements, the posterior distribution for \\(\\theta\\) is beta(\\(\\alpha + k\\), \\(\\beta + n - k\\)).\n\nFor example, the command below uses a default beta(\\(\\alpha=1\\), \\(\\beta=1\\)) prior distribution to plan the sample, since planning() is given the binomial likelihood. If we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a performance materiality of \\(\\theta_{max} = 0.03\\), then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 98\\).\n\nplan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,\n                 likelihood = \"binomial\", prior = TRUE)\nsummary(plan)\n#> \n#>  Bayesian Audit Sample Planning Summary\n#> \n#> Options:\n#>   Confidence level:              0.95 \n#>   Materiality:                   0.03 \n#>   Hypotheses:                    H₀: Θ > 0.03 vs. H₁: Θ < 0.03 \n#>   Expected:                      0 \n#>   Likelihood:                    binomial \n#>   Prior distribution:            beta(α = 1, β = 1) \n#> \n#> Results:\n#>   Minimum sample size:           98 \n#>   Tolerable errors:              0 \n#>   Posterior distribution:        beta(α = 1, β = 99) \n#>   Expected most likely error:    0 \n#>   Expected upper bound:          0.029807 \n#>   Expected precision:            0.029807 \n#>   Expected BF₁₀:                 627.22\n\nYou can inspect how the prior distribution compares to the expected posterior distribution by using the plot() function. The expected posterior distribution is the posterior distribution that would occur if you actually observed the planned sample containing the expected misstatements.\n\nplot(plan)\n\n\n\n\n\n\n\n\nThe input for the prior argument can also be an object created by the auditPrior function. If planning() receives a prior for which there is no conjugate likelihood available, it will numerically derive the posterior distribution. For example, the command below uses a Normal(0, 0.05) prior distribution to plan the sample using the binomial likelihood. Concretely, this means that the following statistical model is assumed:\n\\[\\begin{align}\n  k &\\sim \\text{Binomial}(n, \\theta) \\\\\n  \\theta &\\sim \\text{Normal}(\\mu = 0, \\sigma = 0.05)\n\\end{align}\\]\n\nprior <- auditPrior(method = \"param\", likelihood = \"normal\",\n                    alpha = 0, beta = 0.05)\n\nplan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,\n                 likelihood = \"poisson\", prior = prior)\n\nsummary(plan)\n#> \n#>  Bayesian Audit Sample Planning Summary\n#> \n#> Options:\n#>   Confidence level:              0.95 \n#>   Materiality:                   0.03 \n#>   Hypotheses:                    H₀: Θ > 0.03 vs. H₁: Θ < 0.03 \n#>   Expected:                      0 \n#>   Likelihood:                    poisson \n#>   Prior distribution:            normal(μ = 0, σ = 0.05)T[0,1] \n#> \n#> Results:\n#>   Minimum sample size:           90 \n#>   Tolerable errors:              0 \n#>   Posterior distribution:        Determined via MCMC sampling \n#>   Expected most likely error:    0.0008648 \n#>   Expected upper bound:          0.029029 \n#>   Expected precision:            0.028164 \n#>   Expected BF₁₀:                 19.08\n\nThe resulting sample size under this prior is \\(n = 90\\), a reduction of 8 samples when compared to the default beta(1, 1) prior distribution.\n\nplot(plan)"
  },
  {
    "objectID": "ch03.html#the-poisson-likelihood",
    "href": "ch03.html#the-poisson-likelihood",
    "title": "3  Planning a Sample",
    "section": "3.4 The Poisson Likelihood",
    "text": "3.4 The Poisson Likelihood\nLet’s consider how to use the Poisson likelihood to calculate the minimum sample size needed to achieve a desired level of assurance. The Poisson distribution is a discrete probability distribution that is commonly used to model the number of events occurring in a fixed time or space. We can use the Poisson distribution as a likelihood to model the number of misstatements that are expected to be found in the sample.\n\nIn audit sampling, the Poisson likelihood is often used to approximate the binomial likelihood since it is easier to work with (i.e., it only has one parameter: \\(\\lambda\\), while the binomial has two parameters: \\(\\theta\\) and \\(n\\)). However, the Poisson likelihood is more conservative than the binomial likeliood, meaning that resulting sample sizes will be higher.\n\nThe probability mass function (PMF) of the Poisson distribution is given by:\n\\[\\begin{equation}\n  p(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!},\n\\end{equation}\\]\nwhere \\(k\\) is the number of misstatements in the sample, and \\(\\lambda\\) is the average number of misstatements expected in the sample. The average number of misstatements is related to the misstatement rate in the population, denoted by \\(\\theta\\), and the sample size, \\(n\\), by the following equation:\n\\[\\begin{equation}\n  \\lambda=n\\theta.\n\\end{equation}\\]\n\n3.4.1 Classical planning\nConcretely, the following statistical model is assumed:\n\\[\\begin{equation}\n  k \\sim \\text{Poisson}(n\\theta_{max})\n\\end{equation}\\]\nGiven a desired misstatement tolerance \\(\\theta_{max}\\) and the Poisson likelihood, we can solve for the minimum sample size \\(n\\) needed to achieve a assurance level. A useful trick to utilize is that, if we do not expect any misstatements in the sample, the formula for the required sample size reduces to:\n\\[\\begin{equation}\n  n = \\lceil-\\frac{\\ln(\\alpha)}{\\theta_{max}}\\rceil.\n\\end{equation}\\]\n\n\\(\\lceil...\\rceil\\) is the ceiling function. Hence, \\(\\lceil1.2\\rceil = 2\\).\n\nFor example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a performance materiality of \\(\\theta_{max} = 0.03\\), then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 100\\).\n\nceiling(-log(1 - 0.95) / 0.03)\n#> [1] 100\n\nIn jfa, this sample size can be replicated using the planning() function.\n\nplanning(materiality = 0.03, expected = 0, conf.level = 0.95,\n         likelihood = \"poisson\")\n#> \n#>  Classical Audit Sample Planning\n#> \n#> minimum sample size = 100 \n#> sample size obtained in 101 iterations via method 'poisson'\n\nThe dpois() function calculates the probability of observing \\(k\\) missatements in a sample of \\(n\\) items given an assumed misstatement probability. The sample size of 100 can be confirmed by checking that 100 is the minimum integer that results in less than 5% probability of finding 0 misstatements if the population misstatement is truly 3%.\n\ndpois(x = 0, lambda = 99 * 0.03) < 0.05  # 99:  Not sufficient\n#> [1] FALSE\ndpois(x = 0, lambda = 100 * 0.03) < 0.05 # 100: Sufficient\n#> [1] TRUE\n\nWe can make this visually intuitive by showing the Poisson(\\(k\\) | 100 * 0.03) distribution and highlighting the probability for \\(k = 0\\). This probability should be lower than the required sampling risk \\(\\alpha = 0.05\\).\n\n\n\n\n\n\n\n\n\nHowever, if the number of expected misstatements in the sample is non-zero, it becomes more difficult to solve the formula for \\(n\\). Hence, we can iteratively try every value of \\(n\\) and return the smallest integer that satisfies the sampling objectives. In jfa, this can be done by adjusting the expected argument in the planning() function. For example, if we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a performance materiality of \\(\\theta_{max} = 0.03\\), then the required sample size under the assumption of one expected misstatement in the sample is \\(n = 159\\).\n\nplanning(materiality = 0.03, expected = 1, conf.level = 0.95,\n         likelihood = \"poisson\")\n#> \n#>  Classical Audit Sample Planning\n#> \n#> minimum sample size = 159 \n#> sample size obtained in 158 iterations via method 'poisson'\n\nOnce again, the sample size of 159 can be confirmed by checking that 159 is the minimum integer that results in less than 5% probability of finding 0 or 1 misstatements if the population misstatement is truly 3%.\n\nsum(dpois(x = 0:1, lambda = 158 * 0.03)) < 0.05 # 158: Not sufficient\n#> [1] FALSE\nsum(dpois(x = 0:1, lambda = 159 * 0.03)) < 0.05 # 159: Sufficient\n#> [1] TRUE\n\nLike before, we can make this visually intuitive by showing the Poisson(\\(k\\) | 159 * 0.03) distribution and highlighting the probabilities for \\(k = 0\\) and \\(k = 1\\). The sum of these probabilities should be lower than the required sampling risk \\(\\alpha = 0.05\\).\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 Bayesian Planning\nPerforming Bayesian planning with the Poisson likelihood requires that you specify a prior distribution for the parameter \\(\\theta\\). Practically, this means that you should provide an input for the prior argument in the planning() function.\nSetting prior = TRUE performs Bayesian planning using a default prior conjugate to the specified likelihood (i.e., a gamma prior). Concretely, this means that the following statistical model is assumed:\n\\[\\begin{align}\n  k &\\sim \\text{Poisson}(n\\theta) \\\\\n  \\theta &\\sim \\text{Gamma}(\\alpha, \\beta)\n\\end{align}\\]\n\nThe gamma prior distribution is conjugate to the Poisson likelihood (see this list of conjugate priors), which means that the posterior distribution of \\(\\theta\\) can be determined analytically. For example, if the prior distribution is gamma(\\(\\alpha\\), \\(\\beta\\)) and the auditor has observed a sample of \\(n\\) items containing \\(k\\) misstatements, the posterior distribution for \\(\\theta\\) is gamma(\\(\\alpha + k\\), \\(\\beta + n\\)).\n\nFor example, the command below uses a default gamma(\\(\\alpha=1\\), \\(\\beta=1\\)) prior distribution to plan the sample, since planning() is given the Poisson likelihood. If we want to achieve an assurance level of 95% (\\(\\alpha=0.05\\)) for a performance materiality of \\(\\theta_{max} = 0.03\\), then the required sample size under the assumption of zero expected misstatements in the sample is \\(n = 99\\).\n\nplan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,\n                 likelihood = \"poisson\", prior = TRUE)\nsummary(plan)\n#> \n#>  Bayesian Audit Sample Planning Summary\n#> \n#> Options:\n#>   Confidence level:              0.95 \n#>   Materiality:                   0.03 \n#>   Hypotheses:                    H₀: Θ > 0.03 vs. H₁: Θ < 0.03 \n#>   Expected:                      0 \n#>   Likelihood:                    poisson \n#>   Prior distribution:            gamma(α = 1, β = 1) \n#> \n#> Results:\n#>   Minimum sample size:           99 \n#>   Tolerable errors:              0 \n#>   Posterior distribution:        gamma(α = 1, β = 100) \n#>   Expected most likely error:    0 \n#>   Expected upper bound:          0.029957 \n#>   Expected precision:            0.029957 \n#>   Expected BF₁₀:                 626.69\n\nYou can inspect how the prior distribution compares to the expected posterior distribution by using the plot() function. The expected posterior distribution is the posterior distribution that would occur if you actually observed the planned sample containing the expected misstatements.\n\nplot(plan)\n\n\n\n\n\n\n\n\nThe input for the prior argument can also be an object created by the auditPrior function. If planning() receives a prior for which there is no conjugate likelihood available, it will numerically derive the posterior distribution. For example, the command below uses a Normal(0, 0.05) prior distribution to plan the sample using the Poisson likelihood. Concretely, this means that the following statistical model is assumed:\n\\[\\begin{align}\n  k &\\sim \\text{Poisson}(n\\theta) \\\\\n  \\theta &\\sim \\text{Normal}(\\mu = 0, \\sigma = 0.05)\n\\end{align}\\]\n\nprior <- auditPrior(method = \"param\", likelihood = \"normal\",\n                    alpha = 0, beta = 0.05)\n\nplan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,\n                 likelihood = \"poisson\", prior = prior)\n\nsummary(plan)\n#> \n#>  Bayesian Audit Sample Planning Summary\n#> \n#> Options:\n#>   Confidence level:              0.95 \n#>   Materiality:                   0.03 \n#>   Hypotheses:                    H₀: Θ > 0.03 vs. H₁: Θ < 0.03 \n#>   Expected:                      0 \n#>   Likelihood:                    poisson \n#>   Prior distribution:            normal(μ = 0, σ = 0.05)T[0,1] \n#> \n#> Results:\n#>   Minimum sample size:           91 \n#>   Tolerable errors:              0 \n#>   Posterior distribution:        Determined via MCMC sampling \n#>   Expected most likely error:    0.0010232 \n#>   Expected upper bound:          0.029029 \n#>   Expected precision:            0.028006 \n#>   Expected BF₁₀:                 19.296\n\nThe resulting sample size under this prior is \\(n = 91\\), a reduction of 8 samples when compared to the default gamma(1, 1) prior.\n\nplot(plan)"
  },
  {
    "objectID": "ch03.html#practical-examples",
    "href": "ch03.html#practical-examples",
    "title": "3  Planning a Sample",
    "section": "3.5 Practical Examples",
    "text": "3.5 Practical Examples\nThis section contains practical examples of how to construct a prior distribution based on audit information.\n\n3.5.1 Audit Risk Model\nIn this example, an auditor is performing tests of details on a population of the auditee. For instance, let’s say an auditor is performing an audit on a company’s accounts payable transactions. The company has a total of \\(N\\) = 1000 accounts payable transactions for the year. Rather than testing all 1000 transactions, the auditor can choose to test a sample of the transactions. The performance materiality for the payable transactions account is set to 3%. Based on the results of last years audit, where the estimate of the maximum misstatement was 1%, the auditor wants to tolerate 1% misstatements in the sample before giving an unqualified opinion on the population.\n\nar          <- 0.05 # Audit risk\nmateriality <- 0.03 # Performance materiality\nexpected    <- 0.01 # Tolerable deviation rate\n\nBefore tests of details, the auditor has assessed risk of material misstatement via the audit risk model. In this example, the auditor has assessed the effectiveness of the company’s internal controls, such as its segregation of duties and its risk management processes, and has determined that they are sufficient to prevent or detect material misstatements. Because the internal control systems were effective, the auditor assesses the control risk as medium. The auditor’s firm defines the risk categories low, medium, and high respectively as 50%, 60%, and 100%.\n\nir <- 1              # Inherent risk\ncr <- 0.6            # Control risk\ndr <- ar / (ir * cr) # Detection risk\n\nBy using the detection risk as the adjusted audit risk, the auditor can plan for a sample while taking into account the risk-reducing information from the assessments of inherent risk and control risk. The required minimum sample size is 174 in this case.\n\nplanning(materiality = 0.03, expected = expected, conf.level = 1 - dr)\n#> \n#>  Classical Audit Sample Planning\n#> \n#> minimum sample size = 174 \n#> sample size obtained in 175 iterations via method 'poisson'\n\nThe auditor is free to apply a Bayesian philosophy in planning the sample. For example, the risk assessments from the ARM can be incorporated into a prior distribution. This can be done using method = \"arm\" in the auditPrior() function, which takes the values of the inherent risk probability ir and the control risk probability cr. Hence, the prior distribution in this example can be constructed using the following command:\n\nprior <- auditPrior(method = \"arm\", materiality = 0.03, expected = expected,\n                    ir = ir, cr = cr)\nsummary(prior)\n#> \n#>  Prior Distribution Summary\n#> \n#> Options:\n#>   Likelihood:                    poisson \n#>   Specifics:                     ir = 1; cr = 0.6; dr = 0.0833333 \n#> \n#> Results:\n#>   Functional form:               gamma(α = 1.46, β = 46) \n#>   Mode:                          0.01 \n#>   Mean:                          0.031739 \n#>   Median:                        0.024859 \n#>   Variance:                      0.00069 \n#>   Skewness:                      1.6552 \n#>   Information entropy (nat):     -2.4894 \n#>   95 percent upper bound:        0.08343 \n#>   Precision:                     0.07343\n\nThe prior distribution can be visualized using the plot() function.\n\nplot(prior)\n\n\n\n\n\n\n\n\nBy using the prior distribution to incorporate the assessments of the inherent risk and the control risk, the auditor can plan a sample while taking into account the risk-reducing information. The required minimum sample size is also 174 in this case.\n\nplanning(materiality = 0.03, expected = expected, conf.level = 1 - ar,\n         prior = prior)\n#> \n#>  Bayesian Audit Sample Planning\n#> \n#> minimum sample size = 174 \n#> sample size obtained in 175 iterations via method 'poisson' + 'prior'\n\n\n\n3.5.2 Benchmark Analysis\nThe auditor may incorporate information obtained through analytical procedures (Derks et al., 2021), such as a benchmark analysis, into the prior distribution for \\(\\theta\\). While we have previously discussed methods for constructing a prior distribution based on existing knowledge, there is no set procedure for incorporating information obtained through analytical procedures, as these procedures can vary significantly depending on the type of information being incorporated into the prior distribution. Therefore, it is important to thoroughly substantiate the data and assumptions used in this approach and to carefully consider how these assumptions are incorporated into the prior distribution.\nOne way to construct a prior distribution on the basis of data is through the use of regression models, such as benchmarking the relationship between sales and costs of sales within the auditee’s specific industry sector. The jfa package includes a data set benchmark that can be used for this example.\n\ndata(benchmark)\nhead(benchmark)\n#>       sales costofsales\n#> 1 186273256   140755372\n#> 2 336491541   248675452\n#> 3 222693077   164299866\n#> 4 364905221   285768790\n#> 5 382140185   280187371\n#> 6 113666950   101552955\n\nThe auditee’s the sum of the sales is $298,112,312 and the sum of the booked costs of sales is $223,994,405, respectively. This is indicated by a blue dot in the figure below, which visualizes the industry sales versus the cost of sales.\n\n\n\n\n\n\n\n\n\nThe relationship between the sales \\(S\\) and the cost of sales \\(C\\) can be modelled by a linear equation:\n\\[\\begin{equation}\n  C = \\beta_0 + \\beta_1 \\cdot S + \\epsilon.\n\\end{equation}\\]\nIn practice, this relationship is often more complex than is presented above, and the auditor must carefully construct and evaluate the applied regression model. However, for ease of understanding we will continue our example with this simplified model. The auditor can estimate the regression model using the following command:\n\nfit <- lm(costofsales ~ 1 + sales, data = benchmark)\nsummary(fit)\n#> \n#> Call:\n#> lm(formula = costofsales ~ 1 + sales, data = benchmark)\n#> \n#> Residuals:\n#>       Min        1Q    Median        3Q       Max \n#> -25736696  -7052141   -226945   6857840  25498106 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 2.413e+05  3.455e+06    0.07    0.944    \n#> sales       7.366e-01  1.310e-02   56.21   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 11150000 on 98 degrees of freedom\n#> Multiple R-squared:  0.9699, Adjusted R-squared:  0.9696 \n#> F-statistic:  3160 on 1 and 98 DF,  p-value: < 2.2e-16\n\nThe predicted cost of sales for the auditee, based on the industry benchmark, can be computed as follows:\n\nC_hat <- predict(fit, newdata = data.frame(sales = 298112312),\n                 interval = \"prediction\", level = 0.90)[1]\nC_hat\n#> [1] 219817866\n\nThe fitted regression line and the predicted cost of sales (red dot) are visualized in the figure below:\n\n\n\n\n\n\n\n\n\nThe prior distribution can be justified by the data and the auditee’s numerical prediction of the cost of sales. In this analytical procedure, the prior distribution on \\(\\theta\\) can utilize the relative error distribution from the linear regression. This relative error distribution, which is a Normal(\\(\\mu\\), \\(\\sigma\\)) distribution, captures the uncertainty of the prediction of the cost of sales through the use of linear regression, scaled to be a percentage of the total cost of sales. The mean \\(\\mu\\) of the prior distribution is determined by the relative deviation of the auditee’s booked cost of sales when compared to the predicted cost of sales according to the benchmark data \\(\\frac{C - \\hat{C}}{C}\\).\n\nmu <- (223994405 - C_hat) / 223994405\nmu\n#> [1] 0.01864573\n\nThe standard deviation of the prior distribution is expressed through the standard deviation of the distribution of \\(\\epsilon\\):\n\nstdev <- sd(fit$residuals) / 223994405\nstdev\n#> [1] 0.04951199\n\nThe Normal(0.019, 0.05) prior distribution can be constructed through a call to auditPrior(), where the likelihood of the prior is specified as normal. We call the function with method = \"param\" to manually specify the parameters of the prior distribution.\n\nprior <- auditPrior(method = \"param\", likelihood = \"normal\",\n                    alpha = mu, beta = stdev)\nsummary(prior)\n#> \n#>  Prior Distribution Summary\n#> \n#> Options:\n#>   Likelihood:                    normal \n#>   Specifics:                     α = 0.0186457; β = 0.049512 \n#> \n#> Results:\n#>   Functional form:               normal(μ = 0.019, σ = 0.05)T[0,1] \n#>   Mode:                          0.018646 \n#>   Mean:                          0.047096 \n#>   Median:                        0.041335 \n#>   Variance:                      0.0011116 \n#>   Skewness:                      NA \n#>   Information entropy (nat):     -2.1306 \n#>   95 percent upper bound:        0.11012 \n#>   Precision:                     0.091473\n\nThe specified prior distribution can be visualized using the plot() function.\n\nplot(prior)\n\n\n\n\n\n\n\n\nBy using this prior distribution, the required minimum sample size is 50.\n\nplan <- planning(materiality = 0.05, conf.level = 0.95,\n                 likelihood = \"binomial\", prior = prior)\nplan\n#> \n#>  Bayesian Audit Sample Planning\n#> \n#> minimum sample size = 50 \n#> sample size obtained in 51 iterations via method 'binomial' + 'prior'\n\nYou can inspect how the prior distribution compares to the expected posterior distribution by using the plot() function.\n\nplot(plan)\n\n\n\n\n\n\n\n\n\n\n\n\nDerks, K., Swart, J. de, Batenburg, P. van, Wagenmakers, E.-J., & Wetzels, R. (2021). Priors in a Bayesian audit: How integration of existing information into the prior distribution can improve audit transparency and efficiency. International Journal of Auditing, 25(3), 621–636. https://doi.org/10.1111/ijau.12240\n\n\nDyer, D., & Pierce, R. L. (1993). On the choice of the prior distribution in hypergeometric sampling. Communications in Statistics - Theory and Methods, 22(8), 2125–2146. https://doi.org/10.1080/03610929308831139"
  },
  {
    "objectID": "ch04.html#sampling-units",
    "href": "ch04.html#sampling-units",
    "title": "4  Selecting a Sample",
    "section": "4.1 Sampling Units",
    "text": "4.1 Sampling Units\nSelecting a subset from the population requires knowledge of the sampling units; physical representations of the population that needs to be audited. Generally, the auditor has to choose between two types of sampling units: individual items in the population or individual monetary units in the population. In order to perform statistical selection, the population must be divided into individual sampling units that can be assigned a probability to be included in the sample. The total collection of all sampling units which have been assigned a selection probability is called the sampling frame.\n\n4.1.1 Items\nA sampling unit for record (i.e., attributes) sampling is generally a characteristic of an item in the population. For example, suppose that you inspect a population of receipts. A possible sampling unit for record sampling can be the date of payment of the receipt. When a sampling unit (e.g., date of payment) is selected by the sampling method, the population item that corresponds to the sampled unit is included in the sample.\n\n\n4.1.2 Monetary Units\nA sampling unit for monetary unit sampling is different than a sampling unit for record sampling in that it is an individual monetary unit within an item or transaction, like an individual dollar. For example, a single sampling unit can be the 10\\(^{th}\\) dollar from a specific receipt in the population. When a sampling unit (e.g., individual dollar) is selected by the sampling method, the population item that includes the sampling unit is included in the sample."
  },
  {
    "objectID": "ch04.html#sampling-methods",
    "href": "ch04.html#sampling-methods",
    "title": "4  Selecting a Sample",
    "section": "4.2 Sampling Methods",
    "text": "4.2 Sampling Methods\nThis section discusses four sampling methods that are commonly used in audit sampling. The methods that will be discussed are:\n\nRandom sampling\nFixed interval sampling\nCell sampling\nModified sieve sampling\n\nFirst, let’s get some notation out of the way. As discussed in Chapter 2, the population size \\(N\\) is defined as the total set of individual sampling units (denoted by \\(x_i\\)).\n\\[\\begin{equation}\n  N = \\{x_1, x_2, \\dots, x_N\\}.\n\\end{equation}\\]\nIn statistical sampling, every sampling unit \\(x_i\\) in the population should receive a selection probability \\(p(x_i)\\). The purpose of the sampling method is to provide a framework to assign selection probabilities to each of the sampling units, and subsequently draw sampling units from the population until a set of size \\(n\\) has been created.\nTo illustrate how the resulting sample differs for various sampling methods, we will use the BuildIt data set included in the jfa package. These data can be loaded into R using the code below. For simplicity, we will use a sample size of \\(n = 10\\) for all examples.\n\ndata(BuildIt)\nn <- 10\n\n\n4.2.1 Random Sampling\nRandom sampling is the most simple and straight-forward selection method. The random sampling method provides a method that allows every sampling unit in the population an equal chance of being selected, meaning that every combination of sampling units has the same probability of being selected as every other combination of the same number of sampling units. Simply put, the algorithm draws a random selection of size \\(n\\) of the sampling units. Therefore, the selection probability for each sampling unit is defined as:\n\\[\\begin{equation}\n  p(x) = \\frac{1}{N}.\n\\end{equation}\\]\nTo make this procedure visually intuitive, Figure 4.2 provides an illustration of the random sampling method.\n\n\n\nFigure 4.2: Illustration of random sampling\n\n\n\nAdvantage(s): The random sampling method yields an optimal random selection, with the additional advantage that the sample can be easily extended by applying the same method again.\nDisadvantages: Because the selection probabilities are equal for all sampling units there is no guarantee that items with a large monetary value in the population will be included in the sample.\n\n\n4.2.1.1 Record Sampling\nRandom sampling can easily be coded in base R. First, we have to get a vector of of the possible items (rows) in the population that can be selected. When we are performing record sampling, we can simply use R’s build in sample() function to draw a random sample from a vector 1:nrow(BuildIt) representing the row indices of the items and store the result in a variable items.\n\nset.seed(1)\nitems <- sample(1:nrow(BuildIt), size = n, replace = FALSE)\nitems\n#>  [1] 1017  679 2177  930 1533  471 2347  270 1211 3379\n\nYou can then select the sample from the population using the selected indices stored in items.\n\nBuildIt[items, ]\n#>         ID bookValue auditValue\n#> 1017 50755    618.24     618.24\n#> 679  20237    669.75     669.75\n#> 2177  9517    454.02     454.02\n#> 930  85674    257.82     257.82\n#> 1533 31051    308.53     308.53\n#> 471  84375    824.66     824.66\n#> 2347 75616    623.70     623.70\n#> 270  82033    352.75     352.75\n#> 1211 12877     52.89      52.89\n#> 3379 85322    330.24     330.24\n\nThe sample can be reproduced in jfa via the selection() function. This function takes as input the population data, the sample size, and the characteristics of the sampling method. The argument units allows you to specify that you want to use record sampling (units = \"items\"), while the method argument enables you to specify that you are performing random sampling (method = 'random').\n\nset.seed(1)\nresult <- selection(data = BuildIt, size = n, units = \"items\",\n                    method = \"random\")\nresult$sample\n#>     row times    ID bookValue auditValue\n#> 1  1017     1 50755    618.24     618.24\n#> 2   679     1 20237    669.75     669.75\n#> 3  2177     1  9517    454.02     454.02\n#> 4   930     1 85674    257.82     257.82\n#> 5  1533     1 31051    308.53     308.53\n#> 6   471     1 84375    824.66     824.66\n#> 7  2347     1 75616    623.70     623.70\n#> 8   270     1 82033    352.75     352.75\n#> 9  1211     1 12877     52.89      52.89\n#> 10 3379     1 85322    330.24     330.24\n\n\n\n4.2.1.2 Monetary Unit Sampling\nWhen we are performing record sampling, we have to consider that each item in the population consists of multiple smaller items (i.e., the monetary units), which means that items with a higher book value should get a higher probability of being selected. The sample() function faciliates weighted selection via the prob argument, which takes a vector of values and, using normalization, computes the weights for selection. The call below is similar to before, but in this case we use the book values in the column bookValues of the data set to weigh the items and store the result in a variable items.\n\nset.seed(1)\nitems <- sample(1:nrow(BuildIt), size = n, replace = FALSE,\n                prob = BuildIt$bookValue)\nitems\n#>  [1] 2174 2928 1627  700  147 3056 3118 2045 1311  716\n\nYou can then select the sample from the population using the selected indices stored in items.\n\nBuildIt[items, ]\n#>         ID bookValue auditValue\n#> 2174 90260    625.98     625.98\n#> 2928 68595    548.21     548.21\n#> 1627 98301    429.07     429.07\n#> 700  29683    239.26     239.26\n#> 147  72906    677.62     677.62\n#> 3056 86317    246.22     246.22\n#> 3118 14548    204.63     204.63\n#> 2045 45416    381.05     381.05\n#> 1311 91955    398.96     398.96\n#> 716  12815    873.43     873.43\n\nThe sample can be reproduced in jfa via the selection() function. The argument units allows you to specify that you want to use monetary unit sampling (units = \"values\"), while the method argument enables you to specify that you are performing random sampling (method = 'random'). Note that you should provide the name of the column in the data that contains the monetary units via the values argument.\n\nset.seed(1)\nresult <- selection(data = BuildIt, size = n, units = \"values\",\n                    method = \"random\", values = \"bookValue\")\nresult$sample\n#>     row times    ID bookValue auditValue\n#> 1  2174     1 90260    625.98     625.98\n#> 2  2928     1 68595    548.21     548.21\n#> 3  1627     1 98301    429.07     429.07\n#> 4   700     1 29683    239.26     239.26\n#> 5   147     1 72906    677.62     677.62\n#> 6  3056     1 86317    246.22     246.22\n#> 7  3118     1 14548    204.63     204.63\n#> 8  2045     1 45416    381.05     381.05\n#> 9  1311     1 91955    398.96     398.96\n#> 10  716     1 12815    873.43     873.43\n\n\n\n\n4.2.2 Fixed Interval Sampling\nFixed interval sampling is a method designed for yielding representative samples from monetary populations. The algorithm determines a uniform interval on the (optionally ranked) sampling units. Next, a starting point is handpicked or randomly selected in the first interval and a sampling unit is selected throughout the population at each of the uniform intervals from the starting point. For example, if the interval has a width of 10 sampling units and sampling unit number 5 is chosen as the starting point, the sampling units 5, 15, 25, etc. are selected to be included in the sample.\nThe number of required intervals \\(I\\) can be determined by dividing the number of sampling units in the population by the required sample size:\n\\[\\begin{equation}\n  I = \\frac{N}{n},\n\\end{equation}\\]\nin which \\(n\\) is the required sample size and \\(N\\) is the total number of sampling units in the population.\nIf the space between the selected sampling units is equal, the selection probability for each sampling unit is theoretically defined as:\n\\[\\begin{equation}\n  p(x) = \\frac{1}{I},\n\\end{equation}\\]\nwith the property that the space between selected units \\(i\\) is the same as the interval \\(I\\), see Figure 4.3. However, in practice the selection is deterministic and completely depends on the chosen starting points (using start).\n\n\n\nFigure 4.3: Illustration of fixed interval sampling\n\n\nThe fixed interval method yields a sample that allows every sampling unit in the population an equal chance of being selected. However, the fixed interval method has the property that all items in the population with a monetary value larger than the interval \\(I\\) have an selection probability of one because one of these items’ sampling units are always selected from the interval. Note that, if the population is arranged randomly with respect to its deviation pattern, fixed interval sampling is equivalent to random selection.\n\nAdvantage(s): The advantage of the fixed interval sampling method is that it is often simple to understand and fast to perform. Another advantage is that, in monetary unit sampling, all items that are greater than the calculated interval will be included in the sample. In record sampling, since units can be ranked on the basis of value, there is also a guarantee that some large items will be in the sample.\nDisadvantage(s): A pattern in the population can coincide with the selected interval, rendering the sample less representative. What is sometimes seen as an added complication for this method is that the sample is hard to extend after drawing the initial sample. This is due to the chance of selecting the same sampling unit. However, by removing the already selected sampling units from the population and redrawing the intervals this problem can be efficiently solved.\n\n\n4.2.2.1 Record Sampling\nTo code fixed interval sampling in a record sampling context, we first have to compute the size of the interval we are working with. This is computed by dividing the number of items in the population by the desired sample size \\(n\\). Suppose the auditor wants to select a sample of 10 items, then the interval is computed by:\n\ninterval <- nrow(BuildIt) / n\n\nNext, we have to determine the starting point. We are going to take the fifth unit in each interval in this case.\n\nstart <- 5\n\nTo find which rows are part of the sample, we execute the following code:\n\nitems <- floor(start + interval * 0:(n - 1))\n\nYou can then select the sample from the population using the selected indices stored in items.\n\nBuildIt[items, ]\n#>         ID bookValue auditValue\n#> 5    55080    620.88     620.88\n#> 355  27934    749.38     749.38\n#> 705  21900    919.00     919.00\n#> 1055 66675    384.27     384.27\n#> 1405 13472    360.05     360.05\n#> 1755 61607    389.75     389.75\n#> 2105 68519    354.71     354.71\n#> 2455 91983    467.72     467.72\n#> 2805 25646    420.80     420.80\n#> 3155 94955    248.77     248.77\n\nThe sample can be reproduced in jfa via the selection() function. The argument units allows you to specify that you want to use record sampling (units = \"items\"), while the method argument enables you to specify that you are performing fixed interval sampling (method = 'interval'). Note that, by default, the first sampling unit from each interval is selected. However, this can be changed by setting the argument start to a different value.\n\nresult <- selection(data = BuildIt, size = n, units = \"items\",\n                    method = \"interval\", start = start)\nresult$sample\n#>     row times    ID bookValue auditValue\n#> 1     5     1 55080    620.88     620.88\n#> 2   355     1 27934    749.38     749.38\n#> 3   705     1 21900    919.00     919.00\n#> 4  1055     1 66675    384.27     384.27\n#> 5  1405     1 13472    360.05     360.05\n#> 6  1755     1 61607    389.75     389.75\n#> 7  2105     1 68519    354.71     354.71\n#> 8  2455     1 91983    467.72     467.72\n#> 9  2805     1 25646    420.80     420.80\n#> 10 3155     1 94955    248.77     248.77\n\n\n\n4.2.2.2 Monetary Unit Sampling\nIn monetary unit sampling, the only difference is that we are computing the interval on the basis of the booked values in the column bookValue of the data set. In this case, the starting point start = 5 determines which monetary unit from each interval is selected.\n\ninterval <- sum(BuildIt$bookValue) / n\n\nTo find which units are part of the sample, we execute the following code:\n\nunits <- floor(start + interval * 0:(n - 1))\n\nTo obtain which items are part of the sample, we can run the following for loop. Note that this does not take into account whether the book values contain negative values, which should not be included in the cumulative sum below.\n\nall_units <- ifelse(BuildIt$bookValue < 0, 0, BuildIt$bookValue)\nall_items <- 1:nrow(BuildIt)\nitems <- numeric(n)\nfor (i in 1:n) {\n  item <- which(units[i] <= cumsum(all_units))[1]\n  items[i] <- all_items[item]\n}\n\nYou can then select the sample from the population using the selected indices stored in items.\n\nBuildIt[items, ]\n#>         ID bookValue auditValue\n#> 1    82884    242.61     242.61\n#> 358  20711    610.88     610.88\n#> 715  99012    313.75     313.75\n#> 1081 65319    502.54     201.02\n#> 1421 88454    856.28     856.28\n#> 1774 87258    157.68     157.68\n#> 2103 48652    497.21     497.21\n#> 2435 37248   1041.44    1041.44\n#> 2787 10925    377.10     377.10\n#> 3152 71832   1001.82    1001.82\n\nThe sample can be reproduced in jfa via the selection() function. The argument units allows you to specify that you want to use monetary unit sampling (units = \"values\"), while the method argument enables you to specify that you are performing fixed interval sampling (method = 'interval'). Note that you should provide the name of the column in the data that contains the monetary units via the values argument.\n\nresult <- selection(data = BuildIt, size = n, units = \"values\",\n                    method = \"interval\", values = \"bookValue\", start = start)\nresult$sample\n#>     row times    ID bookValue auditValue\n#> 1     1     1 82884    242.61     242.61\n#> 2   358     1 20711    610.88     610.88\n#> 3   715     1 99012    313.75     313.75\n#> 4  1081     1 65319    502.54     201.02\n#> 5  1421     1 88454    856.28     856.28\n#> 6  1774     1 87258    157.68     157.68\n#> 7  2103     1 48652    497.21     497.21\n#> 8  2435     1 37248   1041.44    1041.44\n#> 9  2787     1 10925    377.10     377.10\n#> 10 3152     1 71832   1001.82    1001.82\n\n\n\n\n4.2.3 Cell Sampling\nThe cell sampling method divides the (optionally ranked) population into a set of intervals \\(I\\) that are computed through the previously given equations. Within each interval, a sampling unit is selected by randomly drawing a number between 1 and the interval range \\(I\\). This causes the space \\(i\\) between the sampling units to vary.\nLike in the fixed interval sampling method, the selection probability for each sampling unit is defined as:\n\\[\\begin{equation}\n  p(x) = \\frac{1}{I}.\n\\end{equation}\\]\n\n\n\nFigure 4.4: Illustration of cell sampling\n\n\nThe cell sampling method has the property that all items in the population with a monetary value larger than twice the interval \\(I\\) have a selection probability of one.\n\nAdvantage(s): More sets of samples are possible than in fixed interval sampling, as there is no systematic interval \\(i\\) to determine the selections. It is argued that the cell sampling algorithm offers a solution to the pattern problem in fixed interval sampling.\nDisadvantage(s): A disadvantage of this sampling method is that not all items in the population with a monetary value larger than the interval have a selection probability of one. Besides, population items can be in two adjacent cells, thereby creating the possibility that an items is included in the sample twice.\n\n\n4.2.3.1 Record Sampling\nTo code cell sampling in a record sampling context, we again have to compute the size of the interval we are working with:\n\ninterval <- nrow(BuildIt) / n\n\nNext, we have to randomly determine which items are going to be selected in each interval.\n\nset.seed(1)\nstarts <- floor(runif(n, 0, interval))\n\nTo find which rows are part of the sample, we execute the following code:\n\nitems <- floor(starts + interval * 0:(n - 1))\n\nYou can then select the sample from the population using the selected indices stored in items.\n\nBuildIt[items, ]\n#>         ID bookValue auditValue\n#> 92   75133    355.16     355.16\n#> 480  81037    456.27     456.27\n#> 900   1730    449.87     449.87\n#> 1367 36587    282.32     282.32\n#> 1470 10305    648.70     648.70\n#> 2064 96344    268.94     268.94\n#> 2430 60885    493.77     493.77\n#> 2681 60935    312.98     312.98\n#> 3020  8716    450.76     450.76\n#> 3171 61036    387.67     387.67\n\nThe sample can be reproduced in jfa via the selection() function. The argument units allows you to specify that you want to use record sampling (units = \"items\"), while the method argument enables you to specify that you are performing cell sampling (method = 'cell').\n\nset.seed(1)\nresult <- selection(data = BuildIt, size = n, units = \"items\",\n                    method = \"cell\")\nresult$sample\n#>     row times    ID bookValue auditValue\n#> 1    92     1 75133    355.16     355.16\n#> 2   480     1 81037    456.27     456.27\n#> 3   900     1  1730    449.87     449.87\n#> 4  1367     1 36587    282.32     282.32\n#> 5  1470     1 10305    648.70     648.70\n#> 6  2064     1 96344    268.94     268.94\n#> 7  2430     1 60885    493.77     493.77\n#> 8  2681     1 60935    312.98     312.98\n#> 9  3020     1  8716    450.76     450.76\n#> 10 3171     1 61036    387.67     387.67\n\n\n\n4.2.3.2 Monetary Unit Sampling\nIn monetary unit sampling, the only difference is that we are computing the interval on the basis of the booked values in the column bookValue of the data set. In this case, the starting points start determines which monetary unit from each interval is selected.\n\ninterval <- sum(BuildIt$bookValue) / n\n\nTo obtain which items are part of the sample, we can run the following for loop. Note that this does not take into account whether the book values contain negative values, which should not be included in the cumulative sum below.\n\nset.seed(1)\nall_units <- ifelse(BuildIt$bookValue < 0, 0, BuildIt$bookValue)\nall_items <- 1:nrow(BuildIt)\nintervals <- 0:n * interval\nitems <- numeric(n)\nfor (i in 1:n) {\n  unit <- stats::runif(1, intervals[i], intervals[i + 1])\n  item <- which(unit <= cumsum(all_units))[1]\n  items[i] <- all_items[item]\n}\n\nYou can then select the sample from the population using the selected indices stored in items.\n\nBuildIt[items, ]\n#>         ID bookValue auditValue\n#> 95   15009    415.60     415.60\n#> 486  79093    635.85     635.85\n#> 931  28025    429.14     429.14\n#> 1387 56444    296.37     296.37\n#> 1492 81443    543.80     543.80\n#> 2074 14196    270.45     270.45\n#> 2418 87743    347.99     347.99\n#> 2660 23927    454.81     454.81\n#> 3024 78925    251.44     251.44\n#> 3172 18286    450.57     450.57\n\nThe sample can be reproduced in jfa via the selection() function. The argument units allows you to specify that you want to use monetary unit sampling (units = \"values\"), while the method argument enables you to specify that you are performing cell sampling (method = 'cell'). Note that you should provide the name of the column in the data that contains the monetary units via the values argument.\n\nset.seed(1)\nresult <- selection(data = BuildIt, size = n, units = \"values\",\n                    method = \"cell\", values = \"bookValue\")\nresult$sample\n#>     row times    ID bookValue auditValue\n#> 1    95     1 15009    415.60     415.60\n#> 2   486     1 79093    635.85     635.85\n#> 3   931     1 28025    429.14     429.14\n#> 4  1387     1 56444    296.37     296.37\n#> 5  1492     1 81443    543.80     543.80\n#> 6  2074     1 14196    270.45     270.45\n#> 7  2418     1 87743    347.99     347.99\n#> 8  2660     1 23927    454.81     454.81\n#> 9  3024     1 78925    251.44     251.44\n#> 10 3172     1 18286    450.57     450.57\n\n\n\n\n4.2.4 Modified Sieve Sampling\nThe fourth option for the sampling method is modified sieve sampling (Hoogduin, Hall, & Tsay, 2010). The algorithm starts by selecting a standard uniform random number \\(R_i\\) between 0 and 1 for each item in the population. Next, the sieve ratio:\n\\[\\begin{equation}\n  S_i = \\frac{Y_i}{R_i}\n\\end{equation}\\]\nis computed for each item by dividing the book value of that item by the random number. Lastly, the items in the population are sorted by their sieve ratio \\(S\\) (in decreasing order) and the top \\(n\\) items are selected for inspection. In contrast to the classical sieve sampling method (Rietveld, 1978), the modified sieve sampling method provides precise control over sample sizes.\n\n4.2.4.1 Monetary Unit Sampling\n\nset.seed(1)\nall_units <- ifelse(BuildIt$bookValue < 0, 0, BuildIt$bookValue)\nall_items <- 1:nrow(BuildIt)\nri <- all_units / stats::runif(length(all_items), 0, 1)\nitems <- all_items[order(-ri)]\nitems <- items[1:n]\n\nYou can then select the sample from the population using the selected indices stored in items.\n\nBuildIt[items, ]\n#>         ID bookValue auditValue\n#> 2329 29919    681.10     681.10\n#> 2883 59402    279.29     279.29\n#> 1949 56012    581.22     581.22\n#> 3065 47482    621.73     621.73\n#> 1072 79901    789.97     789.97\n#> 488  50811    651.35     651.35\n#> 1916 53565    266.37     266.37\n#> 463  65768    480.89     480.89\n#> 1311 91955    398.96     398.96\n#> 2895  8688    492.02     492.02\n\nThe sample can be reproduced in jfa via the selection() function. The argument units allows you to specify that you want to use monetary unit sampling (units = \"values\"), while the method argument enables you to specify that you are performing modified sieve sampling (method = 'sieve'). Note that you should provide the name of the column in the data that contains the monetary units via the values argument.\n\nset.seed(1)\nresult <- selection(data = BuildIt, size = n, units = \"values\",\n                    method = \"sieve\", values = \"bookValue\")\nresult$sample\n#>     row times    ID bookValue auditValue\n#> 1  2329     1 29919    681.10     681.10\n#> 2  2883     1 59402    279.29     279.29\n#> 3  1949     1 56012    581.22     581.22\n#> 4  3065     1 47482    621.73     621.73\n#> 5  1072     1 79901    789.97     789.97\n#> 6   488     1 50811    651.35     651.35\n#> 7  1916     1 53565    266.37     266.37\n#> 8   463     1 65768    480.89     480.89\n#> 9  1311     1 91955    398.96     398.96\n#> 10 2895     1  8688    492.02     492.02"
  },
  {
    "objectID": "ch04.html#ordering-or-randomizing-the-population",
    "href": "ch04.html#ordering-or-randomizing-the-population",
    "title": "4  Selecting a Sample",
    "section": "4.3 Ordering or Randomizing the Population",
    "text": "4.3 Ordering or Randomizing the Population\nThe selection() function from the jfa package has three additional arguments which you can use to preprocess your population before selection. These arguments are order, decreasing and randomize.\nFirst, the order argument takes as input a column name in data which determines the order of the population. For example, you can order the population from lowest book value to highest book value before engaging in the selection. In this case, you should use the decreasing = FALSE (its default value) argument.\n\nset.seed(1)\nresult <- selection(data = BuildIt, size = n, units = \"values\",\n                    values = \"bookValue\", order = \"bookValue\")\nresult$sample\n#>     row times    ID bookValue auditValue\n#> 1  2662     1 30568     14.47      14.47\n#> 2  2307     1 95785    244.49     244.49\n#> 3  1639     1 39570    307.54     307.54\n#> 4  2318     1 11857    360.57     360.57\n#> 5  3409     1 18796    414.75     414.75\n#> 6  1158     1 28985    468.57     468.57\n#> 7  2892     1 27448    530.73     530.73\n#> 8  2759     1 16442    596.34     596.34\n#> 9  3112     1 62440    678.36     678.36\n#> 10 1820     1 82309    796.31     796.31\n\nNext, the randomize argument can be used to randomly shuffle the items in the population before selection. For example, you can randomly shuffle the population before engaging in the selection using randomize = TRUE.\n\nset.seed(1)\nresult <- selection(data = BuildIt, size = n, units = \"values\",\n                    values = \"bookValue\", randomize = TRUE)\nresult$sample\n#>     row times    ID bookValue auditValue\n#> 1  1017     1 50755    618.24     618.24\n#> 2  2097     1 53186    642.34     642.34\n#> 3  2508     1 55666    426.33     426.33\n#> 4   779     1 82046    569.21     227.68\n#> 5  2255     1 63601    234.12     234.12\n#> 6  2072     1 92569    517.14     517.14\n#> 7  1938     1 35525    366.94     366.94\n#> 8   595     1 30750    338.36     338.36\n#> 9  3207     1 74858    884.51     884.51\n#> 10 2981     1 24682    302.23     302.23"
  },
  {
    "objectID": "ch05.html#classical-evaluation",
    "href": "ch05.html#classical-evaluation",
    "title": "5  Evaluating a Sample",
    "section": "5.1 Classical Evaluation",
    "text": "5.1 Classical Evaluation\nClassical hypothesis testing uses the p-value to make a decision about whether to reject the hypothesis \\(H_0\\) or not. As an example, consider that an auditor wants to verify whether the population contains less than 5 percent misstatement, implying the hypotheses \\(H_1:\\theta<0.05\\) and \\(H_0:\\theta\\geq0.05\\). They have taken a sample of 100 items, of which 1 contained an error. They set the significance level for the p-value to 0.05, implying that \\(p < 0.05\\) will be enough to reject the hypothesis \\(H_0\\). The call below evaluates the sample using a classical non-stratified evaluation procedure.\n\nevaluation(materiality = 0.05, x = 1, n = 100)\n#> \n#>  Classical Audit Sample Evaluation\n#> \n#> data:  1 and 100\n#> number of errors = 1, number of samples = 100, taint = 1, p-value =\n#> 0.040428\n#> alternative hypothesis: true misstatement rate is less than 0.05\n#> 95 percent confidence interval:\n#>  0.00000000 0.04743865\n#> most likely estimate:\n#>  0.01 \n#> results obtained via method 'poisson'\n\nThe output shows that the most likely error in the population is estimated to be 1 / 100 = 1% and that the 95% (one-sided) confidence interval ranges from 0% to 4.74%. The output also shows that the p-value is lower than 0.05 implying that the hypothesis \\(H_0\\) can be rejected. Hence, the auditor is able to conclude that the sample provides sufficient evidence to state with reasonable assurance that the population does not contain material misstatement."
  },
  {
    "objectID": "ch05.html#bayesian-evaluation",
    "href": "ch05.html#bayesian-evaluation",
    "title": "5  Evaluating a Sample",
    "section": "5.2 Bayesian Evaluation",
    "text": "5.2 Bayesian Evaluation\nBayesian hypothesis testing uses the Bayes factor, \\(BF_{10}\\) or \\(BF_{01}\\), to make a statement about the evidence provided by the sample in support for one of the two hypotheses \\(H_1\\) or \\(H_0\\). As an example of how to interpret the Bayes factor, the value of \\(BF_{10} = 10\\) (provided by the evaluation() function) can be interpreted as: the data are 10 times more likely to have occurred underthe hypothesis \\(H_1\\) than under the hypothesis \\(H_0\\). \\(BF_{10} > 1\\) indicates evidence in favor of \\(H_1\\) and against \\(H_0\\), while \\(BF_{10} < 1\\) indicates evidence in favor of \\(H_0\\) and against \\(H_1\\). The evaluation() function returns the value for \\(BF_{10}\\), but \\(BF_{01}\\) can be computed as \\(\\frac{1}{BF_{10}}\\).\nConsider the previous example of an auditor who wants to verify whether the population contains less than 5 percent misstatement, implying the hypotheses \\(H_1:\\theta<0.05\\) and \\(H_0:\\theta\\geq0.05\\). They have taken a sample of 100 items, of which 1 was found to contain a misstatement. The prior distribution is assumed to be a default beta(1,1) prior. The call below evaluates the sample using a Bayesian non-stratified evaluation procedure.\n\nprior <- auditPrior(materiality = 0.05, method = \"default\", likelihood = \"binomial\")\nevaluation(materiality = 0.05, x = 1, n = 100, prior = prior)\n#> \n#>  Bayesian Audit Sample Evaluation\n#> \n#> data:  1 and 100\n#> number of errors = 1, number of samples = 100, taint = 1, BF₁₀ =\n#> 515.86\n#> alternative hypothesis: true misstatement rate is less than 0.05\n#> 95 percent credible interval:\n#>  0.00000000 0.04610735\n#> most likely estimate:\n#>  0.01 \n#> results obtained via method 'binomial' + 'prior'\n\nThe output shows that the most likely error in the population is estimated to be 1 / 100 = 1% and that the 95% (one-sided) credible interval ranges from 0% to 4.61%. The small difference between the classical and default Bayesian results is due to the prior distribution, which must be proper in order to calculate a Bayes factor (classical results can be emulated by constructing a prior with method = \"strict\" in the auditPrior() function). The Bayes factor in this case is shown to be \\(BF_{10}=515\\), meaning that the data from the sample are about 515 times more likely to occur under the hypothesis of tolerable misstatement than under the hypothesis of material misstatement.\nNote that this is a very high Bayes factor for the little data that is observed. That is because the Bayes factor is dependent on the prior distribution for \\(\\theta\\). As a rule of thumb, when the prior distribution is highly conservative (as with method = 'default') with respect to the hypothesis of tolerable misstatement, the Bayes factor tends to over quantify the evidence in favor of this hypothesis. You can mitigate this dependency by using a prior distribution that is impartial with respect to the hypotheses via method = \"impartial\" in the auditPrior() function (Derks et al., 2022).\n\nprior <- auditPrior(materiality = 0.05, method = \"impartial\", likelihood = \"binomial\")\nevaluation(materiality = 0.05, x = 1, n = 100, prior = prior)\n#> \n#>  Bayesian Audit Sample Evaluation\n#> \n#> data:  1 and 100\n#> number of errors = 1, number of samples = 100, taint = 1, BF₁₀ =\n#> 47.435\n#> alternative hypothesis: true misstatement rate is less than 0.05\n#> 95 percent credible interval:\n#>  0.00000000 0.04110834\n#> most likely estimate:\n#>  0.0088878 \n#> results obtained via method 'binomial' + 'prior'\n\nThe output shows that \\(BF_{10}=47\\), implying that under the assumption of impartiality there is strong evidence for \\(H_1\\), the hypothesis that the population contains misstatements lower than 5 percent of the population (tolerable misstatement). Since the two prior distributions both resulted in convincing Bayes factors, the results can be considered robust to the choice of prior distribution. Hence, the auditor is able to conclude that the sample provides convincing evidence to state that the population does not contain material misstatement."
  },
  {
    "objectID": "ch05.html#evaluation-using-data",
    "href": "ch05.html#evaluation-using-data",
    "title": "5  Evaluating a Sample",
    "section": "5.3 Evaluation using Data",
    "text": "5.3 Evaluation using Data\nFor this example, we take the allowances that set that comes with the package. This data set contains 3500 financial statement line items, each with a booked value bookValue and, for illustrative purposes, and audited (true) value auditValue. Since the focus of this vignette is the evaluation stage in the audit, the sample is already indicated in the data set. The performance materiality in this example is set to 5%.\n\ndata(allowances)\nhead(allowances)\n#>   item branch bookValue auditValue times\n#> 1    1     12      1600       1600     1\n#> 2    2     12      1625         NA     0\n#> 3    3     12      1775         NA     0\n#> 4    4     12      1250       1250     1\n#> 5    5     12      1400         NA     0\n#> 6    6     12      1190         NA     0\n\nEvaluating a non-stratified sample using data requires specification of the data, values and values.audit arguments. The input for these arguments is the name of the specific column in data.\n\n5.3.1 Classical Evaluation\nThe call below evaluates the allowances sample using a classical non-stratified evaluation procedure.\n\nx <- evaluation(\n  materiality = 0.05, data = allowances,\n  values = \"bookValue\", values.audit = \"auditValue\", times = \"times\"\n)\nsummary(x)\n#> \n#>  Classical Audit Sample Evaluation Summary\n#> \n#> Options:\n#>   Confidence level:               0.95 \n#>   Materiality:                    0.05 \n#>   Hypotheses:                     H₀: Θ >= 0.05 vs. H₁: Θ < 0.05 \n#>   Method:                         poisson \n#> \n#> Data:\n#>   Sample size:                    1604 \n#>   Number of errors:               401 \n#>   Sum of taints:                  252.9281046 \n#> \n#> Results:\n#>   Most likely error:              0.15769 \n#>   95 percent confidence interval: [0, 0.175] \n#>   Precision:                      0.017311 \n#>   p-value:                        1\n\nIn this case, the output shows that the estimate of the misstatement in the population is 15.77%, with the 95% (one-sided) confidence interval ranging from 0% to 17.5%.\n\n\n5.3.2 Bayesian evaluation\nThe call below evaluates the allowances sample using a Bayesian non-stratified evaluation procedure.\n\nx <- evaluation(\n  materiality = 0.05, data = allowances, prior = TRUE,\n  values = \"bookValue\", values.audit = \"auditValue\", times = \"times\"\n)\nsummary(x)\n#> \n#>  Bayesian Audit Sample Evaluation Summary\n#> \n#> Options:\n#>   Confidence level:               0.95 \n#>   Materiality:                    0.05 \n#>   Hypotheses:                     H₀: Θ > 0.05 vs. H₁: Θ < 0.05 \n#>   Method:                         poisson \n#>   Prior distribution:             gamma(α = 1, β = 1) \n#> \n#> Data:\n#>   Sample size:                    1604 \n#>   Number of errors:               401 \n#>   Sum of taints:                  252.9281046 \n#> \n#> Results:\n#>   Posterior distribution:         gamma(α = 253.928, β = 1605) \n#>   Most likely error:              0.15759 \n#>   95 percent credible interval:   [0, 0.17489] \n#>   Precision:                      0.0173 \n#>   BF₁₀:                            0\n\nThe output shows that the estimate of the misstatement in the population is 15.76%, with the 95% (one-sided) credible interval ranging from 0% to 17.49%."
  },
  {
    "objectID": "ch06.html#no-pooling",
    "href": "ch06.html#no-pooling",
    "title": "6  Evaluating a Stratified Sample",
    "section": "6.1 No pooling",
    "text": "6.1 No pooling\nNo pooling (pooling = \"none\", default) assumes no similarities between strata. This means that the prior distribution specified through prior is applied independently for each stratum. This allows for independent estimates for the misstatement in each stratum but also results in a relatively high uncertainty in the population estimate. The call below evaluates the sample using a Bayesian stratified evaluation procedure, in which the stratum estimates are poststratified to arrive at the population estimate.\n\nset.seed(1) # Important because the posterior distribution is determined via sampling\nresult_np <- evaluation(\n  materiality = 0.05, method = \"binomial\", prior = TRUE,\n  n = retailer$samples, x = retailer$errors, N.units = retailer$items,\n  alternative = \"two.sided\", pooling = \"none\"\n)\nsummary(result_np)\n#> \n#>  Bayesian Audit Sample Evaluation Summary\n#> \n#> Options:\n#>   Confidence level:               0.95 \n#>   Population size:                144000 \n#>   Materiality:                    0.05 \n#>   Hypotheses:                     H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 \n#>   Method:                         binomial \n#>   Prior distribution:             Determined via MCMC sampling \n#> \n#> Data:\n#>   Sample size:                    2575 \n#>   Number of errors:               115 \n#>   Sum of taints:                  115 \n#> \n#> Results:\n#>   Posterior distribution:         Determined via MCMC sampling \n#>   Most likely error:              0.058487 \n#>   95 percent credible interval:   [0.042763, 0.082201] \n#>   Precision:                      0.023714 \n#>   BF₁₀:                            0 \n#> \n#> Strata (20):\n#>        N   n  x  t     mle      lb      ub precision\n#> 1   5000 300 21 21 0.07000 0.04637 0.10467   0.03467\n#> 2   5000 300 16 16 0.05333 0.03324 0.08489   0.03156\n#> 3   5000 300 15 15 0.05000 0.03069 0.08086   0.03086\n#> 4   5000 300 14 14 0.04667 0.02816 0.07681   0.03014\n#> 5   5000 300 16 16 0.05333 0.03324 0.08489   0.03156\n#> 6   5000 150  5  5 0.03333 0.01472 0.07558   0.04225\n#> 7   5000 150  4  4 0.02667 0.01084 0.06643   0.03977\n#> 8   5000 150  3  3 0.02000 0.00726 0.05696   0.03696\n#> 9   5000 150  4  4 0.02667 0.01084 0.06643   0.03977\n#> 10  5000 150  5  5 0.03333 0.01472 0.07558   0.04225\n#> 11 10000  50  2  2 0.04000 0.01230 0.13459   0.09459\n#> 12 10000  50  3  3 0.06000 0.02178 0.16242   0.10242\n#> 13 10000  50  2  2 0.04000 0.01230 0.13459   0.09459\n#> 14 10000  50  1  1 0.02000 0.00478 0.10447   0.08447\n#> 15 10000  50  0  0 0.00000 0.00050 0.06978   0.06978\n#> 16 10000  15  0  0 0.00000 0.00158 0.20591   0.20591\n#> 17 10000  15  0  0 0.00000 0.00158 0.20591   0.20591\n#> 18 10000  15  0  0 0.00000 0.00158 0.20591   0.20591\n#> 19 10000  15  1  1 0.06667 0.01551 0.30232   0.23565\n#> 20  4000  15  3  3 0.20000 0.07266 0.45646   0.25646\n\nIn this case, the output of the summary() function shows that the estimate of the misstatement in the population is 5.85%, with the 95% credible interval ranging from 4.28% to 8.22%. The stratum estimates differ substantially from each other but are relatively uncertain.\n\nplot(result_np, type = \"estimates\")\n\n\n\n\n\n\n\n\nThe prior and posterior distribution for the population misstatement can be requested via the plot() function.\n\nplot(result_np, type = \"posterior\")"
  },
  {
    "objectID": "ch06.html#complete-pooling",
    "href": "ch06.html#complete-pooling",
    "title": "6  Evaluating a Stratified Sample",
    "section": "6.2 Complete pooling",
    "text": "6.2 Complete pooling\nComplete pooling (pooling = \"complete\") assumes no differences between strata. This has the advantages that data from all strata can be aggregated, which decreases the uncertainty in the population estimate compared to the no pooling approach. However, the disadvantage of this approach is that it does not facilitate the distinction between between strata, as every stratum receives the same estimate equal to that of the population. The call below evaluates the sample using a Bayesian stratified evaluation procedure, in which the strata are assumed to be the same.\n\nresult_cp <- evaluation(\n  materiality = 0.05, method = \"binomial\", prior = TRUE,\n  n = retailer$samples, x = retailer$errors, N.units = retailer$items,\n  alternative = \"two.sided\", pooling = \"complete\"\n)\nsummary(result_cp)\n#> \n#>  Bayesian Audit Sample Evaluation Summary\n#> \n#> Options:\n#>   Confidence level:               0.95 \n#>   Population size:                144000 \n#>   Materiality:                    0.05 \n#>   Hypotheses:                     H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 \n#>   Method:                         binomial \n#>   Prior distribution:             beta(α = 1, β = 1) \n#> \n#> Data:\n#>   Sample size:                    2575 \n#>   Number of errors:               115 \n#>   Sum of taints:                  115 \n#> \n#> Results:\n#>   Posterior distribution:         beta(α = 116, β = 2461) \n#>   Most likely error:              0.04466 \n#>   95 percent credible interval:   [0.03735, 0.053345] \n#>   Precision:                      0.0086852 \n#>   BF₁₀:                            0.022725 \n#> \n#> Strata (20):\n#>        N   n  x  t     mle      lb      ub precision    bf10\n#> 1   5000 300 21 21 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 2   5000 300 16 16 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 3   5000 300 15 15 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 4   5000 300 14 14 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 5   5000 300 16 16 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 6   5000 150  5  5 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 7   5000 150  4  4 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 8   5000 150  3  3 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 9   5000 150  4  4 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 10  5000 150  5  5 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 11 10000  50  2  2 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 12 10000  50  3  3 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 13 10000  50  2  2 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 14 10000  50  1  1 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 15 10000  50  0  0 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 16 10000  15  0  0 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 17 10000  15  0  0 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 18 10000  15  0  0 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 19 10000  15  1  1 0.04466 0.03735 0.05335   0.00869 0.02273\n#> 20  4000  15  3  3 0.04466 0.03735 0.05335   0.00869 0.02273\n\nFor example, the output of the summary() function shows that the estimate of the misstatement in the population is 4.47%, with the 95% credible interval ranging from 3.74% to 5.33%. Since the data is aggregated, the stratum estimates contain relatively little uncertainty. However, the probability of misstatement in stratum 20 (many misstatements) under this assumption is the same as that of stratum 15 (few misstatements).\n\nplot(result_cp, type = \"estimates\")\n\n\n\n\n\n\n\n\nThe prior and posterior distribution for the population misstatement can be requested via the plot() function.\n\nplot(result_cp, type = \"posterior\")"
  },
  {
    "objectID": "ch06.html#partial-pooling",
    "href": "ch06.html#partial-pooling",
    "title": "6  Evaluating a Stratified Sample",
    "section": "6.3 Partial pooling",
    "text": "6.3 Partial pooling\nFinally, partial pooling (pooling = \"partial\") assumes differences and similarities between strata. This allows the auditor to differentiate between strata, while also sharing information between the strata to reduce uncertainty in the population estimate. The call below evaluates the sample using a Bayesian stratified evaluation procedure, in which the stratum estimates are poststratified to arrive at the population estimate.\n\nset.seed(1) # Important because the posterior distribution is determined via sampling\nresult_pp <- evaluation(\n  materiality = 0.05, method = \"binomial\", prior = TRUE,\n  n = retailer$samples, x = retailer$errors, N.units = retailer$items,\n  alternative = \"two.sided\", pooling = \"partial\"\n)\nsummary(result_pp)\n#> \n#>  Bayesian Audit Sample Evaluation Summary\n#> \n#> Options:\n#>   Confidence level:               0.95 \n#>   Population size:                144000 \n#>   Materiality:                    0.05 \n#>   Hypotheses:                     H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 \n#>   Method:                         binomial \n#>   Prior distribution:             Determined via MCMC sampling \n#> \n#> Data:\n#>   Sample size:                    2575 \n#>   Number of errors:               115 \n#>   Sum of taints:                  115 \n#> \n#> Results:\n#>   Posterior distribution:         Determined via MCMC sampling \n#>   Most likely error:              0.043714 \n#>   95 percent credible interval:   [0.034206, 0.053522] \n#>   Precision:                      0.0098086 \n#>   BF₁₀:                            0.019031 \n#> \n#> Strata (20):\n#>        N   n  x  t     mle      lb      ub precision\n#> 1   5000 300 21 21 0.04809 0.03814 0.08017   0.03207\n#> 2   5000 300 16 16 0.04569 0.03328 0.06816   0.02247\n#> 3   5000 300 15 15 0.04497 0.03207 0.06407   0.01909\n#> 4   5000 300 14 14 0.04433 0.03043 0.06220   0.01787\n#> 5   5000 300 16 16 0.04620 0.03281 0.06708   0.02088\n#> 6   5000 150  5  5 0.04348 0.02367 0.05968   0.01620\n#> 7   5000 150  4  4 0.04126 0.02088 0.05677   0.01551\n#> 8   5000 150  3  3 0.04164 0.01846 0.05501   0.01337\n#> 9   5000 150  4  4 0.04229 0.02137 0.05677   0.01448\n#> 10  5000 150  5  5 0.04181 0.02328 0.05844   0.01663\n#> 11 10000  50  2  2 0.04410 0.02417 0.06688   0.02278\n#> 12 10000  50  3  3 0.04418 0.02616 0.07366   0.02948\n#> 13 10000  50  2  2 0.04318 0.02261 0.06669   0.02351\n#> 14 10000  50  1  1 0.04280 0.01993 0.06367   0.02087\n#> 15 10000  50  0  0 0.04234 0.01641 0.05928   0.01694\n#> 16 10000  15  0  0 0.04331 0.02039 0.06699   0.02369\n#> 17 10000  15  0  0 0.04424 0.02027 0.06700   0.02276\n#> 18 10000  15  0  0 0.04330 0.01984 0.06587   0.02257\n#> 19 10000  15  1  1 0.04293 0.02313 0.07342   0.03049\n#> 20  4000  15  3  3 0.04527 0.03047 0.10417   0.05889\n\nIn this case, the output shows that the estimate of the misstatement in the population is 4.34%, with the 95% credible interval ranging from 3.45% to 5.33%. Note that this population estimate is substantially less uncertain than that of the no pooling approach. Note that, like in the no pooling approach, the stratum estimates are different from each other but lie closer together and are less uncertain.\n\nplot(result_pp, type = \"estimates\")\n\n\n\n\n\n\n\n\nThe prior and posterior distribution for the population misstatement can be requested via the plot() function.\n\nplot(result_pp, type = \"posterior\")"
  },
  {
    "objectID": "ch06.html#evaluation-using-data",
    "href": "ch06.html#evaluation-using-data",
    "title": "6  Evaluating a Stratified Sample",
    "section": "6.4 Evaluation using data",
    "text": "6.4 Evaluation using data\nFor this example, we take the allowances that set that comes with the package. This data set contains 3500 financial statement line items, each with a booked value bookValue and, for illustrative purposes, and audited (true) value auditValue. Since the focus of this vignette is the evaluation stage in the audit, the sample is already indicated in the data set. The performance materiality in this example is set to 5%.\n\ndata(allowances)\nhead(allowances)\n#>   item branch bookValue auditValue times\n#> 1    1     12      1600       1600     1\n#> 2    2     12      1625         NA     0\n#> 3    3     12      1775         NA     0\n#> 4    4     12      1250       1250     1\n#> 5    5     12      1400         NA     0\n#> 6    6     12      1190         NA     0\n\nEvaluating a stratified sample using data requires specification of the data, values, values.audit and strata arguments in the evaluation() function. In this case, the units are monetary and calculated by aggregating the book values of the items in each stratum.\n\nN.units <- aggregate(allowances$bookValue, list(allowances$branch), sum)$x\n\n\n6.4.1 Classical Evaluation\nThe call below evaluates the allowances sample using a classical stratified evaluation procedure, in which the stratum estimates are poststratified to arrive at the population estimate.\n\nx <- evaluation(\n  materiality = 0.05, data = allowances,\n  values = \"bookValue\", values.audit = \"auditValue\", strata = \"branch\", times = \"times\",\n  alternative = \"two.sided\", N.units = N.units\n)\nsummary(x)\n#> \n#>  Classical Audit Sample Evaluation Summary\n#> \n#> Options:\n#>   Confidence level:               0.95 \n#>   Population size:                16772249 \n#>   Materiality:                    0.05 \n#>   Hypotheses:                     H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 \n#>   Method:                         poisson \n#> \n#> Data:\n#>   Sample size:                    1604 \n#>   Number of errors:               401 \n#>   Sum of taints:                  252.9281046 \n#> \n#> Results:\n#>   Most likely error:              0.14723 \n#>   95 percent confidence interval: [0.12549, 0.18239] \n#>   Precision:                      0.03516 \n#>   p-value:                        NA \n#> \n#> Strata (16):\n#>             N   n   x         t     mle      lb      ub precision p.value\n#> 1   317200.09  87   6   1.27814 0.01469 0.00073 0.06950   0.05481 0.46285\n#> 2  2792814.33 305 233 193.23313 0.63355 0.54558 0.72945   0.09590 0.00000\n#> 3  1144231.69  55   3   3.00000 0.05455 0.01105 0.15940   0.10486 0.75827\n#> 4   414202.89  70  45  15.05094 0.21501 0.11878 0.35434   0.13933 0.00000\n#> 5    96660.53  18   1   0.64537 0.03585 0.00015 0.27456   0.23871 0.59343\n#> 6   348006.13  34   1   0.17866 0.00525 0.00000 0.11926   0.11401 1.00000\n#> 7  2384079.33  55  14   9.44448 0.17172 0.07885 0.32122   0.14950 0.00058\n#> 8  1840399.33  96   1   0.00813 0.00008 0.00000 0.03860   0.03852 0.10355\n#> 9   563957.70  92   0   0.00000 0.00000 0.00000 0.04010   0.04010 0.01783\n#> 10 3198877.73 201   7   0.92023 0.00458 0.00009 0.02703   0.02245 0.00122\n#> 11 1983299.06 128   7   1.50034 0.01172 0.00084 0.05013   0.03841 0.10773\n#> 12  319144.13  86   5   1.68141 0.01955 0.00174 0.07806   0.05851 0.46069\n#> 13  148905.79  25   0   0.00000 0.00000 0.00000 0.14756   0.14756 0.64187\n#> 14  513058.76 150   0   0.00000 0.00000 0.00000 0.02459   0.02459 0.00134\n#> 15  432007.61 150  39  21.80000 0.14533 0.09026 0.22045   0.07511 0.00001\n#> 16  275403.70  52  39   4.18726 0.08052 0.02237 0.20215   0.12163 0.12258\n\nIn this case, the output shows that the estimate of the misstatement in the population is 14.72%, with the 95% confidence interval ranging from 12.55% to 18.26%. The precision of the population estimate is 3.54%. The stratum estimates can be seen in the output of the summary() function and are visualized below.\n\nplot(x, type = \"estimates\")\n\n\n\n\n\n\n\n\n\n\n6.4.2 Bayesian Evaluation\nBayesian inference can improve upon the estimates of the classical approach by pooling information between strata where possible. The call below evaluates the allowances sample using a Bayesian multilevel stratified evaluation procedure, in which the stratum estimates are poststratified to arrive at the population estimate.\n\nx <- evaluation(\n  materiality = 0.05, data = allowances, prior = TRUE,\n  values = \"bookValue\", values.audit = \"auditValue\", strata = \"branch\", times = \"times\",\n  alternative = \"two.sided\", N.units = N.units, pooling = \"partial\"\n)\nsummary(x)\n#> \n#>  Bayesian Audit Sample Evaluation Summary\n#> \n#> Options:\n#>   Confidence level:               0.95 \n#>   Population size:                16772249 \n#>   Materiality:                    0.05 \n#>   Hypotheses:                     H₀: Θ = 0.05 vs. H₁: Θ ≠ 0.05 \n#>   Method:                         poisson \n#>   Prior distribution:             Determined via MCMC sampling \n#> \n#> Data:\n#>   Sample size:                    1350 \n#>   Number of errors:               401 \n#>   Sum of taints:                  224.657517 \n#> \n#> Results:\n#>   Posterior distribution:         Determined via MCMC sampling \n#>   Most likely error:              0.1555 \n#>   95 percent credible interval:   [0.1458, 0.17009] \n#>   Precision:                      0.014595 \n#>   BF₁₀:                            3.1386e+15 \n#> \n#> Strata (16):\n#>             N   n   x         t     mle      lb      ub precision\n#> 1   317200.09  62   6   1.07814 0.02037 0.01356 0.03659   0.01622\n#> 2  2792814.33 283 233 176.87807 0.60930 0.57298 0.65128   0.04198\n#> 3  1144231.69  55   3   3.00000 0.16735 0.11682 0.24582   0.07847\n#> 4   414202.89  48  45  11.65094 0.27653 0.22254 0.34868   0.07214\n#> 5    96660.53   9   1   0.21512 0.02207 0.01055 0.08932   0.06725\n#> 6   348006.13  14   1   0.04467 0.01233 0.00723 0.04022   0.02790\n#> 7  2384079.33  44  14   6.65401 0.13637 0.09156 0.21540   0.07903\n#> 8  1840399.33  78   1   0.00813 0.00640 0.00458 0.00961   0.00320\n#> 9   563957.70  74   0   0.00000 0.00608 0.00461 0.00957   0.00349\n#> 10 3198877.73 184   7   0.89982 0.00804 0.00615 0.01074   0.00270\n#> 11 1983299.06 111   7   1.35066 0.01525 0.01077 0.02243   0.00718\n#> 12  319144.13  56   5   1.19069 0.08428 0.05625 0.14502   0.06074\n#> 13  148905.79  10   0   0.00000 0.01216 0.00636 0.04545   0.03329\n#> 14  513058.76 150   0   0.00000 0.00472 0.00377 0.00633   0.00161\n#> 15  432007.61 128  39  18.30000 0.27398 0.23217 0.33730   0.06332\n#> 16  275403.70  44  39   3.38726 0.07640 0.05784 0.10161   0.02521\n\nThe output shows that the estimate of the misstatement in the population is 15.66%, with the 95% credible interval ranging from 14.59% to 17%. The precision of the population estimate is 1.34%, which is substantially lower than that of the classical approach. The stratum estimates can be seen in the output of the summary() function and are visualized below.\n\nplot(x, type = \"estimates\")\n\n\n\n\n\n\n\n\nThe prior and posterior distribution for the population misstatement can be requested via the plot() function.\n\nplot(x, type = \"posterior\")"
  },
  {
    "objectID": "ch07.html#jasp-for-audit-gui",
    "href": "ch07.html#jasp-for-audit-gui",
    "title": "7  Other Software",
    "section": "7.1 JASP for Audit (GUI)",
    "text": "7.1 JASP for Audit (GUI)\nJASP for Audit (Derks et al., 2021) is an add-on module for JASP (JASP Team, 2022), based on the jfa package, that facilitates statistical audit sampling. Concretely, it contains graphical user interfaces (GUI’s) for calculating sample sizes, selecting items according to standard audit sampling techniques, and performing inference about the population misstatement on the basis of a data sample or summary statistics of a sample. The module also features Bayesian equivalents of these analyses that enable the user to easily incorporate prior information into the statistical procedure. In all analyses, the Audit module offers explanatory text that helps the auditor in interpreting, explaining, and reporting the analysis. Since JASP for Audit is an R-based GUI around jfa, its functionality can be mapped almost one-on-one to that of the package.\n\n\n\n\nFigure 7.1: The JASP welcome screen.\n\n\n\n\n7.1.1 Planning\nPlanning a sample in JASP for Audit works similar to how you would do it in jfa. For example, the screenshot below shows how to plan a minimum sample size for a performance materiality of 5% using a beta(1, 1) prior distribution, while expecting zero misstatements in the sample.\n\n\n\n\nFigure 7.2: The JASP interface for planning a sample.\n\n\n\nIn jfa, these results can be reproduced via the following command:\n\nplanning(materiality = 0.05, likelihood = \"binomial\", prior = TRUE)\n#> \n#>  Bayesian Audit Sample Planning\n#> \n#> minimum sample size = 58 \n#> sample size obtained in 59 iterations via method 'binomial' + 'prior'\n\n\n\n7.1.2 Selection\nSelecting a sample in JASP for Audit works similar to how you would do it in jfa. For example, the screenshot below shows how to select a sample of 60 monetary units from the BuildIt data set that is included in the package using a fixed interval sampling method with a starting point of 1.\n\nset.seed(1)\ndata(BuildIt)\nresult <- selection(data = BuildIt, size = 60, method = \"interval\", start = 1,\n                    units = \"values\", values = \"bookValue\")\nhead(result$sample)\n#>   row times    ID bookValue auditValue\n#> 1   1     1 82884    242.61     242.61\n#> 2  63     1 51272    248.40     248.40\n#> 3 123     1 37985    562.09     562.09\n#> 4 183     1 96080    449.07     449.07\n#> 5 240     1 92819    690.08     690.08\n#> 6 302     1 94296    198.59     198.59\n\n\n\n\n\nFigure 7.3: The JASP interface for selecting a sample.\n\n\n\n\n\n7.1.3 Evaluation\nEvaluating a sample in JASP for Audit works similar to how you would do it in jfa. For example, the screenshot below shows how to evaluating a sample of \\(n = 60\\) containing \\(x = 0\\) misstatements against a performance materiality of 5% using a beta(1, 1) prior distribution.\n\n\n\n\nFigure 7.4: The JASP interface for evaluating a sample.\n\n\n\nIn jfa, these results can be reproduced via the following command:\n\nevaluation(materiality = 0.05, method = \"binomial\", x = 2, n = 93, prior = TRUE)\n#> \n#>  Bayesian Audit Sample Evaluation\n#> \n#> data:  2 and 93\n#> number of errors = 2, number of samples = 93, taint = 2, BF₁₀ =\n#> 111.66\n#> alternative hypothesis: true misstatement rate is less than 0.05\n#> 95 percent credible interval:\n#>  0.0000000 0.0654624\n#> most likely estimate:\n#>  0.021505 \n#> results obtained via method 'binomial' + 'prior'"
  },
  {
    "objectID": "ch07.html#mus-r",
    "href": "ch07.html#mus-r",
    "title": "7  Other Software",
    "section": "7.2 MUS (R)",
    "text": "7.2 MUS (R)\nMUS (Prömpers & Guimarães, 2019) is an R package proving sampling and evaluation methods to apply Monetary Unit Sampling during an audit of financial statements. The package is available via CRAN and can be downloaded with:\n\ninstall.packages(\"MUS\")\n\n\n\n\n\nDerks, K., Swart, J. de, Wagenmakers, E., Wille, J., & Wetzels, R. (2021). JASP for Audit: Bayesian tools for the auditing practice. Journal of Open Source Software, 6(68), 2733.\n\n\nJASP Team. (2022). JASP (Version 0.16.4)[Computer software]. https://jasp-stats.org/\n\n\nPrömpers, H., & Guimarães, A. (2019). MUS: Monetary unit sampling and estimation methods, widely used in auditing. https://CRAN.R-project.org/package=MUS"
  },
  {
    "objectID": "chref.html",
    "href": "chref.html",
    "title": "References",
    "section": "",
    "text": "American Institute of Certified Public Accountants (AICPA). (2016a).\nAppendix A: Attributes statistical sampling tables. In\nAudit guide: Audit sampling. https://doi.org/10.1002/9781119448617.app1\n\n\nAmerican Institute of Certified Public Accountants (AICPA). (2016b).\nAppendix C: Monetary unit sampling tables. In Audit\nguide: Audit sampling. https://doi.org/10.1002/9781119448617.app3\n\n\nChang, W. (2022). R Graphics Cookbook. O’Reilly.\nhttps://r-graphics.org/\n\n\nDerks, K., Swart, J. de, Batenburg, P. van, Wagenmakers, E.-J., &\nWetzels, R. (2021). Priors in a Bayesian audit: How\nintegration of existing information into the prior distribution can\nimprove audit transparency and efficiency. International Journal of\nAuditing, 25(3), 621–636. https://doi.org/10.1111/ijau.12240\n\n\nDerks, K., Swart, J. de, Wagenmakers, E., Wille, J., & Wetzels, R.\n(2021). JASP for Audit: Bayesian\ntools for the auditing practice. Journal of Open Source\nSoftware, 6(68), 2733.\n\n\nDyer, D., & Pierce, R. L. (1993). On the choice of the prior\ndistribution in hypergeometric sampling. Communications in\nStatistics - Theory and Methods, 22(8), 2125–2146. https://doi.org/10.1080/03610929308831139\n\n\nGrolemund, G. (2014). Hands-On Programming with\nR. https://rstudio-education.github.io/hopr/\n\n\nInternational Auditing and Assurance Standards Board (IAASB). (2018).\nISA 530: Audit sampling. In International standards on\nauditing (ISA).\n\n\nJASP Team. (2022). JASP (Version\n0.16.4)[Computer software]. https://jasp-stats.org/\n\n\nLin, J. (2021). Audit Analytics with\nR. https://auditanalytics.jonlin.ca/\n\n\nPrömpers, H., & Guimarães, A. (2019). MUS: Monetary\nunit sampling and estimation methods, widely used in auditing. https://CRAN.R-project.org/package=MUS\n\n\nStewart, T. (2012). Technical notes on the AICPA audit\nguide audit sampling. 5–8.\n\n\nWickam, H., & Brian, J. (2022). R Packages. https://r-pkgs.org/\n\n\nWickam, H., & Grolemund, G. (2017). R for\nData Science. https://r4ds.had.co.nz/\n\n\nWilke, C. O. (2022). Fundamentals of Data\nVisualization. https://clauswilke.com/dataviz/"
  }
]