```{r echo = FALSE, cache = FALSE}
source("utils.R", local = TRUE)
```

::: {.callout-note appearance="simple"}
You are reading the work-in-progress first edition of Statistical Auditing with
R. This chapter is currently a dumping ground of ideas, and it is incomplete.
:::

# Planning {#chap-planning}

One of the key considerations in audit sampling is determining the appropriate
sample size to reduce the sampling risk to an appropriately low level, while
minimizing audit effort. To quantify the sampling risk, it is necessary to
specify the statistical model that connects the data to the population
misstatement, referred to as the likelihood. This chapter will delve into three
standard likelihoods commonly employed in audit sampling: the hypergeometric
likelihood, the binomial likelihood, and the Poisson likelihood.

Note that, when you are using the Bayesian approach to audit sampling, it is not
required to plan a specific sample size in advance [@Derks2022]. That is because
in Bayesian inference, the posterior distribution after seeing each item is used
as the prior distribution for the next item. That means that you can simply
start sampling and monitor the evidence in the data over time. However, to get
an idea of how many samples are required to reduce the sampling risk to an
level, planning a sample using a Bayesian approach can still be good practice.

## Required Information

First, planning a minimum sample requires knowledge of the conditions that lead 
to acceptance or rejection of the population (i.e., the sampling objectives).
Typically, sampling objectives can be classified into one or both of the
following:

- **Hypothesis testing**: The goal of the sample is to obtain evidence for or
  against the claim that the misstatement in the population is lower than a
  given value (i.e., the performance materiality). Note that if this sampling
  objective is not specified, the performance materiality can be set to 1.
- **Estimation**: The goal of the sample is to obtain an accurate estimate of
  the misstatement in the population (with a minimum precision). Note that if
  this sampling objective is not specified, the minimum precision can be set to
  1.

Second, it is advised to specify the expected (or tolerable) misstatements in
the sample. The expected misstatements are the misstatements that you allow in
the sample, while still retaining the desired amount of assurance about the 
population. It is strongly recommended to set the value for the expected
misstatements in the sample conservatively to minimize the chance of the
observed misstatements in the sample exceeding the expected misstatements, which
would imply that insufficient work has been done in the end.

Finally, next to determining the sampling objective(s) and the expected
misstatements, it is important to determine the statistical distribution linking
the sample outcomes to the population misstatement. This distribution is called
the likelihood (i.e., `poisson`, `binomial`, or `hypergeometric`). All three
aforementioned likelihoods are commonly used in an audit sampling context,
however, `poisson` is the default likelihood in **jfa** because it is the most
conservative of the three. In the subsections below, we elaborate on the three
standard likelihoods for audit sampling and demonstrate how they can be used
to obtain a minimum sample size.

In **jfa**, determining an appropriate sample size is achieved via the
`planning()` function.

![When the sampling objectives, the expected misstatements and the likelihood are set, there exists only one sample size that minimizes the amount of audit effort. Image available under a [CC-BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/legalcode) license.](img/book_puzzle.png){fig-align="center" width=75%}

## The Hypergeometric Likelihood

The hypergeometric distribution is a discrete probability distribution that is
commonly used to model the number of events occurring in a fixed number of
trials when the population size is known. It assumes that samples are drawn
from the population without replacement, and is therefore the likelihood that
most closely resembles the audit practice. For our purpose, we can use the
hypergeometric distribution as a likelihood to model the number of misstatements
that are expected to be found in the sample.

The probability mass function (PMF) of the hypergeometric distribution is given
by:

\begin{equation}
  p(X = k) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}},
\end{equation}

where $k$ is the number of misstatements in the sample, $n$ is the sample size,
$N$ is the population size and $K$ is the total number of misstatements assumed
in the population. The assumed misstatements $K$ is a whole number, that is, a
linear extrapolation of the maximum tolerable misstatement rate (i.e., the
performance materiality) $\theta_{max}$ to the total population of size $N$:

\begin{equation}
  K = \lceil \theta_{max} N \rceil.
\end{equation}

::: {.callout-note}
$\lceil...\rceil$ is the ceiling function, which means that $\lceil1.2\rceil = 2$.
:::

Let's consider how to use the hypergeometric likelihood to calculate the minimum
sample size needed to reduce the sampling risk to an appropriately low level.

### Classical planning

In classical planning using the hypergeometric likelihood, the following
statistical model is specified:

\begin{equation}
  k \sim \text{Hypergeometric}(n, N, K)
\end{equation}

Given the performance materiality $\theta_{max}$, we can compute $K$ and solve
for the minimum sample size $n$ needed to reduce the sampling risk to an
appropriately low level. This sample size is also dependent on the number of
misstatements that the auditor expects, or tolerates, in the sample.

#### No Expected Misstatements

If the auditor does not expect any misstatements in the sample, they can set
$k = 0$, which consequently determines how the sample size can be calculated.
For example, if we want to achieve an assurance level of 95% ($\alpha = 0.05$)
for a performance materiality of $\theta_{max} = 0.03$ in a population of
$N = 1000$ items, then $K = \lceil 0.03 \cdot 1000 \rceil = 30$ and the minimum
sample size under the assumption of no expected misstatements in the sample is
$n = 94$.

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "hypergeometric", N.units = 1000)
plan
```

The sample size of 94 can be confirmed by checking that 94 is the minimum
integer that results in less than 5% probability of finding 0 misstatements,
given the assumption that the population misstatement is truly 3%. The
`dhyper()` function calculates the probability of observing $k$ missatements in
a sample of $n$ items given the assumed hypergeometric distribution with $N$
items and $K$ assumed misstatements in the population. By calculating this
probability for $n = 93$, we can show that this sample size is insufficient as
the relevant probability is higher than the sampling risk $\alpha$.

```{r}
K <- ceiling(0.03 * 1000)
dhyper(x = 0, m = K, n = 1000 - K, k = 93) < 0.05
```

However, for $n = 94$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
dhyper(x = 0, m = K, n = 1000 - K, k = 94) < 0.05
```

We can make this sample size visually intuitive by showing the
hypergeometric($k$ | 94, 1000, 30) distribution and highlighting the probability
for $k = 0$. This probability is lower than the required sampling risk
$\alpha = 0.05$.

```{r}
plot(plan)
```

::: {.callout-tip}
## Additional arguments to `planning()`
The `planning()` function has two additional arguments that are not shown in
the call above: `by` and `max`. The argument `by` sets the increment between
possible sample sizes for consideration. For example, `by = 5` considers only
samples of size 10, 20, 30, etc:

```{r}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "hypergeometric", N.units = 1000, by = 10)
```

The argument `max` sets the sample size at which the algorithm terminates. This
can be used to avoid too many iterations of the algorithm at very low values of
the performance materiality. For instance, `max = 50` throws an error if more
than 100 samples are required.

```{r error=TRUE}
planning(materiality = 0.03, expected = 0, conf.level = 0.95,
         likelihood = "hypergeometric", N.units = 1000, max = 50)
```
:::

#### Expected Misstatements

If the auditor expects misstatements in the sample, they can set $k$ to any
integer value, which consequently determines how the sample size can be
calculated. As another example, if we want to achieve an assurance level of 95%
($\alpha = 0.05$) for a performance materiality of $\theta_{max} = 0.03$ in a
population of $N = 1000$ items, then the required sample size under the
assumption of one expected misstatement in the sample is $n = 147$.

```{r}
plan <- planning(materiality = 0.03, expected = 1, conf.level = 0.95,
                 likelihood = "hypergeometric", N.units = 1000)
plan
```

Once again, the sample size of 147 can be confirmed by checking that 147 is the
minimum integer that results in less than 5% probability of finding 0 or 1
misstatements, given the assumption that that the population misstatement is
truly 3%. By calculating this probability for $n = 146$, we can show that this
sample size is insufficient as the relevant probability is higher than the
sampling risk $\alpha$.

```{r}
sum(dhyper(x = 0:1, m = K, n = 1000 - K, k = 146)) < 0.05
```

However, for $n = 147$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
sum(dhyper(x = 0:1, m = K, n = 1000 - K, k = 147)) < 0.05
```

Like before, we can make this sample size visually intuitive by showing the
hypergeometric($k$ | 147, 1000, 30) distribution and highlighting the
probabilities for $k = 0$ and $k = 1$. The sum of these probabilities is lower
than the required sampling risk $\alpha = 0.05$.

```{r}
plot(plan)
```

### Bayesian Planning

Performing Bayesian planning with the hypergeometric likelihood [@Dyer1993]
requires that you specify a prior distribution for the total misstatements $K$.
Practically, this means that you should provide an input for the `prior`
argument in the `planning()` function.

Setting `prior = TRUE` performs Bayesian planning using a [default prior](https://koenderks.github.io/jfa/articles/creating-prior.html#default-priors-method-default)
conjugate to the specified `likelihood` (i.e., a beta-binomial prior). Because
this is a Bayesian analysis, the following statistical model is specified:

\begin{align}
  k &\sim \text{Hypergeometric}(n, N, K) \\
  K &\sim \text{Beta-binomial}(N, \alpha, \beta)
\end{align}

::: {.callout-note}
The beta-binomial prior distribution is the conjugate prior for to the
hypergeometric likelihood (see this [list](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)
of conjugate priors), which means that the posterior distribution of $K$ can be
determined analytically. For example, if the prior distribution for $K$ is:

\begin{equation}
  K \sim \text{Beta-binomial}(N, \alpha, \beta) \,\,\,\,\,\,\,\,\,\, K = 0, \ldots, N
\end{equation}

and the auditor has observed a sample of $n$ items containing $k$ misstatements,
then the posterior distribution for $K$ is:

\begin{equation}
  K \sim \text{Beta-binomial}(N - n, \alpha + k, \beta + k - n) \,\,\,\,\,\,\,\,\,\, K = k, k + 1, \ldots, N - n + k.
\end{equation}
:::

#### No Expected Misstatements

Planning for no expected misstatements in the sample can be done by setting the
value for the `expected` argument to zero. If we want to achieve an assurance
level of 95% ($\alpha = 0.05$) for a performance materiality of
$\theta_{max} = 0.1$ in a population of $N = 20$ items, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 15$. The command below uses a default beta-binomial($N$, 1, 1) prior
distribution to plan this sample, since `planning()` is given the hypergeometric
likelihood.

```{r}
plan <- planning(materiality = 0.1, expected = 0, conf.level = 0.95,
                 likelihood = "hypergeometric", N.units = 20,
                 prior = TRUE)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

You can inspect how the prior distribution compares to the expected posterior
distribution by using the `plot()` function. The expected posterior distribution
is the posterior distribution that would occur if you actually observed the
planned sample containing the expected misstatements. Note that the posterior
distribution is only defined in the range [$k$; $N - n + k$], since a part of
the population has already been seen.

```{r}
plot(plan)
```

#### Expected Misstatements

Planning for expected misstatements in the sample can be done by setting the
value for the `expected` argument to a different value than zero. For example,
the command below calculates the minimum sample size to achieve an assurance
level of 95% ($\alpha = 0.05$) for a performance materiality of
$\theta_{max} = 0.1$ in a population of $N = 50$ items, given one expected
misstatement in the sample. This sample size is $n = 32$.

```{r}
plan <- planning(materiality = 0.1, expected = 1, conf.level = 0.95,
                 likelihood = "hypergeometric", N.units = 50,
                 prior = TRUE)
plan
```

Like before, you can inspect how the prior distribution compares to the expected
posterior distribution by using the `plot()` function.

```{r}
plot(plan)
```

## The Binomial Likelihood

The binomial distribution is a discrete probability distribution that is
commonly used to model the number of events occurring in a fixed number of
trials. It is similar to the hypergeometric distribution, however, it assumes
that samples are drawn from the population with replacement. For our purpose, we
can use the binomial distribution as a likelihood to model the number of
misstatements that are expected to be found in the sample. 

::: {.callout-note}
In audit sampling, the binomial likelihood is often used to approximate the
hypergeometric likelihood since it is easier to work with (i.e., it only has two
parameters: $\theta$ and $n$, while the hypergeometric has three: $n$, $N$, and
$K$). However, the binomial likelihood is more conservative than the
hypergeometric likelihood, meaning that resulting sample sizes will be higher.
:::

The probability mass function (PMF) of the binomial distribution is given by:

\begin{equation}
  p(k; n, \theta) = \binom{n}{k} \theta^{k} (1-\theta)^{n - k},
\end{equation}

where $k$ is the number of misstatements in the sample, $n$ is the sample size
and $\theta$ is the probability of misstatement in the population. Let's
consider how to use the binomial likelihood to calculate the minimum sample size
needed to reduce the sampling risk to an appropriately low level.

### Classical Planning

In classical planning using the binomial likelihood, the following statistical
model is specified:

\begin{equation}
  k \sim \text{Binomial}(n, \theta_{max})
\end{equation}

#### No Expected Misstatements

If the auditor does not expect any misstatements in the sample, they can set
$k = 0$, which consequently determines how the sample size can be calculated.
Given a performance materiality $\theta_{max}$, we can solve for the minimum
sample size $n$ needed to reduce the sampling risk to an appropriately low
level. A useful trick to utilize is that, if we do not expect any misstatements
in the sample, the formula for the minimum required sample size reduces to:

\begin{equation}
  n = \lceil\frac{\ln(\alpha)}{\ln(1 - \theta_{max})}\rceil.
\end{equation}

For example, if we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 99$.

```{r}
ceiling(log(1 - 0.95) / log(1 - 0.03))
```

In **jfa**, this sample size can be replicated using the following code:

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "binomial")
plan
```

The sample size of 99 can be confirmed by checking that 99 is the minimum
integer that results in less than 5% probability of finding 0 misstatements,
given the assumption that the population misstatement is truly 3%. The
`dbinom()` function calculates the probability of observing $k$ missatements in
a sample of $n$ items given an assumed misstatement probability $\theta_{max}$.
By calculating this probability for $n = 98$, we can show that this
sample size is insufficient as the relevant probability is higher than the
sampling risk $\alpha$.

```{r}
dbinom(x = 0, size = 98, prob = 0.03) < 0.05
```

However, for $n = 99$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
dbinom(x = 0, size = 99, prob = 0.03) < 0.05
```

We can make this sample size visually intuitive by showing the binomial($k$ |
99, 0.03) distribution and highlighting the probability for $k = 0$. This
probability is lower than the required sampling risk $\alpha = 0.05$.

```{r}
plot(plan)
```

#### Expected Misstatementss

However, if the number of expected misstatements in the sample is non-zero,
it becomes more difficult to solve the formula for $n$. Hence, they will need to
set $k$ to a different integer value, which consequently determines how the
sample size is calculated. Here, we can iteratively try every value of $n$ and
return the smallest integer that satisfies the sampling objectives.

In **jfa**, this can be done by adjusting the `expected` argument in the
`planning()` function. For example, if we want to achieve an assurance level of
95% ($\alpha = 0.05$) for a performance materiality of $\theta_{max} = 0.03$,
then the required sample size under the assumption of one expected misstatement
in the sample is $n = 157$.

```{r}
plan <- planning(materiality = 0.03, expected = 1, conf.level = 0.95,
                 likelihood = "binomial")
```

Once again, the sample size of 157 can be confirmed by checking that 157 is the
minimum integer that results in less than 5% probability of finding 0 or 1
misstatements, given the assumption that the population misstatement is truly
3%. By calculating this probability for $n = 156$, we can show that this
sample size is insufficient as the relevant probability is higher than the
sampling risk $\alpha$.

```{r}
sum(dbinom(x = 0:1, size = 156, prob = 0.03)) < 0.05
```

However, for $n = 157$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
sum(dbinom(x = 0:1, size = 157, prob = 0.03)) < 0.05
```

Like before, we can make this sample size visually intuitive by showing the
binomial($k$ | 157, 0.03) distribution and highlighting the probabilities for
$k = 0$ and $k = 1$. The sum of these probabilities is lower than the
required sampling risk $\alpha = 0.05$.

```{r}
plot(plan)
```

#### Expected Misstatement Rate

When the expected misstatement rate in the sample $\theta_{exp}$ is assessed,
the value for $k$ can be determined as $k = n\theta_{exp}$, which consequently
determines how the sample size can be calculated.

To account for the fact that $k$ can have non-integer values in this case, we
can use a well-known similarity between the binomial distribution and the beta
distribution to plan the sample size. The upper bound for any binomial($k$; $n$,
$\theta$) distributed variable can also be obtained via percentiles of the
beta($1 + k$, $n - k$) distribution. 

For example, the upper bound for a sample of $n = 10$ items containing $k = 2$
misstatements, when calculated via the traditional `binom.test()` is:

```{r}
ub_binom <- binom.test(x = 2, n = 10, p = 0.03, conf.level = 0.95,
                       alternative = "less")$conf.int[2]
ub_binom
```

When calculated via the beta relationship, the upper bound is:

```{r}
ub_beta <- qbeta(p = 0.95, shape1 = 1 + 2, shape2 = 10 - 2)
ub_beta
```

It can be validated that the two approaches result in the same upper bound via:

```{r}
ub_binom == ub_beta
```

This relationship between the binomial likelihood and the beta distribution is
deliberately **not** used in **jfa**. That is because, in the case of the
binomial distribution, the auditing standards round the tolerable misstatements
upwards to a whole number. For example, if we try to call the `planning()`
function with the argument `expected = 1.5`, **jfa** will internally convert
this to `expected = 2` and base the sample size on this in order to stay
compliant with @AICPA-A. The resulting sample size is $n = 208$ in this case.

```{r}
planning(materiality = 0.03, expected = 1.5, conf.level = 0.95,
         likelihood = "binomial")
```

### Bayesian Planning

Performing Bayesian planning using the binomial likelihood requires that you
specify a prior distribution for the parameter $\theta$. Practically, this means
that you should provide an input for the `prior` argument in the `planning()`
function.

Setting `prior = TRUE` performs Bayesian planning using a
[default prior](https://koenderks.github.io/jfa/articles/creating-prior.html#default-priors-method-default)
conjugate to the specified `likelihood` (i.e., a beta prior). Because this is a
Bayesian analysis, the following statistical model is specified:

\begin{align}
  k &\sim \text{Binomial}(n, \theta) \\
  \theta &\sim \text{Beta}(\alpha, \beta)
\end{align}

::: {.callout-note}
The beta prior distribution is the conjugate prior for the binomial likelihood
(see this [list](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)
of conjugate priors), which means that the posterior distribution of $\theta$
can be determined analytically. For example, if the prior distribution for
$\theta$ is:

\begin{equation}
  \theta \sim \text{Beta}(\alpha, \beta) \,\,\,\,\,\,\,\,\,\, \theta \in [0, 1]
\end{equation}

and the auditor has observed a sample of $n$ items containing $k$ misstatements,
then the posterior distribution for $\theta$ is:

\begin{equation}
  \theta \sim \text{Beta}(\alpha + k, \beta + n - k) \,\,\,\,\,\,\,\,\,\, \theta \in [0, 1].
\end{equation}
:::

For example, the command below uses a default beta($\alpha=1$, $\beta=1$) prior
distribution to plan the sample, since `planning()` is given the binomial
likelihood. If we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 98$.

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "binomial", prior = TRUE)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

You can inspect how the prior distribution compares to the expected
posterior distribution by using the `plot()` function. The expected posterior
distribution is the posterior distribution that would occur if you actually
observed the planned sample containing the expected misstatements.

```{r}
plot(plan)
```

The input for the `prior` argument can also be an object created by the
`auditPrior` function. If `planning()` receives a prior for which there is no
conjugate likelihood available, it will numerically derive the posterior
distribution. For example, the command below uses a Normal(0, 0.05) prior
distribution to plan the sample using the binomial likelihood. Because this is a
Bayesian analysis, the following statistical model is specified:

\begin{align}
  k &\sim \text{Binomial}(n, \theta) \\
  \theta &\sim \text{Normal}(\mu = 0, \sigma = 0.05)
\end{align}

```{r}
prior <- auditPrior(method = "param", likelihood = "normal",
                    alpha = 0, beta = 0.05)

plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson", prior = prior)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

The resulting sample size under this prior is $n = 90$, a reduction of 8 samples
when compared to the default beta(1, 1) prior distribution.

```{r}
plot(plan)
```

## The Poisson Likelihood

The Poisson distribution is a discrete probability distribution that is commonly
used to model the number of events occurring in a fixed time or space. We can
use the Poisson distribution as a likelihood to model the number of
misstatements that are expected to be found in the sample.

::: {.callout-note}
In audit sampling, the Poisson likelihood is often used to approximate the
binomial likelihood since it is easier to work with (i.e., it only has one
parameter: $\lambda$, while the binomial has two parameters: $\theta$ and $n$).
However, the Poisson likelihood is more conservative than the binomial
likelihood, meaning that resulting sample sizes will be higher.
:::

The probability mass function (PMF) of the Poisson distribution is given by:

\begin{equation}
  p(k; \lambda) = \frac{\lambda^k e^{-\lambda}}{k!},
\end{equation}

where $k$ is the number of misstatements in the sample, and $\lambda$ is the
average number of misstatements expected in the sample. The average number of
misstatements is related to the misstatement rate in the population, denoted by
$\theta$, and the sample size, $n$, by the following equation:

\begin{equation}
  \lambda = n \theta.
\end{equation}

Let's consider how to use the Poisson likelihood to calculate the minimum sample
size needed to reduce the sampling risk to an appropriately low level.

### Classical planning

In classical planning using the Poisson likelihood, the following statistical
model  is specified:

\begin{equation}
  k \sim \text{Poisson}(n \theta_{max})
\end{equation}

#### No Expected Misstatements

Given the performance materiality $\theta_{max}$ and the Poisson likelihood, we
can solve for the minimum sample size $n$ needed to reduce the sampling risk to
an appropriately low level. A useful trick to utilize is that, if we do not
expect any misstatements in the sample, the formula for the required sample size
reduces to:

\begin{equation}
  n = \lceil-\frac{\ln(\alpha)}{\theta_{max}}\rceil.
\end{equation}

For example, if we want to achieve an assurance level of 95% ($\alpha = 0.05$)
for a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 100$.

```{r}
ceiling(-log(1 - 0.95) / 0.03)
```

In **jfa**, this sample size can be replicated using the following code:

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson")
```

The sample size of 100 can be confirmed by checking that 100 is the minimum
integer that results in less than 5% probability of finding 0 misstatements,
given the assumption that the population misstatement is truly 3%. The `dpois()`
function calculates the probability of observing $k$ missatements in a sample of
$n$ items given an assumed misstatement probability $\theta_{max}$. By
calculating this probability for $n = 99$, we can show that this sample size is
insufficient as the relevant probability is higher than the sampling risk
$\alpha$.

```{r}
dpois(x = 0, lambda = 99 * 0.03) < 0.05
```

However, for $n = 100$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
dpois(x = 0, lambda = 100 * 0.03) < 0.05
```

We can make this visually intuitive by showing the Poisson($k$ | 100 * 0.03)
distribution and highlighting the probability for $k = 0$. This probability is
lower than the required sampling risk $\alpha = 0.05$.

```{r}
plot(plan)
```

#### Expected Misstatements

However, if the number of expected misstatements in the sample is non-zero,
it becomes more difficult to solve the formula for $n$ algebraically. Hence,
they will need to set $k$ to a different integer value. Next, we can iteratively
try every value of $n$ and return the smallest integer that satisfies the
sampling objectives.

For example, if we want to achieve an assurance level of 95% ($\alpha = 0.05$)
for a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of one expected misstatement in the sample is
$n = 159$.

```{r}
plan <- planning(materiality = 0.03, expected = 1, conf.level = 0.95,
                 likelihood = "poisson")
```

Once again, the sample size of 159 can be confirmed by checking that 159 is the
minimum integer that results in less than 5% probability of finding 0 or 1
misstatements, given the assumption that the population misstatement is truly
3%. By calculating this probability for $n = 158$, we can show that this sample
size is insufficient as the relevant probability is higher than the sampling
risk $\alpha$.

```{r}
sum(dpois(x = 0:1, lambda = 158 * 0.03)) < 0.05
```

However, for $n = 159$ the relevant probability is lower than the sampling risk
$\alpha$ and thus the sample size is considered to be sufficient.

```{r}
sum(dpois(x = 0:1, lambda = 159 * 0.03)) < 0.05
```

Like before, we can make this visually intuitive by showing the Poisson($k$ |
159 $\times$ 0.03) distribution and highlighting the probabilities for $k = 0$
and $k = 1$. The sum of these probabilities is lower than the required sampling
risk $\alpha = 0.05$.

```{r echo = FALSE}
plot(plan)
```

#### Expected Misstatement Rate

When the expected misstatements in the sample $\theta_{exp}$ is assessed, the
value for $k$ can be determined as $k = n\theta_{exp}$, which consequently
determines how the sample size can be calculated.

To account for the fact that $k$ can have non-integer values in this case, we
use a well-known similarity between the Poisson distribution and the gamma
distribution to plan the sample size. The upper bound for any Poisson($k$;
$n \theta$) distributed variable can also be obtained via percentiles of the
gamma($1 + k$, $n$) distribution. 

For example, the upper bound for a sample of $n = 10$ items containing $k = 2$
misstatements, when calculated via the traditional `poisson.test()` is:

```{r}
ub_pois <- poisson.test(x = 2, T = 10, r = 0.03, conf.level = 0.95,
                        alternative = "less")$conf.int[2]
ub_pois
```

When calculated via the relationship with the gamma distribution, the upper
bound is:

```{r}
ub_gamma <- qgamma(p = 0.95, shape = 1 + 2, rate = 10)
ub_gamma
```

It can be validated that the two approaches result in the same upper bound via:

```{r}
ub_pois == ub_gamma
```

This relationship between the Poisson likelihood and the gamma distribution is
used under the hood in **jfa**. For example, if we want to achieve an assurance
level of 95% ($\alpha = 0.05$) for a performance materiality of
$\theta_{max} = 0.03$, then the required sample size under the assumption of 1.5
expected misstatements in the sample is $n = 185$.

```{r}
planning(materiality = 0.03, expected = 1.5, conf.level = 0.95,
         likelihood = "poisson")
```

The sample size of 185 can be confirmed by checking that 185 is the minimum
integer that results in less than 5% probability of finding a misstatement rate
in the population equal to, or higher than, 3%. By calculating this probability
for $n = 184$, we can show that this sample size is insufficient as the relevant
upper bound is higher than the performance materiality $\theta_{max}$.

```{r}
qgamma(p = 0.95, shape = 1 + 1.5, rate = 184) < 0.03
```

However, for $n = 185$ the relevant upper bound is lower than the performance
materiality $\theta_{max}$ and thus the sample size is sufficient.

```{r}
qgamma(p = 0.95, shape = 1 + 1.5, rate = 185) < 0.03
```

### Bayesian Planning

Performing Bayesian planning with the Poisson likelihood requires that you
specify a prior distribution for the parameter $\theta$. Practically, this means
that you should provide an input for the `prior` argument in the `planning()`
function.

Setting `prior = TRUE` performs Bayesian planning using a [default prior](https://koenderks.github.io/jfa/articles/creating-prior.html#default-priors-method-default)
conjugate to the specified `likelihood` (i.e., a gamma prior). Because this is a
Bayesian analysis, the following statistical model is specified:

\begin{align}
  k &\sim \text{Poisson}(n\theta) \\
  \theta &\sim \text{Gamma}(\alpha, \beta)
\end{align}

::: {.callout-note}
The gamma prior distribution is the conjugate prior for the Poisson likelihood
(see this [list](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)
of conjugate priors), which means that the posterior distribution of $\theta$
can be determined analytically. For example, if the prior distribution for
$\theta$ is:

\begin{equation}
  \theta \sim \text{Gamma}(\alpha, \beta) \,\,\,\,\,\,\,\,\,\, \theta \in [0, \infty]
\end{equation}

and the auditor has observed a sample of $n$ items containing $k$ misstatements,
then the posterior distribution for $\theta$ is:

\begin{equation}
  \theta \sim \text{Gamma}(\alpha + k, \beta + n) \,\,\,\,\,\,\,\,\,\, \theta \in [0, \infty].
\end{equation}
:::

For example, the command below uses a default gamma($\alpha=1$, $\beta=1$) prior
distribution to plan the sample, since `planning()` is given the Poisson
likelihood. If we want to achieve an assurance level of 95% ($\alpha=0.05$) for
a performance materiality of $\theta_{max} = 0.03$, then the required sample
size under the assumption of zero expected misstatements in the sample is
$n = 99$.

```{r}
plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson", prior = TRUE)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

You can inspect how the prior distribution compares to the expected
posterior distribution by using the `plot()` function. The expected posterior
distribution is the posterior distribution that would occur if you actually
observed the planned sample containing the expected misstatements.

```{r}
plot(plan)
```

The input for the `prior` argument can also be an object created by the
`auditPrior` function. If `planning()` receives a prior for which there is no
conjugate likelihood available, it will numerically derive the posterior
distribution. For example, the command below uses a Normal(0, 0.05) prior
distribution to plan the sample using the Poisson likelihood. Concretely, this
means that the following statistical model is specified:

\begin{align}
  k &\sim \text{Poisson}(n\theta) \\
  \theta &\sim \text{Normal}(\mu = 0, \sigma = 0.05)
\end{align}

```{r}
prior <- auditPrior(method = "param", likelihood = "normal",
                    alpha = 0, beta = 0.05)

plan <- planning(materiality = 0.03, expected = 0, conf.level = 0.95,
                 likelihood = "poisson", prior = prior)
```

The `summary()` function can be used to obatain relevant information about the
planning.

```{r}
summary(plan)
```

The resulting sample size under this prior is $n = 91$, a reduction of 8 samples
when compared to the default gamma(1, 1) prior.

```{r}
plot(plan)
```

## Prior Distributions

The `auditPrior()` function is used to specify a prior distribution for audit
sampling. Below is an enumeration of the several ways that a prior distribution
can be constructed using this function.

### Default Prior

The default prior distributions are created using `method = 'default'`.
**jfa**'s default priors satisfy two criteria: 1) they contain relatively little
information about the population misstatement and 2) they are proper (i.e., they
integrate to 1). The default priors in **jfa** are:

* `likelihood = 'poisson'`: gamma($\alpha$ = 1, $\beta$ = 1)
* `likelihood = 'binomial'`: beta($\alpha$ = 1, $\beta$ = 1)
* `likelihood = 'hypergeometric'`: beta-binomial(N, $\alpha$ = 1, $\beta$ = 1)
* `likelihood = 'normal'`: normal($\mu$ = 0, $\sigma$ = 1000)
* `likelihood = 'uniform'`: uniform(min = 0, max = 1) 
* `likelihood = 'cauchy'`: Cauchy($x_0$ = 0, $\gamma$ = 1000)
* `likelihood = 't'`: Student-t(df = 1)
* `likelihood = 'chisq'`: chi-squared(df = 1)
* `likelihood = 'exponential'`: exponential($\lambda$ = 1)

```{r}
prior <- auditPrior(method = "default", likelihood = "binomial")
summary(prior)
```

All prior distributions can be visually inspected via the `plot()` function.

```{r}
plot(prior)
```

Furthermore, the `predict()` function produces the predictions of the prior
distribution on the data level for a sample of `n` items. For example, the
command below requests the prediction of the default beta(1, 1) prior for a
hypothetical sample of 6 items.

```{r}
predict(prior, n = 6)
```

The predictions of the prior distribution can be visualized using the `plot()`
function.

```{r}
plot(predict(prior, n = 10))
```

### Parametric Prior

You can manually specify the parameters of the prior distribution with
`method = 'param'` and the `alpha` and `beta` arguments, which correspond to the
first and (optionally) second parameter of the prior as described above. For
example, the commands below create a beta(2, 10) prior distribution, a
normal(0.025, 0.05) prior distribution and a Student-t(0.01) prior distribution.

```{r}
auditPrior(method = "param", likelihood = "binomial", alpha = 2, beta = 10)
auditPrior(method = "param", likelihood = "normal", alpha = 0.025, beta = 0.05)
auditPrior(method = "param", likelihood = "t", alpha = 0.01)
```

### Improper Prior

You can construct an improper prior distribution with classical properties using
`method = 'strict'`. The posterior distribution of from this prior yields the
same results as the classical methodology with respect to sample sizes and upper
limits, but is only proper once a single non-misstated unit is present in the 
sample [@Derks2022b]. For example, the command below creates an improper
beta(1, 0) prior distribution.

::: {.callout-note appearance="simple"}
This method requires the `poisson`, `binomial` or `hypergeometric` likelihood.
:::

```{r}
auditPrior(method = "strict", likelihood = "binomial")
```

### Impartial Prior

You can incorporate the assumption that tolerable misstatement is equally likely
as intolerable misstatement [@Derks2022b] using `method = 'impartial'`. For
example, the command below creates an impartial beta prior distribution for a
performance materiality of 5 percent.

::: {.callout-note appearance="simple"}
This method requires that you specify a value for the `materiality`.
:::

```{r}
auditPrior(method = "impartial", likelihood = "binomial",
           materiality = 0.05)
```

### Probability of Tolerable Misstatement

You can manually assign prior probabilities to the hypothesis of tolerable 
misstatement and the hypotheses of intolerable misstatement [@Derks2021] with
`method = 'hyp'` in combination with `p.hmin`. For example, the command below
incorporates the information that the hypothesis of tolerable misstatement  has
a probability of 60% into a beta prior distribution.

::: {.callout-note appearance="simple"}
This method requires that you specify a value for the `materiality`.
:::

```{r}
auditPrior(method = "hyp", likelihood = "binomial",
           materiality = 0.05, p.hmin = 0.6)
```

### Audit Risk Model

You can translate risk assessments from the Audit Risk Model (inherent risk and
internal control risk) into a prior distribution [@Derks2021] using
`method = 'arm'` in combination with the `ir` and `cr` arguments. For example,
the command below incorporates the information that the inherent risk is equal
to 90% and internal control risk is equal to 60% into a beta prior distribution.

::: {.callout-note appearance="simple"}
This method requires the `poisson`, `binomial` or `hypergeometric` likelihood.
:::

```{r}
auditPrior(method = "arm", likelihood = "binomial",
           materiality = 0.05, ir = 0.9, cr = 0.6)
```

### Bayesian Risk Assessment Model

You can incorporate information about the mode and the upper bound of the prior
distribution using `method = 'bram'`. For example, the code below incorporates
the information that the mode of the prior distribution is 1% and the upper
bound is 60% into a beta prior distribution.

::: {.callout-note appearance="simple"}
This method requires the `poisson`, `binomial` or `hypergeometric` likelihood.
:::

```{r}
auditPrior(method = "bram", likelihood = "binomial",
           materiality = 0.05, expected = 0.01, ub = 0.6)
```

### Earlier Sample

You can incorporate information from an earlier sample into the prior
distribution [@Derks2021] using `method = 'sample'` in combination with `x` and
`n`. For example, the command below incorporates the information from an earlier
sample of 30 items in which 0 misstatements were found into a beta prior
distribution.

::: {.callout-note appearance="simple"}
This method requires the `poisson`, `binomial` or `hypergeometric` likelihood.
:::

```{r}
auditPrior(method = "sample", likelihood = "binomial",
           x = 0, n = 30)
```

### Weighted Earlier Sample

You can incorporate information from last years results, weighted by a factor
[@Derks2021], into the prior distribution using `method = 'factor'` in
combination with `x` and `n`. For example, the command below incorporates the
information from a last years results (a sample of 58 items in which 0
misstatements were found), weighted by a factor 0.7, into a beta prior
distribution.

::: {.callout-note appearance="simple"}
This method requires the `poisson`, `binomial` or `hypergeometric` likelihood.
:::

```{r}
auditPrior(method = "factor", likelihood = "binomial",
           x = 0, n = 58, factor = 0.7)
```

### Nonparametric Prior

You can base the prior on samples of the prior distribution using 
`method = 'nonparam'` in combination with `samples`. For example, the command
below creates a prior on 1000 samples of a beta(1, 10) distribution.

::: {.callout-note appearance="simple"}
The `likelihood` argument is not required and will be ignored in this method.
:::

```{r}
auditPrior(method = "nonparam", samples = stats::rbeta(1000, 1, 10))
```

## Practical Examples

This section contains practical examples of how to conduct the planning of
statistical audit samples and demonstrates how to set up a prior distribution
based on various types of relevant audit information.

### Audit Risk Model

In our first example, an auditor is performing tests of details on a population
of the auditee. For instance, let's say an auditor is performing an audit on a
company's accounts payable transactions. The company has a total of $N$ = 1000
accounts payable transactions for the year. Rather than testing all 1000
transactions, the auditor can choose to test a sample of the transactions. The
performance materiality for the payable transactions account is set to
$\theta_{max}$ = 3%, and the audit risk is set to $\alpha = 0.05$, or 5%. Based
on the results of last years audit, where the most likely estimate of the
misstatement was 1%, the auditor wants to tolerate 1% misstatements in the
sample before giving an unqualified opinion on the population.

```{r}
ar          <- 0.05 # Audit risk
materiality <- 0.03 # Performance materiality
expected    <- 0.01 # Tolerable deviation rate
```

Before tests of details, the auditor has assessed risk of material
misstatement via the audit risk model. In this example, the auditor has assessed
the effectiveness of the company's internal controls, such as its segregation of
duties and its risk management processes, and has determined that they are
sufficient to prevent or detect material misstatements. Because the internal
control systems were effective, the auditor assesses the control risk as medium.
The auditor's firm defines the risk categories low, medium, and high
respectively as 50%, 60%, and 100%. According to the Audit Risk Model, the
detection risk can be calculated as a function of the audit risk, the inherent
risk and the control risk.

```{r}
ir <- 1              # Inherent risk
cr <- 0.6            # Control risk
dr <- ar / (ir * cr) # Detection risk
dr
```

By using the detection risk of 8.33% as the sampling risk for this population,
the auditor can plan for a sample while taking into account the risk-reducing
information. The required minimum sample size is 174 in this case.

```{r}
planning(materiality = 0.03, expected = expected, conf.level = 1 - dr)
```

The example above is a frequentist one. However, the auditor is free to apply a
Bayesian philosophy in planning the sample. For example, the risk assessments
from the ARM can be incorporated into a prior distribution. This can be done
using `method = "arm"` in the `auditPrior()` function, which takes the values of
the inherent risk probability `ir` and the control risk probability `cr`. Hence,
the prior distribution in this example can be constructed using the following
command:

```{r}
prior <- auditPrior(method = "arm", materiality = 0.03, expected = expected,
                    ir = ir, cr = cr)
```

The `summary()` function can be used to obtain relevant information about the
prior distribution.

```{r}
summary(prior)
```

Furthermore, the prior distribution can be visualized with a call to the
`plot()` function.

```{r}
plot(prior)
```

By using the prior distribution to incorporate the assessments of the inherent
risk and the control risk, the auditor can plan a sample while taking into
account the risk-reducing information. The required minimum sample size
is also 174 in this case.

```{r}
planning(materiality = 0.03, expected = expected, conf.level = 1 - ar,
         prior = prior)
```

### Benchmark Analysis

The auditor may incorporate information obtained through analytical procedures
[@Derks2021], such as a benchmark analysis, into the prior distribution for
$\theta$. While we have previously discussed methods for constructing a prior
distribution based on existing knowledge, there is no set procedure for
incorporating information obtained through analytical procedures, as these
procedures can vary significantly depending on the type of information being
incorporated into the prior distribution. Therefore, it is important to
thoroughly substantiate the data and assumptions used in this approach and to
carefully consider how these assumptions are incorporated into the prior
distribution.

One way to construct a prior distribution on the basis of data is through the
use of regression models, such as benchmarking the relationship between sales
and costs of sales within the auditee's specific industry sector. The **jfa**
package includes a data set `benchmark` that can be used for this example.

```{r}
data(benchmark)
head(benchmark)
```

The auditee's the sum of the sales is $298,112,312 and the sum of the booked
costs of sales is $223,994,405, respectively. This is indicated by a blue dot in
the figure below, which visualizes the industry sales versus the cost of sales.

```{r}
C_real <- 223994405
```

```{r echo = FALSE, fig.width = 7, fig.height = 6, fig.align = "center"}
breaks <- pretty(c(benchmark$sales, benchmark$costofsales))
labels <- paste0("$", format(breaks / 1000000, scientific = FALSE), "M")
p <- ggplot(data = benchmark, mapping = aes(x = sales, y = costofsales)) +
  geom_point(shape = 21, fill = "darkgray", size = 2) +
  geom_point(data = data.frame(x = 298112312, y = C_real), shape = 21,
             mapping = aes(x = x, y = y), fill = "dodgerblue", size = 2.5,
             inherit.aes = FALSE, show.legend = FALSE) +
  scale_x_continuous(name = "Sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  scale_y_continuous(name = "Cost of sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  geom_segment(x = -Inf, xend = -Inf, y = min(breaks), yend = max(breaks)) +
  geom_segment(x = min(breaks), xend = max(breaks), y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

The relationship between the sales $S$ and the cost of sales $C$ can be modelled
by a linear equation:

\begin{equation}
  C = \beta_0 + \beta_1 \cdot S + \epsilon.
\end{equation}

In practice, this relationship is often more complex than is presented above,
and the auditor must carefully construct and evaluate the applied regression
model. However, for ease of understanding we will continue our example with this
simplified model. The auditor can estimate the regression model using the
following command:

```{r}
fit <- lm(costofsales ~ 1 + sales, data = benchmark)
summary(fit)
```

The predicted cost of sales for the auditee, based on the industry benchmark,
can be computed as follows:

```{r}
C_pred <- predict(fit, newdata = data.frame(sales = 298112312),
                  interval = "prediction", level = 0.90)[1]
C_pred
```

The fitted regression line and the predicted cost of sales (red dot) are
visualized in the figure below:

```{r echo = FALSE, fig.width = 7, fig.height = 6, fig.align = "center"}
breaks <- pretty(c(benchmark$sales, benchmark$costofsales))
labels <- paste0("$", format(breaks / 1000000, scientific = FALSE), "M")
p <- ggplot(data = benchmark, mapping = aes(x = sales, y = costofsales)) +
  geom_smooth(stat = "smooth", formula = y ~ x, method = "lm",
              colour = "black", linewidth = 0.5) +
  geom_point(shape = 21, fill = "darkgray", size = 2) +
  geom_point(data = data.frame(x = 298112312, y = C_real), shape = 21,
             mapping = aes(x = x, y = y), fill = "dodgerblue", size = 2.5,
             inherit.aes = FALSE, show.legend = FALSE) +
  geom_point(data = data.frame(x = 298112312, y = C_pred), shape = 21,
             mapping = aes(x = x, y = y), fill = "firebrick", size = 2.5,
             inherit.aes = FALSE, show.legend = FALSE) +
  scale_x_continuous(name = "Sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  scale_y_continuous(name = "Cost of sales", breaks = breaks,
                     limits = range(breaks), labels = labels) +
  geom_segment(x = -Inf, xend = -Inf, y = min(breaks), yend = max(breaks)) +
  geom_segment(x = min(breaks), xend = max(breaks), y = -Inf, yend = -Inf)
p <- jfa:::.theme_jfa(p)
p
```

The prior distribution can be justified by the data and the auditee's numerical
prediction of the cost of sales. In this analytical procedure, the prior
distribution on $\theta$ can utilize the relative error distribution from the
linear regression. This relative error distribution, which is a Normal($\mu$,
$\sigma$) distribution, captures the uncertainty of the prediction of the cost
of sales through the use of linear regression, scaled to be a percentage of the
total cost of sales. The mean $\mu$ of the prior distribution is determined by
the relative deviation of the auditee's booked cost of sales when compared to
the predicted cost of sales according to the benchmark data
$\frac{C - \hat{C}}{C}$.

```{r}
mu <- (C_real - C_pred) / C_real
mu
```

The standard deviation of the prior distribution is expressed through the
standard deviation of the distribution of $\epsilon$:

```{r}
stdev <- sd(fit$residuals) / C_real
stdev
```

The Normal(0.019, 0.05) prior distribution can be constructed through a call to
`auditPrior()`, where the likelihood of the prior is specified as `normal`. We
call the function with `method = "param"` to manually specify the parameters of
the prior distribution.

```{r}
prior <- auditPrior(method = "param", likelihood = "normal",
                    alpha = mu, beta = stdev)
summary(prior)
```

The specified prior distribution can be visualized using the `plot()` function.

```{r}
plot(prior)
```

The performance materiality for this example is set to $\theta_{max}$ = 5%, and
the audit risk is set to $\alpha = 0.05$, or 5%. By using this prior
distribution, the required minimum sample size is 50.

```{r}
plan <- planning(materiality = 0.05, conf.level = 0.95,
                 likelihood = "binomial", prior = prior)
plan
```

You can inspect how the prior distribution compares to the expected posterior
distribution by using the `plot()` function.

```{r}
plot(plan)
```

By using a frequentist approach, the required minimum sample size is 50. Thus,
by performing the analytical procedure and incorporating this information into
the prior distribution, the auditor has achieved a reduction in sample size of
9 items.

```{r}
plan <- planning(materiality = 0.05, conf.level = 0.95,
                 likelihood = "binomial")
plan
```

### Predictive Modeling

As a final example, we consider an example wehre the auditor incorporates
information about the probability of misstatement obtained through a predictive
analysis into the prior distribution for $\theta$. In this example, the auditor
is conducting an audit on a long-term client that they have been working with
for fifteen years. Hence, the auditor has access to a historycal data set called
`history`, which contains the samples from all of the previous audits that have
been conducted on this auditee over the past fifteen years.

```{r}
history <- read.csv("https://github.com/koenderks/sasr/raw/master/data/ch3_history.csv",
                    colClasses = c("factor", "numeric", "numeric"))
head(history)
```

It should be noted that for all historical sample items, there are three known
characteristics: whether they contained a misstatement (designated as `k`), the
number of full-time equivalent employees (FTEs) who had access to that item
within the internal computer systems of the auditee (designated as `ftes`), and
the number of days that the item was outstanding (designated as `days`).
Additionally, the `ftes` and `days` characteristics are also known for all items
in the current year's population. Of course, it is unknown if any misstatements
exist within the population of the current year.

```{r}
population <- read.csv("https://github.com/koenderks/sasr/raw/master/data/ch3_population.csv")
head(population)
```

The objective of this analytical procedure is to forecast potential
misstatements within the population of the current year. In order for the
information obtained through this procedure to serve as prior knowledge in a
Bayesian analysis, the procedure must yield a distribution of the probability of
misstatement. Therefore, the auditor employs a machine learning technique known
as Random Forest [@Hastie2009] to learn the relationship between misstatements,
the number of full-time equivalent employees, and the number of outstanding days
in the historical data set.

```{r}
set.seed(1)
fit <- randomForest::randomForest(formula = k ~ ftes + days, data = history)
```

The auditor specifically uses the random forest technique due to its ability to
provide a distribution of the misstatement probabilities. The probabilistic
predictions for the unseen misstatements in the `population` data can be
obtained by calling the `predict()` function with the argument `type = "prob"`.

```{r}
predictions <- predict(object = fit, newdata = population, type = "prob")
```

These predictions come in a probabilistic format:

```{r}
head(predictions)
```

The prior distribution for $\theta$ will be based on the distribution of
probabilities that each item in the population is misstated. In contrast to the
previous example, this distribution is not a parametric distribution, which
means we are unable to utilize any parametric priors from **jfa**. However, by
providing samples of the prior distribution, **jfa** is able to construct a
nonparametric prior distribution internally via the density of the samples.

The nonparametric prior distribution can be constructed through a call to
`auditPrior()`, where the method to construct of the prior is specified as
`nonparam`. The samples of the prior distribution can be provided through the
`samples` argument. We use the second column of the the `predictions` object for
this.

```{r}
prior <- auditPrior(method = "nonparam", samples = predictions[, 2])
```

The nonparametric prior distribution can be visualized using the `plot()`
function.

```{r}
plot(prior)
```

The performance materiality for this example is set to $\theta_{max}$ = 1%, and
the audit risk is set to $\alpha = 0.05$, or 5%. The minimum sample size can be
calculated with the command below and is 108.

```{r}
plan <- planning(materiality = 0.01, conf.level = 0.95,
                 likelihood = "binomial", prior = prior)
plan
```

You can inspect how the prior distribution compares to the expected posterior
distribution by using the `plot()` function.

```{r}
plot(plan)
```

By using a frequentist approach, the required minimum sample size is 299. Thus,
by performing the analytical procedure and incorporating this information into
the prior distribution, the auditor has achieved a reduction in sample size of
299 - 108 = 191 items.

```{r}
plan <- planning(materiality = 0.01, conf.level = 0.95,
                 likelihood = "binomial")
plan
```

## Exercises

In this section, you will find a variety of exercises designed to help you
practice and reinforce the concepts and skills that you have learned in this
chapter. These exercises are an important part of the learning process, as they
allow you to actively apply what you have learned and see how it works in
practice. Whether you are working through this book on your own or as part of a
class, we encourage you to take the time to complete these exercises and get the
most out of your learning experience.

1. Use the classical approach with the hypergeometric likelihood to compute the
   minimum required sample size for a population of $N = 100$ when applying a
   performance materiality of 3% and a sampling risk of 5%. Tolerate no
   misstatements in the sample.

<details>
<summary>Click to reveal answer</summary>
```{r}
planning(materiality = 0.03, likelihood = "hypergeometric", N.units = 100)
```
</details>

2. Recompute the previous sample size with the Bayesian approach using a default
   prior.

<details>
<summary>Click to reveal answer</summary>
```{r}
planning(materiality = 0.03, likelihood = "hypergeometric", N.units = 100,
         prior = TRUE)
```
</details>

3. Use the classical approach with the binomial likelihood to compute the
   minimum required sample size for a performance materiality of 4.4% and a
   sampling risk of 5%. Tolerate one misstatement in the sample.

<details>
<summary>Click to reveal answer</summary>
```{r}
planning(materiality = 0.044, likelihood = "binomial", expected = 1)
```
</details>

4. Recompute the previous sample size with the Bayesian approach using a default
   prior.

<details>
<summary>Click to reveal answer</summary>
```{r}
planning(materiality = 0.044, likelihood = "binomial", expected = 1,
         prior = TRUE)
```
</details>

5. Use the classical approach with the Poisson likelihood to compute the minimum
   required sample size for a performance materiality of 2% and a sampling risk
   of 5%. Use an expected misstatement rate of 0.5%.

<details>
<summary>Click to reveal answer</summary>
```{r}
planning(materiality = 0.02, expected = 0.005)
```
</details>

6. Recompute the previous sample size with the Bayesian approach using a default
   prior.

<details>
<summary>Click to reveal answer</summary>
```{r}
planning(materiality = 0.02, expected = 0.005, prior = TRUE)
```
</details>

7. Compute the sampling risk according to the Audit Risk Model for an audit risk
   percentage of 5%, an inherent risk percentage of 50% and an internal control
   risk percentage of 80$. Next, use the classical approach with the binomial
   likelihood to compute the minimum sample size for a performance materiality
   of 5% and the new sampling risk. Tolerate no misstatements in the sample.

<details>
<summary>Click to reveal answer</summary>
```{r}
dr <- 0.05 / (0.5 * 0.8)
planning(materiality = 0.05, conf.level = 1 - dr)
```
</details>

8. Construct a prior distribution on the basis of the information in exercise 7.
   Use this prior distribution to recompute the previous sample size with the
   Bayesian approch.

<details>
<summary>Click to reveal answer</summary>
```{r}
prior <- auditPrior(method = "arm", likelihood = "binomial",
                    materiality = 0.05, ir = 0.5, cr = 0.8)
plot(prior)
planning(materiality = 0.05, prior = prior)
```
</details>

9. Construct a prior distribution on the basis of the assumption that tolerable
   misstatement is equally likely as intolerable misstatement before seeing the
   sample data. Use the binomial likelihood and assume a performance
   materiality of 2.5%.

<details>
<summary>Click to reveal answer</summary>
```{r}
prior <- auditPrior(method = "impartial", likelihood = "binomial",
                    materiality = 0.05)
plot(prior)
```
</details>